\def\module{M4P33 Algebraic Geometry}
\def\lecturer{Prof Kevin Buzzard}
\def\term{Spring 2020}
\def\cover{}
\def\syllabus{}
\def\thm{section}

\input{../style/header}

\begin{document}

\input{../style/cover}

\section{Introduction}

\subsection{B\'ezout's theorem}

\lecture{1}{Monday}{13/01/20}

Here is an example of a theorem in algebraic geometry and an outline of a geometric method for proving it which illustrates some of the main themes in algebraic geometry.

\begin{theorem}[B\'ezout]
Let $ C $ be a plane algebraic curve $ \cbr{\br{x, y} \st f\br{x, y} = 0} $ where $ f $ is a polynomial of degree $ m $. Let $ D $ be a plane algebraic curve $ \cbr{\br{x, y} \st g\br{x, y} = 0} $ where $ g $ is a polynomial of degree $ n $. Suppose that $ C $ and $ D $ have no component in common, since if they had a component in common, then their intersection would obviously be infinite. Then $ C \cap D $ consists of $ mn $ points, provided that
\begin{itemize}
\item we work over the complex numbers $ \CC $,
\item we work in the projective plane, which consists of the ordinary plane together with some points at infinity, and
\item we count intersections with the correct multiplicities, so if the curves are tangent at a point, it counts as more than one intersection.
\end{itemize}
\end{theorem}

Consider the cases where $ C $ is a line of degree one and $ D $ has either degree one or two. The projective plane will be formally defined later in the course. We will not define intersection multiplicities in this course, but the idea is that multiple intersections resemble multiple roots of a polynomial in one variable.

\begin{proof}
We prove a special case, where $ C $ is the union of $ m $ lines, then use this to prove the general case of the theorem.
\begin{itemize}
\item First for the special case, suppose we have $ m $ lines in the plane, with equations
$$ a_1x + b_1y + c_1 = 0, \qquad \dots, \qquad a_mx + b_my + c_m = 0. $$
We can multiply these equations together to get
$$ \br{a_1x + b_1y + c_1} \dots \br{a_mx + b_my + c_m} = 0. $$
This is an equation of degree $ m $ and its solution set is the union of the lines. Each line intersects $ D $ in $ n $ points, counted with multiplicities, because we can rearrange the equation of the line into the form $ x = \dots $ or $ y = \dots $ then substitute into the equation for $ D $. This usually gives a polynomial of degree $ n $ in one variable, and this has $ n $ roots if we count them correctly. There are also special cases to worry about where the line intersects $ D $ at infinity. Combining all the $ m $ lines, we deduce that their union intersects $ D $ in $ mn $ points.
\item Now we deduce the general case from the special case. We let the curve $ C $ vary in a family of curves of degree $ m $. What exactly we mean by varying in a family will be defined later in the course. As an example, consider the family of curves
$$ \FFF : \cbr{\br{x, y} \st x^2 - y^2 = t}, $$
where $ t $ is a parameter, so for different values of $ t $ we get different curves. When the curve $ C $ varies in a family like this, the number of intersection points in $ C \cap D $ does not change, counting with multiplicity. This is the core of the proof. It requires a lot of work to justify which we will not do here. For any degree $ m $ curve $ C $, it is possible to find a family of curves which contains both $ C $ itself and a union of $ m $ lines $ X $. For example, if $ C $ is the hyperbola defined by the equation $ x^2 - y^2 = 1 $, then it is found in the family $ \FFF $, with $ t = 1 $. If we let $ t = 0 $ in this family, then the equation factors as $ \br{x - y}\br{x + y} $ and this defines the union of two lines in the plane. We have already proved that $ X \cap D $ has $ mn $ points, and we stated that $ X \cap D $ has the same number of points as $ C \cap D $ because $ C $ and $ X $ are in the same family. We conclude that $ C \cap D $ has $ mn $ points.
\end{itemize}
\end{proof}

\pagebreak

The idea that something stays the same everywhere, or almost everywhere, in a family of varying algebraic sets is a key theme in algebraic geometry. Note that this proof uses not just curves but also higher-dimensional algebraic sets. Instead of thinking about a family of curves such as $ \FFF $, with coordinates $ \br{x, y} $ and a parameter $ t $, we can regard $ x, y, t $ all as coordinates in three-dimensional space and consider the surface
$$ \cbr{\br{x, y, t} \st x^2 - y^2 = t}. $$
Then we use facts about this surface as part of the proof. We will not prove B\'ezout's theorem in this course. In particular, we will not define intersection multiplicities. But we will set up many of the tools needed to fill in the gaps in this outline proof.

\subsection{Practical information about the course}

The following are books.
\begin{itemize}
\item M Reid, Undergraduate algebraic geometry, 1988
\item R Hartshorne, Algebraic geometry, 1977
\end{itemize}
During the course we will sometimes assume results from commutative algebra. Books which contain these results, and much much more, include the following.
\begin{itemize}
\item H Matsumura, Commutative ring theory, 1986
\item M F Atiyah and I G Macdonald, Introduction to commutative algebra, 1969
\item D Eisenbud, Commutative algebra: with a view toward algebraic geometry, 2011
\end{itemize}
The following is the course outline.
\begin{itemize}
\item Affine varieties.
\begin{itemize}
\item Definition and examples.
\item Maps between varieties.
\item Translating between geometry and commutative algebra and the Nullstellensatz.
\end{itemize}
\item Projective varieties.
\begin{itemize}
\item Definition and examples.
\item Maps between varieties.
\item Rigidity and images of maps.
\end{itemize}
\item Dimension.
\begin{itemize}
\item Several different definitions, all equivalent, but useful for different purposes.
\item Calculating dimensions of examples.
\end{itemize}
\end{itemize}
What is not in the course?
\begin{itemize}
\item Schemes.
\item Sheaves and cohomology.
\item Curves, divisors, and the Riemannâ€“Roch theorem.
\end{itemize}

\pagebreak

\section{Affine varieties}

\subsection{Affine algebraic sets}

\subsubsection{Affine space}

Let $ k $ be an algebraically closed field. We are going to be thinking about solutions to polynomials, so everything is much simpler over algebraically closed fields. Number theorists might be interested in other fields, but you generally have to start by understanding the algebraically closed case first. In this course we will stop with the algebraically closed case too. Apart from being algebraically closed, it usually does not matter much which field we use to do algebraic geometry, except sometimes it matters whether the characteristic is zero or positive. In this course I will take care to mention results which depend on the characteristic, and sometimes we might consider only the characteristic zero case. You will not lose much if you just assume that $ k = \CC $ throughout the course, except when it will be explicitly something else. Indeed it is often useful to think about $ k = \CC $ because then you can use your usual geometric intuition. When I draw pictures on the whiteboard, I am usually only drawing the real solutions because it is hard to draw shapes in $ \CC^2 $. This is cheating but it is often very useful. The real solutions are not the full picture but in many cases we can still see the important features there.

\begin{definition*}
Algebraic geometers write $ \AA^n $ to mean $ k^n $, and call it \textbf{affine $ n $-space}.
\end{definition*}

You may think of this as just a funny choice of notation, but there are at least two reasons for it.
\begin{itemize}
\item When we write $ k^n $, it makes us think of a vector space, equipped with operations of addition and scalar multiplication. But $ \AA^n $ means just a set of points, described by coordinates $ \br{x_1, \dots, x_n} $ with $ x_i \in k $, without the vector space structure.
\item Because it usually does not matter much what our base field $ k $ is, as long as it is algebraically closed, it is convenient to have notation which does not prominently mention $ k $.
\end{itemize}
On occasions when it is important to specify which field $ k $ we are using, we write $ \AA_k^n $ for affine $ n $-space.

\subsubsection{Definition and examples}

\lecture{2}{Thursday}{16/01/20}

\begin{definition*}
An \textbf{affine algebraic set} is a subset $ V \subseteq \AA^n $ which consists of the common zeroes of some finite set of polynomials $ f_1, \dots, f_m $ with coefficients in $ k $. More formally, an affine algebraic set is a set of the form
$$ V = \cbr{\br{x_1, \dots, x_n} \in \AA^n \st f_1\br{x_1, \dots, x_n} = \dots = f_m\br{x_1, \dots, x_n} = 0}, \qquad f_1, \dots, f_m \in k\sbr{X_1, \dots, X_n}. $$
\end{definition*}

\begin{example*}
Examples.
\begin{itemize}
\item The empty set, defined by the polynomial $ f_1 = 3 $, for example.
\item The whole space $ \AA^n $, defined by the polynomial $ f_1 = 0 $, or by the empty set of polynomials.
\item Any finite subset $ \cbr{a_1, \dots, a_n} $ in $ \AA^1 $, defined by the polynomial $ f_1 = \br{X - a_1} \dots \br{X - a_n} $.
\item Any single-point set $ \cbr{\br{a_1, \dots, a_n}} $ in $ \AA^n $, defined by the polynomials $ f_i = X_i - a_i $. Note that this is different from the example of a finite set in $ \AA^1 $, because that example had a single polynomial in one variable of degree $ n $, while here we have $ n $ distinct polynomials in $ n $ variables of degree one.
\item Any algebraic curve in $ \AA^n $, that is, a set of the form
$$ \cbr{\br{x_1, \dots, x_n} \in \AA^n \st f\br{x_1, \dots, x_n} = 0}, \qquad f \in k\sbr{X_1, \dots, X_n}. $$
\item Embeddings of $ \AA^m $ in $ \AA^n $ where $ m < n $,
$$ \cbr{\br{x_1, \dots, x_m, 0, \dots, 0} \in \AA^n} = \cbr{\br{x_1, \dots, x_n} \in \AA^n \st x_{m + 1} = \dots = x_n = 0}. $$
More generally, the image of a linear map $ \AA^m \to \AA^n $,
$$ \cbr{\br{x_1, \dots, x_n} \in \AA^n \st \text{some linear conditions}}. $$
\end{itemize}
\end{example*}

\pagebreak

\begin{example*}
Non-examples.
\begin{itemize}
\item Any infinite subset of $ \AA^1 $, other than $ \AA^1 $ itself, such as a line segment, a line with a double point, or an infinite discrete set. This is because a one-variable polynomial with infinitely many roots must be the zero polynomial. This also tells us that $ \cbr{x \in \AA^1 \st x \ne 0} $ is not an affine algebraic set. However there is an affine algebraic set which is isomorphic to $ \AA^1 \setminus \cbr{0} $, namely $ \cbr{\br{x, y} \in \AA^2 \st xy - 1 = 0} $. By looking at just the $ x $ coordinate, this set bijects to $ \AA^1 \setminus \cbr{0} $.
\item A sine wave. If $ \cbr{\br{x, y} \st y = \sin x} $ were an affine algebraic set, then $ \cbr{\br{x, y} \st y = \sin x, \ y = 0} $ would also be an affine algebraic set because it is defined by imposing an extra polynomial condition, but the latter is an infinite discrete set.
\item The example of the image of a linear map $ \AA^m \to \AA^n $ does not generalise to images of maps where each coordinate is given by a polynomial. For example, consider the map
$$ \function[\phi]{\AA^2}{\AA^2}{\br{x, y}}{\br{x, xy}}. $$
The image of $ \phi $ is $ S = \AA^2 \setminus \cbr{\br{0, y}} \cup \cbr{\br{0, 0}} $. To prove that $ S $ is not an affine algebraic set, consider a polynomial $ g\br{X, Y} \in k\sbr{X, Y} $ which vanishes on $ S $. For each fixed $ y \in k $, the one-variable polynomial $ g\br{X, y} $ vanishes at all $ x \ne 0 $. This implies that $ g\br{X, y} $ is the zero polynomial. Thus $ g\br{x, y} = 0 $ for all $ \br{x, y} \in k^2 $, that is, $ g $ is the zero polynomial.
\end{itemize}
\end{example*}

\begin{remark}
The words affine variety mean more or less the same thing as affine algebraic set but there is an ontological difference. Affine algebraic set means a subset which lives inside $ \AA^n $ and knows how it lives inside $ \AA^n $, while affine variety means an object in its own right which is considered outside of $ \AA^n $. I will try to use these words consistently, but the difference is quite subtle and books may not always use it consistently. For the first few weeks, we will talk about affine algebraic sets only. Note that some books, such as Reid and Hartshorne, have another difference between affine varieties and affine algebraic sets. They require varieties to be irreducible, which we will define next time. Other books, such as Shafarevich, do not require varieties to be irreducible. In this course we will not require varieties to be irreducible.
\end{remark}

\subsubsection{New algebraic sets from old}

Now we prove that the union of two affine algebraic sets is an affine algebraic set. Consider two points $ \br{a_1, \dots, a_n} $ and $ \br{b_1, \dots, b_n} $ in $ \AA^n $. The two-point set $ \cbr{\br{a_1, \dots, a_n}, \br{b_1, \dots, b_n}} $ can be defined by taking the product for each possible pair of equations, one from each list, so $ \br{X_i - a_i}\br{X_j - b_j} = 0 $ for all $ i, j \in \cbr{1, \dots, n} $.

\begin{note*}
It is necessary to consider all the pairs between the lists, not just the ones with $ i = j $, because otherwise we would be allowing points like $ \br{a_1, \dots, a_{n - 1}, b_n} $.
\end{note*}

\begin{lemma}
If $ V, W \subseteq \AA^n $ are affine algebraic sets, then their union $ V \cup W \subseteq \AA^n $ is also an affine algebraic set.
\end{lemma}

% We see that any finite subset of $ \AA^n $ is an affine algebraic set.

\begin{proof}
We have to take the product for each possible pair of defining polynomials. If
$$ V = \cbr{\underline{x} \in \AA^n \st f_1\br{\underline{x}} = \dots = f_r\br{\underline{x}} = 0}, \qquad W = \cbr{\underline{x} \in \AA^n \st g_1\br{\underline{x}} = \dots = g_s\br{\underline{x}} = 0}, $$
then
$$ V \cup W = \cbr{\underline{x} \in \AA^n \st \forall 1 \le i \le r, \ \forall 1 \le j \le s, \ f_i\br{\underline{x}}g_j\br{\underline{x}} = 0}. $$
Let us check that these equations really do define $ V \cup W $. First, suppose that $ \underline{x} \in V \cup W $. Then either $ \underline{x} \in V $, so $ f_i\br{\underline{x}} = 0 $ for every $ i $, so we can multiply by $ g_j\br{\underline{x}} $ to get $ f_i\br{\underline{x}}g_j\br{\underline{x}} = 0 $ for every $ i $ and $ j $, or $ \underline{x} \in W $, in which case the same argument works with $ g_j $ in place of $ f_i $. The reverse direction is a little trickier. Suppose that we have $ \underline{x} \in \AA^n $ satisfying $ f_i\br{\underline{x}}g_j\br{\underline{x}} = 0 $ for all $ i $ and $ j $. Looking just at $ f_1 $, we get
$$ f_1\br{\underline{x}}g_1\br{\underline{x}} = 0 \implies f_1\br{\underline{x}} = 0 \ \text{or} \ g_1\br{\underline{x}} = 0, \qquad \dots, \qquad f_1\br{\underline{x}}g_s\br{\underline{x}} = 0 \implies f_1\br{\underline{x}} = 0 \ \text{or} \ g_s\br{\underline{x}} = 0. $$
Putting these all together, we get $ f_1\br{\underline{x}} = 0 $ or $ g_j\br{\underline{x}} = 0 $ for every $ j $. We can do the same thing for $ f_2 $ to get $ f_2\br{\underline{x}} = 0 $ or $ g_j\br{\underline{x}} = 0 $ for every $ j $, and so on for each $ f_i $. Putting all these together, we get $ f_i\br{\underline{x}} = 0 $ for every $ i $ or $ g_j\br{\underline{x}} = 0 $ for every $ j $. This says precisely that $ \underline{x} \in V \cup W $.
\end{proof}

\pagebreak

It is even easier to check that the intersection of finitely many affine algebraic sets is an affine algebraic set.

\begin{lemma}
If $ V, W \subseteq \AA^n $ are affine algebraic sets, then their intersection $ V \cap W \subseteq \AA^n $ is also an affine algebraic set.
\end{lemma}

\begin{proof}
Just combine the lists of defining equations. That is, say
$$ V = \cbr{\underline{x} \in \AA^m \st f_1\br{\underline{x}} = \dots = f_r\br{\underline{x}} = 0}, \qquad W = \cbr{\underline{y} \in \AA^n \st g_1\br{\underline{y}} = \dots = g_s\br{\underline{y}} = 0}. $$
Then $ V \cap W $ is simply the set where all the polynomials in both lists vanish, that is
$$ V \cap W = \cbr{\underline{x} \in \AA^n \st f_1\br{\underline{x}} = \dots = f_r\br{\underline{x}} = g_1\br{\underline{x}} = \dots = g_s\br{\underline{x}} = 0}. $$
\end{proof}

Just a remark on one other way of constructing new affine algebraic sets from existing ones.

\begin{lemma}
If $ V \subseteq \AA^m $ and $ W \subseteq \AA^n $ are affine algebraic sets, then their Cartesian product $ V \times W \subseteq \AA^{m + n} $ is an affine algebraic set.
\end{lemma}

\begin{proof}
Write
$$ V = \cbr{\underline{x} \in \AA^m \st f_1\br{\underline{x}} = \dots = f_r\br{\underline{x}} = 0}, \qquad W = \cbr{\underline{y} \in \AA^n \st g_1\br{\underline{y}} = \dots = g_s\br{\underline{y}} = 0}. $$
Then
$$ V \times W = \cbr{\br{\underline{x}, \underline{y}} \in \AA^{m + n} \st f_1\br{\underline{x}} = \dots = f_r\br{\underline{x}} = g_1\br{\underline{y}} = \dots = g_s\br{\underline{y}} = 0}. $$
\end{proof}

This looks a bit like the equations defining $ V \cap W $, but here the $ f_i $ involve different variables from the $ g_j $, while for $ V \cap W $ both used the same variables.

\subsubsection{Ideals and algebraic sets}

\lecture{3}{Friday}{17/01/20}

The union of infinitely many affine algebraic sets is not always an affine algebraic set. I do not mean that it is never an affine algebraic set, just that there exist counter-examples. Indeed, any subset of $ \AA^n $ can be written as a union of single-point sets. The intersection of infinitely many affine algebraic sets always an affine algebraic set. If we try to prove this by combining the lists of defining equations, we run into a problem. In our definition of affine algebraic sets we only allowed a finite list of polynomial equations. We introduce ideals to remove this restriction.

\begin{definition*}
Recall from commutative algebra that, if $ R $ is a ring, an \textbf{ideal} is a subset $ I \subseteq R $ with the properties that
\begin{itemize}
\item if $ f, g \in I $, then $ f + g \in I $, and
\item if $ f \in I $ and $ q \in R $, then $ qf \in I $.
\end{itemize}
Given any subset $ S \subseteq R $, we define the \textbf{ideal generated by $ S $} to be the smallest ideal which contains $ S $, and denote it by $ \abr{S} $. In particular, if $ S $ is the finite set $ \cbr{f_1, \dots, f_m} $ then it generates the ideal
$$ \abr{f_1, \dots, f_m} = \cbr{q_1f_1 + \dots + q_mf_m \st q_1, \dots, q_m \in R}. $$
\end{definition*}

Let us introduce some notation.

\begin{definition*}
For any set $ S \subseteq k\sbr{X_1, \dots, X_n} $, let
$$ \VV\br{S} = \cbr{\underline{x} \in \AA^n \st \forall f \in S, \ f\br{\underline{x}} = 0}. $$
\end{definition*}

\begin{lemma}
\label{lem:vs}
If $ S \subseteq k\sbr{X_1, \dots, X_n} $ generates the ideal $ I $, then $ \VV\br{S} = \VV\br{I} $.
\end{lemma}

\begin{proof}
We have $ S \subseteq I $ and so it is easy to see that $ \VV\br{I} \subseteq \VV\br{S} $. Suppose that $ \underline{x} \in \VV\br{S} $, and $ f \in \VV\br{I} $. Then there are $ f_1, \dots, f_m \in S $ and $ q_1, \dots, q_m \in k\sbr{X_1, \dots, X_n} $ such that $ f = q_1f_1 + \dots + q_mf_m $. Since $ f_1\br{\underline{x}} = \dots = f_m\br{\underline{x}} = 0 $, it follows that $ f\br{\underline{x}} = 0 $. Since this holds for every $ f \in I $, $ \underline{x} \in \VV\br{I} $.
\end{proof}

\pagebreak

\begin{theorem}[Hilbert basis theorem]
From commutative algebra, if $ k $ is any field, then the polynomial ring $ k\sbr{X_1, \dots, X_n} $ is Noetherian. That means that the following two equivalent conditions hold.
\begin{itemize}
\item Let $ I $ be an ideal in $ k\sbr{X_1, \dots, X_n} $. Then there exists a finite set $ \cbr{f_1, \dots, f_m} \subseteq k\sbr{X_1, \dots, X_n} $ which generates $ I $.
\item Let $ I_1 \subseteq I_2 \subseteq \dots $ be an ascending chain of ideals in $ k\sbr{X_1, \dots, X_n} $. Then there is some $ N $ such that $ I_n = I_N $ for every $ n > N $.
\end{itemize}
\end{theorem}

Using the Hilbert basis theorem, we can deduce that the restriction to finite lists of polynomials in the definition of affine algebraic sets is unnecessary.

\begin{corollary}
\label{cor:vs}
$ \VV\br{S} $ is an affine algebraic set for any set of polynomials $ S \subseteq k\sbr{X_1, \dots, X_n} $.
\end{corollary}

\begin{proof}
Let $ I $ be the ideal in $ k\sbr{X_1, \dots, X_n} $ generated by $ S $. By the Hilbert basis theorem, $ k\sbr{X_1, \dots, X_n} $ is Noetherian and so we can choose a finite set $ \cbr{f_1, \dots, f_m} $ which generates $ I $. Then Lemma \ref{lem:vs} tells us that $ \VV\br{S} = \VV\br{I} = \VV\br{f_1, \dots, f_m} $.
\end{proof}

\begin{corollary}
The intersection of finitely many affine algebraic sets is an affine algebraic set.
\end{corollary}

\begin{proof}
Combine the lists of defining polynomials for all the algebraic sets, and apply Corollary \ref{cor:vs}.
\end{proof}

We can also go in the other direction, from affine algebraic sets to ideals. Say $ V_n = \VV\br{I_n} $. Does $ V_1 \supseteq V_2 $ imply that $ I_1 \subseteq I_2 $? No. The problem is that there is more than one ideal defining the same algebraic set.

\begin{example*}
Let $ I_1 = \abr{X} $ and $ I_2 = \abr{X^2} $ in $ k\sbr{X} $. We have $ \VV\br{I_1} = \cbr{0} = \VV\br{I_2} $.
\end{example*}

However, there is a natural choice we can make for one ideal canonically associated with an affine algebraic set, the set of all polynomials which vanish on that set.

\begin{definition*}
Formally, if $ A $ is any subset of $ \AA^n $, usually $ A $ will be an affine algebraic set, we define
$$ \II\br{A} = \cbr{f \in k\sbr{X_1, \dots, X_n} \st \forall \underline{x} \in A, \ f\br{\underline{x}} = 0}. $$
\end{definition*}

\begin{note*}
$ \II\br{A} $ is an ideal in $ k\sbr{X_1, \dots, X_n} $.
\end{note*}

We have now defined two functions
$$ \VV : \cbr{\text{ideals in} \ k\sbr{X_1, \dots, X_n}} \to \cbr{\text{affine algebraic sets in} \ \AA^n}, $$
$$ \II : \cbr{\text{affine algebraic sets in} \ \AA^n} \to \cbr{\text{ideals in} \ k\sbr{X_1, \dots, X_n}}. $$
These functions are not inverses of each other. The example of $ \abr{X} $ and $ \abr{X^2} $ shows that $ \II\br{\VV\br{\abr{X^2}}} = \abr{X} \ne \abr{X^2} $. But composing $ \VV $ and $ \II $ in the other order gives the identity.

\begin{lemma}
\label{lem:viv}
If $ V $ is an affine algebraic set, then $ \VV\br{\II\br{V}} = V $.
\end{lemma}

\begin{proof}
It is clear that $ V \subseteq \VV\br{\II\br{V}} $, and this works when $ V $ is any subset of $ \AA^n $, not necessarily algebraic. For the reverse inclusion, we have to use the hypothesis that $ V $ is an affine algebraic set. By the definition of affine algebraic sets, $ V = \VV\br{J} $ for some ideal $ J \subseteq k\sbr{X_1, \dots, X_n} $. Suppose that $ \underline{y} \notin V $. We shall show that $ \underline{y} \notin \VV\br{\II\br{V}} $. Because $ \underline{y} \notin V = \VV\br{J} $, there exists $ f \in J $ such that $ f\br{\underline{y}} \ne 0 $. By definition, $ J \subseteq \II\br{V} $ and so $ f \in \II\br{V} $. Hence $ f\br{\underline{y}} \ne 0 $ tells us that $ \underline{y} \notin \VV\br{\II\br{V}} $.
\end{proof}

What is the geometric interpretation of the Hilbert basis theorem?

\begin{note*}
It is clear that $ \VV $ and $ \II $ reverse the direction of inclusions, so if $ I_1 \subseteq I_2 $, then $ \VV\br{I_2} \subseteq \VV\br{I_1} $.
\end{note*}

Hence the ascending chain condition for ideals translates into the descending chain condition for affine algebraic sets. The following statement is the translation into affine algebraic sets of the Hilbert basis theorem.

\begin{lemma}
\label{lem:descendingchain}
Let $ V_1 \supseteq V_2 \supseteq \dots $ be a descending chain of affine algebraic sets in $ \AA^n $. Then there exists $ N $ such that $ V_n = V_N $ for all $ n > N $.
\end{lemma}

\begin{proof}
The fact that $ V_1 \supseteq V_2 \supseteq \dots $ implies that $ \II\br{V_1} \subseteq \II\br{V_2} \subseteq \dots $. Because $ k\sbr{X_1, \dots, X_n} $ is Noetherian, there exists $ N $ such that $ \II\br{V_n} = \II\br{V_N} $ for all $ n > N $. By Lemma \ref{lem:viv}, $ V_n = \VV\br{\II\br{V_n}} $ for every $ n $ and so this proves the proposition.
\end{proof}

\pagebreak

\subsubsection{Statement of the Nullstellensatz}

When does $ \II\br{\VV\br{I}} = I $? It turns out that the only reason that this can fail is where elements of the ideal $ I $ have $ n $-th roots which are not in $ I $, just as with the example of $ I = \abr{X^2} $ where $ X^2 \in I $ has a square root $ X $ which is not in $ I $. To state this precisely, we need to recall the definition of the radical of an ideal from commutative algebra.

\begin{definition*}
Let $ I $ be an ideal in a ring $ R $. The \textbf{radical} of $ I $ is
$$ \rad I = \sqrt{I} = \cbr{f \in R \st \exists n > 0, \ f^n \in I}. $$
We say that $ I $ is a \textbf{radical ideal} if $ \rad I = I $.
\end{definition*}

\begin{note*}
If $ I $ is any ideal, then $ \rad I $ is always a radical ideal.
\end{note*}

\begin{theorem}[Hilbert's Nullstellensatz]
\label{thm:strongnullstellensatz}
Let $ I $ be any ideal in the polynomial ring $ k\sbr{X_1, \dots, X_n} $ over an algebraically closed field $ k $. Then we have
$$ \II\br{\VV\br{I}} = \rad I. $$
\end{theorem}

This is a substantial theorem, fundamental to algebraic geometry. We will prove it in a few lectures' time, not because we need to develop more theory, just because I would like to introduce some more concepts first which will allow us to do more with examples.

\begin{note*}
To calculate $ \rad I $, we need to add in $ n $-th roots of all elements of $ I $, not just the generators.
\end{note*}

\begin{example*}
If $ I = \abr{X, Y^2 - X} \subseteq k\sbr{X, Y} $, then we can rewrite this as $ I = \abr{X, Y^2} $ and so $ \rad I = \abr{X, Y} \ne I $, even though neither of the original generators of $ I $ had any non-trivial $ n $-th roots.
\end{example*}

\subsubsection{Basic facts about the Zariski topology}

We have seen that affine algebraic sets in $ \AA^n $ satisfy the following conditions.
\begin{itemize}
\item $ \AA^n $ and $ \emptyset $ are affine algebraic sets.
\item A finite union of affine algebraic sets is an affine algebraic set.
\item An arbitrary intersection of affine algebraic sets is an affine algebraic set.
\end{itemize}
The are precisely the conditions satisfied by the closed sets in a topological space. Therefore, we can define a topological space in which the underlying set is $ \AA^n $ and closed sets are the affine algebraic sets. This is called the \textbf{Zariski topology}. This is a very different topology from the ones you are used to in analysis. In particular, it is a very long way from being Hausdorff. For any affine algebraic set $ V \subseteq \AA^n $, we define the \textbf{Zariski topology} on $ V $ to be the subspace topology on $ V $ induced by the Zariski topology on $ \AA^n $. Thus, a subset of $ V $ is Zariski closed in $ V $ if and only if it is Zariski closed in $ \AA^n $. Thus for closed sets it does not matter whether we say Zariski closed in $ V $ or Zariski closed in $ \AA^n $.

\lecture{4}{Monday}{20/01/20}

\begin{example*}
The Zariski topology on $ \AA^1 $ is the same as the cofinite topology. Prove that the Zariski topology on $ \AA^1 $ is not Hausdorff. \footnote{Exercise}
\end{example*}

Thus we see that the Zariski topology has much fewer closed sets, or much fewer open sets, than for example the Euclidean topology.

\begin{lemma}
Suppose that $ k = \CC $, so there is a Euclidean topology on $ \AA_\CC^n $. If $ V $ is a Zariski closed subset of $ \AA_\CC^n $, then $ V $ is closed in the Euclidean topology, so the Euclidean topology is finer than the Zariski topology.
\end{lemma}

\begin{proof}
Let $ f \in \CC\sbr{X_1, \dots, X_n} $ be a polynomial. It is a continuous function $ \AA_\CC^n \to \CC $ for the Euclidean topology. Since $ \cbr{0} $ is a closed subset of $ \CC $, $ \VV\br{f} = f^{-1}\br{0} $ is a closed subset of $ \AA_\CC^n $ in the Euclidean topology. We conclude by noting that intersections of closed sets are closed.
\end{proof}

\pagebreak

On the other hand, for open sets Zariski open in $ V $ does not mean the same thing as Zariski open in $ \AA^n $. A Zariski open subset of $ V $ need not be Zariski open in $ \AA^n $.

\begin{example*}
Let $ V $ be the $ x $-axis in $ \AA^2 $. Then $ V \setminus \cbr{0} $ is open in $ V $, but not open in $ \AA^2 $.
\end{example*}

The open subsets of the Zariski topology are all very big. This is made precise, for $ \AA^1 $, by the following lemma.

\begin{lemma}
Prove that every pair $ U_1 $ and $ U_2 $ of non-empty open sets in $ \AA^1 $ has a non-empty intersection $ U_1 \cap U_2 $.
\end{lemma}

Hence the Zariski topology on $ \AA^1 $ is not Hausdorff. A subset of $ \AA^1 $ is dense in the Zariski topology if and only if it is infinite. At the moment, the Zariski topology is likely to seem very strange. It might also seem like, what is the point of such a strange topology? We will not use it in a very deep way, it is just a convenient language to be able to talk about open and closed sets. It does get used more seriously in the theory of schemes.

\subsubsection{Connected and irreducible sets}

Recall the definition of a connected topological space.

\begin{definition*}
A topological space $ S $ is \textbf{connected} if it is not possible to write it as the union of two disjoint non-empty open sets. This is equivalent to, it is not possible to write $ S $ as the union of two disjoint non-empty closed sets.
\end{definition*}

It is possible to talk about connectedness in the Zariski topology.

\begin{example*}
A finite set of points of size greater than one is not connected in the Zariski topology, since every subset is closed.
\end{example*}

Consider the following affine algebraic sets in $ \AA^2 $. Do they have one or two pieces? Do they have one or two pieces? I have deliberately not specified what I mean by pieces. There are multiple sensible interpretations, so there is not always a unique correct answer.
\begin{itemize}
\item The union of two disjoint lines $ \VV\br{X\br{X - 1}} $.
\item The union of two intersecting lines $ \VV\br{XY} $.
\item The hyperbola $ \VV\br{XY - 1} $.
\end{itemize}

\begin{example*}
The union of two disjoint lines $ \VV\br{X\br{X - 1}} $ is not connected, since it unambiguously has two pieces, the two lines $ \VV\br{X} $ and $ \VV\br{X - 1} $, and each line is a non-empty closed subset.
\end{example*}

But there is a more refined notion for the Zariski topology.

\begin{example*}
The set $ \VV\br{XY} $ has more than one answer. The two axes form two pieces. It is a union of two lines, intersecting at the origin, joining them into one piece. Describe the Zariski closed subsets. \footnote{Exercise}
\end{example*}

The following notion gives us a way of formally understanding the example described.

\begin{definition*}
A topological space $ S $ is \textbf{reducible} if it is empty, or there exist closed sets $ S_1, S_2 \subseteq S $ such that $ S = S_1 \cup S_2 $, and neither $ S_1 $ nor $ S_2 $ is equal to $ S $. A topological space $ S $ is \textbf{irreducible} if it is non-empty and it is not possible to write it as the union $ S_1 \cup S_2 $ of two closed sets, unless at least one of $ S_1 $ and $ S_2 $ is equal to $ S $ itself. Compared to the second definition of connected, we no longer require $ S_1 $ and $ S_2 $ to be disjoint.
\end{definition*}

This is not a very useful notion for the topological spaces we consider in analysis.

\begin{example*}
Considering the real line with the Euclidean topology, we can write it as a union of proper closed subsets,
$$ \RR = \cbr{x \in \RR \st x \le 0} \cup \cbr{x \in \RR \st x \ge 0}. $$
These subsets are not disjoint because they intersect at zero. Of course, there are many other ways to write $ \RR $ as a union of proper closed subsets in the usual topology. The same is true for any other Hausdorff space.
\end{example*}

\pagebreak

\begin{example*}
The drawing of $ \VV\br{XY - 1} $ in $ \RR^2 $ is misleading. It looks like it has two pieces, but, as mentioned before, we are missing a lot by only looking at real solutions. For algebraic geometry, we need to look at complex solutions, and then over $ \CC $ it unambiguously has one piece. One way to visualise this is to note that, if we project down to the $ x $ coordinate, $ \VV\br{XY - 1} $ looks like the set $ \AA^1 \setminus \cbr{0} $. This is not a formal statement. We have not yet defined a notion of isomorphism of affine algebraic sets, and even if we had, $ \AA^1 \setminus \cbr{0} $ is not an affine algebraic set. In a few weeks we will develop technology to make this into a rigorous statement. But for now we use it as a heuristic. Then $ \RR \setminus \cbr{0} $ unambiguously has two pieces, but $ \CC \setminus \cbr{0} $ is connected in the usual analytic topology on $ \CC $ and unambiguously has one piece. So the hyperbola, over an algebraically closed field, should have only one piece.
\end{example*}

We prove below in the lecture that $ \VV\br{XY - 1} $ is irreducible, and also connected.

\begin{lemma}
The hyperbola $ H = \VV\br{XY - 1} $ is irreducible.
\end{lemma}

\begin{proof}
We need to describe the Zariski closed subsets of $ H $. So let $ V \subseteq H $ be a proper Zariski closed subset. Since $ V \ne H $ there must be some polynomial $ f \in k\sbr{X, Y} $ which vanishes on $ V $ but does not vanish on all of $ H $. Because $ V \subseteq H $ and $ y = 1 / x $ on $ H $, we have $ f\br{x, y} = f\br{x, 1 / x} $ when $ \br{x, y} \in V $. Now $ f\br{X, 1 / X} $ is almost a polynomial in the single variable $ X $, except that it may contain negative powers of $ X $, so
$$ f\br{X, \dfrac{1}{X}} = \sum_{n \in \ZZ} a_nX^n. $$
We can multiply up by $ X^m $ where $ -m $ is the lowest exponent of $ X $ which appears in this expression. Then $ X^mf\br{X, 1 / X} $ is a polynomial in $ X $, which vanishes on $ V $. Furthermore $ f\br{X, 1 / X} $ is not identically zero because $ f $ does not vanish identically on $ H $. Hence $ X^mf\br{X, 1 / X} $ is a non-zero single-variable polynomial, therefore it has only finitely many roots. The roots of $ X^mf\br{X, 1 / X} = 0 $ are the possible $ x $ coordinates for points in $ V $. For each value of $ x $, there is at most one possible $ y $ such that $ \br{x, y} \in V $ because $ y = 1 / x $ on $ V $. Therefore $ V $ is finite. Thus we have shown that all proper Zariski closed subsets of $ H $ are finite. In particular, if $ V_1 $ and $ V_2 $ are two proper Zariski closed subsets of $ H $, they are both finite and so their union is finite. Hence $ V_1 \cup V_2 \ne H $ so $ H $ is irreducible.
\end{proof}

Thus the Zariski topology on $ H $ is the cofinite topology. Here is a bonus fact about connected sets in the Zariski topology which I did not mention in the lecture. The proof is surprisingly hard.

\begin{theorem}
Over $ \CC $, an affine algebraic set is connected in the Zariski topology if and only if it is connected in the Euclidean topology.
\end{theorem}

\subsubsection{Prime ideals and irreducible sets}

If $ V $ is an affine algebraic set, what condition on the ideal $ \II\br{V} $ is equivalent to $ V $ being irreducible?

\lecture{5}{Thursday}{23/01/20}

\begin{definition*}
From commutative algebra, an ideal $ I $ in a ring $ R $ is a \textbf{prime ideal} if $ I \ne R $ and for every $ f, g \in R $, if $ fg \in I $, then $ f \in I $ or $ g \in I $, or both.
\end{definition*}

\begin{lemma}
\label{lem:irreducibleprime}
An affine algebraic set $ V \subseteq \AA^n $ is irreducible if and only if $ \II\br{V} $ is a prime ideal in $ k\sbr{X_1, \dots, X_n} $.
\end{lemma}

\begin{proof}
First suppose that $ V $ is irreducible. Suppose we have $ f, g \in k\sbr{X_1, \dots, X_n} $ such that $ fg \in \II\br{V} $. Let
$$ V_1 = \cbr{\underline{x} \in V \st f\br{\underline{x}} = 0}, \qquad V_2 = \cbr{\underline{x} \in V \st g\br{\underline{x}} = 0}. $$
For every $ \underline{x} \in V $, $ f\br{\underline{x}}g\br{\underline{x}} = 0 $ and hence either $ f\br{\underline{x}} = 0 $ or $ g\br{\underline{x}} = 0 $. Thus for every $ \underline{x} \in V $, either $ \underline{x} \in V_1 $ or $ \underline{x} \in V_2 $. In other words, $ V = V_1 \cup V_2 $. Furthermore $ V_1 $ and $ V_2 $ are closed subsets of $ V $. Hence as $ V $ is irreducible, either $ V_1 = V $ or $ V_2 = V $. If $ V_1 = V $ then $ f \in \II\br{V} $ and if $ V_2 = V $ then $ g \in \II\br{V} $. Now suppose that $ V $ is reducible. Then we can write it as a union $ V_1 \cup V_2 $ of proper closed subsets. Since $ V_1 $ is a proper closed subset of $ V $, there exists some $ f \in k\sbr{X_1, \dots, X_n} $ vanishing on $ V_1 $ but not on all of $ V $. Similarly there exists $ g $ vanishing on $ V_2 $ but not on all of $ V $. Thus neither $ f $ nor $ g $ is in $ \II\br{V} $, but the product $ fg $ vanishes on $ V_1 \cup V_2 $ and hence we have $ fg \in \II\br{V} $. Thus $ \II\br{V} $ is not prime. Then $ V $ is empty if and only if $ \II\br{V} = k\sbr{X_1, \dots, X_n} $, which is explicitly defined to not be a prime ideal. So it was ok to ignore this case above.
\end{proof}

\pagebreak

\begin{definition*}
A \textbf{hypersurface} is an affine algebraic set in $ \AA^n $ defined by one polynomial equation, that is,
$$ \cbr{\underline{x} \in \AA^n \st f\br{\underline{x}} = 0}, \qquad f \in k\sbr{X_1, \dots, X_n}. $$
\end{definition*}

It follows from Lemma \ref{lem:irreducibleprime} together with Hilbert's Nullstellensatz that a hypersurface defined by a polynomial $ f $ is irreducible if and only if $ f $ is a power of an irreducible polynomial. See problem sheet $ 1 $.

\begin{example*}
We can use this to prove that the circle $ \cbr{\br{x, y} \st x^2 + y^2 = 1} $ is irreducible, by proving that the polynomial $ X^2 + Y^2 - 1 $ is irreducible. This is because, if $ f = X^2 + Y^2 - 1 = f_1f_2 $ then we can scale $ f_1 $ and $ f_2 $ by constants to get
$$ f_1 = X + g_1\br{Y}, \qquad f_2 = X + g_2\br{Y}, $$
since $ f $ has degree two in $ X $ and its $ X^2 $ term has coefficient one. Since $ f $ has no $ X $ term, we must have $ g_1 + g_2 = 0 $. But then
$$ f_1f_2 = \br{X + g_1\br{Y}}\br{X - g_1\br{Y}} = X^2 - g_1\br{Y}^2, $$
so $ g_1\br{Y}^2 = -Y^2 + 1 $, and $ -Y^2 + 1 $ is not a square. On the other hand, the hypersurface $ \cbr{\br{x, y} \st x^2 + y^2 = 0} $ is reducible, because $ X^2 + Y^2 $ factors as $ \br{X - iY}\br{X + iY} $.
\end{example*}

It can often be convenient to rewrite the definition of irreducible spaces in terms of open sets instead of closed sets.

\begin{lemma}
\label{lem:irreducibleopen}
The following conditions on a topological space $ S $ are equivalent to irreducibility.
\begin{itemize}
\item $ S $ is non-empty, and every pair of non-empty open subsets $ U_1, U_2 \subseteq S $ have non-empty intersection $ U_1 \cap U_2 $.
\item $ S $ is non-empty, and every non-empty open subset of $ S $ is dense in $ S $.
\end{itemize}
\end{lemma}

\begin{proof}
Just manipulation of the topological definition.
\end{proof}

\begin{corollary}
\label{cor:irreducibleopen}
Let $ S $ be a irreducible topological space and $ U \subseteq S $ a non-empty open subset. Then $ U $ is irreducible, in the subspace topology.
\end{corollary}

Lemma \ref{lem:irreducibleopen} says that irreducible is a very long way from Hausdorff. The Hausdorff condition says that a space has lots of pairs of disjoint non-empty open subsets, while an irreducible space has none.

\begin{example*}
We saw that $ \RR $, with the Euclidean topology, is reducible in many ways.
\end{example*}

Corollary \ref{cor:irreducibleopen} implies that $ \AA^1 \setminus \cbr{0} $ is irreducible, in the subspace topology induced by the Zariski topology on $ \AA^1 $, because it is open in $ \AA^1 $. Compare this to the fact that the hyperbola $ H $ is irreducible. This lends support to the heuristic argument that the hyperbola $ H $ is irreducible, but it is not a proof. Checking that the subspace topology on $ \AA^1 \setminus \cbr{0} $ is the same as the Zariski topology on $ H $ would require exactly the same work as the proof that $ H $ is irreducible to prove that the Zariski topology on $ H \subseteq \AA^2 $.

\subsubsection{Irreducible components}

Just like the definition of connected components, we can define the following.

\begin{definition*}
Let $ S $ be a topological space. An \textbf{irreducible component} of $ S $ is a maximal irreducible subset of $ S $.
\end{definition*}

Unlike connected components, irreducible components need not be disjoint.

\begin{example*}
The irreducible components of $ \cbr{\br{x, y} \st xy = 0} $ are the lines $ x = 0 $ and $ y = 0 $, which intersect in $ \cbr{\br{0, 0}} $.
\end{example*}

More generally, the irreducible components of a hypersurface $ \VV\br{f} $ correspond to the irreducible factors of $ f $. If $ f = f_1^{a_1} \dots f_m^{a_m} $, where the $ f_i $ are distinct irreducible polynomials, then the irreducible components of $ \VV\br{f} $ are $ \VV\br{f_1}, \dots, \VV\br{f_m} $. Irreducible components have the following key properties.

\pagebreak

\begin{proposition}
\label{prop:irreduciblecomponent}
Let $ V $ be an affine algebraic set. Then
\begin{enumerate}
\item the union of the irreducible components of $ V $ is all of $ V $, and
\item $ V $ has only finitely many irreducible components.
\end{enumerate}
\end{proposition}

Proposition \ref{prop:irreduciblecomponent}.$ 1 $ matches a property of connected components. Proposition \ref{prop:irreduciblecomponent}.$ 2 $ does not apply to the connected components of an arbitrary topological space.

\begin{example*}
$ \ZZ $ or $ \QQ $ with the subspace topology from $ \RR $.
\end{example*}

\begin{note*}
Proposition \ref{prop:irreduciblecomponent}.$ 2 $ does imply that an affine algebraic set has only finitely many connected components for the Zariski topology, because each connected component must be a union of irreducible components.
\end{note*}

Proposition \ref{prop:irreduciblecomponent}.$ 2 $ is a finiteness statement, so it is not surprising that it follows from the Noetherian property, the descending chain condition on closed subsets. The key idea in the proof is as follows. If an affine algebraic set is reducible, then we can write it as a union of proper closed subsets. If these subsets are reducible, then we can write them in turn as unions of proper closed subsets. The following lemma says that this process eventually stops. After finitely many steps, we reach irreducible sets.

\begin{lemma}
\label{lem:irreducibleclosed}
Every affine algebraic set can be written as a union of finitely many irreducible closed subsets.
\end{lemma}

\begin{proof}
Suppose that $ V $ is an affine algebraic set which cannot be written as a union of finitely many irreducible closed subsets. Then $ V $ must be reducible, otherwise we could write it as a union of one irreducible closed subset. So $ V = V_1 \cup W_1 $, with $ V_1 $ and $ W_1 $ proper closed subsets of $ V $. Then $ V_1 $ and $ W_1 $ cannot both be unions of finitely many irreducible closed subsets, because taking the union of those decompositions would give us $ V $ as a union of finitely many irreducible closed subsets. Thus at least one of $ V_1 $ and $ W_1 $ does not satisfy Lemma \ref{lem:irreducibleclosed}. Without loss of generality, we may suppose that $ V_1 $ does not satisfy Lemma \ref{lem:irreducibleclosed}. Then $ V_1 $ must be reducible, so we can write $ V_1 = V_2 \cup W_2 $. We can repeat the argument. At least one of $ V_2 $ and $ W_2 $ does not satisfy Lemma \ref{lem:irreducibleclosed}, without loss of generality $ V_2 $, etc. Thus we build up a chain of closed subsets $ V \supset V_1 \supset V_2 \supset \dots $ where all these sets do not satisfy Lemma \ref{lem:irreducibleclosed}, and all the inclusions are strict. This contradicts Lemma \ref{lem:descendingchain}, the descending chain condition for affine algebraic sets.
\end{proof}

In order to prove Proposition \ref{prop:irreduciblecomponent}, we want to show that the finitely many irreducible closed subsets in Lemma \ref{lem:irreducibleclosed} are the irreducible components. There is just one wrinkle. Consider $ V = \VV\br{XY} $. The irreducible components are $ \VV\br{X} $ and $ \VV\br{Y} $. But we could write $ V $ as a union of finitely many irreducible closed subsets by saying
$$ V = \VV\br{X} \cup \VV\br{Y} \cup \cbr{\br{0, 2}}. $$
Thus we can always add in extra sets to a decomposition as in Lemma \ref{lem:irreducibleclosed}, where the extra sets are contained in one of the other sets in the decomposition. Of course we can always just throw away these empty sets from the list without changing the union. Let $ V = V_1 \cup \dots \cup V_r $, as in Lemma \ref{lem:irreducibleclosed}. By throwing away any $ V_i $ which is contained in another $ V_j $, we can assume that $ V_i \not\subseteq V_j $ whenever $ i \ne j $, and still the union of the $ V_j $'s will be $ V $. Subject to this non-redundancy condition, there is only one way to write $ V $ as a finite union of irreducible closed subsets and we can prove the following.

\begin{proposition}
\label{prop:irreducibleclosed}
Let $ V $ be an affine algebraic set. Write $ V = V_1 \cup \dots \cup V_r $, where the $ V_i $ are irreducible closed subsets and $ V_i \not\subseteq V_j $ for $ i \ne j $. Then $ V_1, \dots, V_r $ are precisely the irreducible components of $ V $.
\end{proposition}

\begin{proof}
First we show that each $ V_i $ is an irreducible component. By hypothesis, $ V_i $ is irreducible. So if $ V_i $ is not an irreducible component, it is not a maximal irreducible set and must be contained in a larger irreducible set $ W \subseteq V $. But then
$$ W = \br{V_1 \cap W} \cup \dots \cup \br{V_r \cap W}, $$
where $ V_1 \cap W, \dots, V_r \cap W $ are closed subsets of $ W $. Because $ W $ is irreducible, we must have $ W = V_j \cap W $ for some $ j $. Thus $ V_i \subseteq W \subseteq V_j $. By the condition $ V_i \not\subseteq V_j $ for any $ j \ne i $, we must have $ i = j $ and $ W = V_i $. Thus $ V_i $ is an irreducible component of $ V $. Conversely, let $ C $ be an irreducible component of $ V $. Then
$$ C = \br{V_1 \cap C} \cup \dots \cup \br{V_r \cap C}. $$
By the same argument as before, the irreducibility of $ C $ implies that $ C \subseteq V_i $ for some $ i $. Then the maximality of $ C $ implies that $ C = V_i $.
\end{proof}

The combination of Lemma \ref{lem:irreducibleclosed} and Proposition \ref{prop:irreducibleclosed} proves both Proposition \ref{prop:irreduciblecomponent}.$ 1 $ and Proposition \ref{prop:irreduciblecomponent}.$ 2 $.

\pagebreak

\subsubsection{Primary decomposition of ideals}

The irreducible component decomposition of an affine algebraic set can give a geometric understanding of the primary decomposition of ideals in the Noetherian ring $ k\sbr{X_1, \dots, X_n} $. However, the irreducible decomposition gives only partial information about the primary decomposition of an ideal, because ideals contain more information than affine algebraic sets. Recall that the algebraic set depends only on the radical of the ideal.

\begin{example*}
Let $ I = \abr{X^2, XY} \subseteq k\sbr{X, Y} $. Then $ \VV\br{I} $ is simply the line $ X = 0 $, which of course is irreducible. However a primary decomposition of $ I $ is
$$ I = \abr{X} \cap \abr{X^2, XY, Y^2}. $$
Here $ \abr{X} $ is the ideal of the line $ X = 0 $, the unique irreducible component of $ V = \VV\br{I} $. The ideal $ \abr{X^2, XY, Y^2} $ defines the point $ \cbr{\br{0, 0}} $, which is contained in $ V $ so is not an irreducible component.
\end{example*}

Thus the minimal associated primes of the primary decomposition of $ I $ corespond to the irreducible components of $ \VV\br{I} $, while non-minimal associated primes correspond to additional smaller sets strictly contained in the irreducible components, called \textbf{embedded components}. In scheme theory, we can think of $ \VV\br{I} $ as containing multiple copies of these embedded components.

\begin{example*}
The ideal $ I = \abr{X^2, XY} $ corresponds, in the world of schemes, to the line $ X = 0 $ with two copies of the origin.
\end{example*}

\subsection{Regular and rational maps}

\subsubsection{Regular functions}

\lecture{6}{Friday}{24/01/20}

So far we have only considered algebraic sets as sets, sitting individually. Now we look at functions between them. Just as one uses continuous functions for topological spaces, holomorphic functions for complex manifolds, homomorphisms for groups, etc, so algebraic geometry has its own type of functions, regular functions. Of course, these are given by polynomials.

\begin{definition*}
Let $ V \subseteq \AA^n $ be an affine algebraic set. A \textbf{regular function} on $ V $ is a function $ f : V \to k $ such that there exists a polynomial $ F \in k\sbr{X_1, \dots, X_n} $ with $ f\br{\underline{x}} = F\br{\underline{x}} $ for all $ \underline{x} \in V $.
\end{definition*}

\begin{note*}
The polynomial $ F $ is not uniquely determined by the function $ f $, since $ F, G \in k\sbr{X_1, \dots, X_n} $ determine the same regular function on $ V $ if and only if $ F - G $ vanishes on $ V $, that is if and only if $ F - G \in \II\br{V} $.
\end{note*}

\begin{definition*}
The regular functions on $ V $ form a $ k $-algebra. They can be added and multiplied by each other, and multiplied by scalars in $ k $. This is called the \textbf{coordinate ring} of $ V $ and denoted $ k\sbr{V} $.
\end{definition*}

There is a ring homomorphism $ k\sbr{X_1, \dots, X_n} \to k\sbr{V} $ which sends a polynomial $ F $ to the function $ \eval{F}_V $ which it defines on $ V $. This homomorphism is surjective and its kernel is $ \II\br{V} $, so
$$ k\sbr{V} \cong k\sbr{X_1, \dots, X_n} / \II\br{V}. $$

\begin{example*}
What are the coordinate rings of the following affine algebraic sets?
\begin{itemize}
\item The coordinate ring of $ \AA^n $ is $ k\sbr{X_1, \dots, X_n} $.
\item The coordinate ring of a point is $ k $. A regular function on a point is just a single value.
\item The coordinate ring of two points $ \cbr{x \in \AA^1 \st x\br{x - 1} = 0} $ is $ k \times k $. A regular function on two points is determined by two scalars, namely its value on each of the two points. For any pair of values $ \br{a, b} \in k \times k $, one can easily write down a polynomial $ f \in k\sbr{X} $ such that $ f\br{1} = a $ and $ f\br{0} = b $. Alternatively, one can check algebraically that the map
$$ \function{k \times k}{k\sbr{X} / \abr{X\br{X - 1}}}{\br{a, b}}{\br{a - 1}X + b \mod \abr{X\br{X - 1}}} $$
is a $ k $-algebra isomorphism. This example generalises. If $ V $ is a disconnected affine algebraic set, we can write $ V $ as a union $ V_1 \cup V_2 $ of disjoint Zariski closed subsets, and then $ k\sbr{V} = k\sbr{V_1} \times k\sbr{V_2} $. On the other hand, if $ V $ is reducible but connected, so that the sets $ V_1 $ and $ V_2 $ are not disjoint, then $ k\sbr{V} $ is a proper subset of $ k\sbr{V_1} \times k\sbr{V_2} $.

\pagebreak

\item The coordinate ring of two intersecting lines $ \cbr{\br{x, y} \in \AA^2 \st xy = 0} $ is
$$ \cbr{\br{f, g} \in k\sbr{X} \times k\sbr{Y} \st f\br{0} = g\br{0}}. $$
To prove this, one can also interpret this as
$$ k\sbr{X, Y} / \abr{XY} \cong \cbr{a_0 + \sum_{r = 1}^m b_rX^r + \sum_{s = 1}^n c_sY^s \st a_0, b_1, \dots, b_m, c_1, \dots, c_n \in k, \ m, n \in \NN}. $$
We can compare these two descriptions by observing that
$$ k\sbr{X} = \cbr{a_0 + \sum_{r = 1}^m b_rX^r}, \qquad k\sbr{Y} = \cbr{a_0 + \sum_{s = 1}^n c_sY^s}, $$
and the condition that $ f\br{0} = g\br{0} $ is equivalent to insisting that these two polynomials have the same constant coefficient $ a_0 $. This does not generalise to arbitrary reducible algebraic sets. We may have $ V = V_1 \cup V_2 $ where $ V_1 $ and $ V_2 $ are closed subsets, but
$$ k\sbr{V} \ne \cbr{\br{f, g} \in k\sbr{V_1} \times k\sbr{V_2} \st \eval{f}_{V_1 \cap V_2} = \eval{g}_{V_1 \cap V_2}}. $$
There will be an example of this on problem sheet $ 2 $.
\item The coordinate ring of a hyperbola $ \cbr{\br{x, y} \in \AA^2 \st xy - 1 = 0} $ is the quotient ring $ k\sbr{X, Y} / \abr{XY - 1} $. To describe this more explicitly, note that any term of a two-variable polynomial is
$$ a_{r, s}X^rY^s \equiv
\begin{cases}
a_{r, s}X^{r - s} & r \ge s \\
a_{r, s}Y^{s - r} & s > r
\end{cases}
\mod \abr{XY - 1}.
$$
Thus every coset in $ k\sbr{X, Y} / \abr{XY - 1} $ has a representative of the form
$$ \sum_{i = 0}^m a_iX^i + \sum_{j = 1}^n a_jY^j. $$
The polynomials of this form determine different functions on $ V $, so we have written down exactly one representative of each coset. Furthermore, since $ XY = 1 $ in $ k\sbr{V} $, we may relabel $ Y $ as $ X^{-1} $. Then the multiplication rule will be what the notation leads us to expect. So we can write
$$ k\sbr{V} = k\sbr{X, X^{-1}} = \cbr{\sum_{j = -n}^m a_jX^m \st a_{-n}, \dots, a_m \in k, \ m, n \in \NN}. $$
\end{itemize}
\end{example*}

\begin{lemma}
An affine algebraic set $ V $ is irreducible if and only if $ k\sbr{V} $ is an integral domain.
\end{lemma}

\begin{proof}
$ V $ is irreducible if and only if $ \II\br{V} $ is a prime ideal in $ k\sbr{X_1, \dots, X_n} $.
\end{proof}

\subsubsection{Regular maps}

A regular function goes from an algebraic set $ V $ to the field $ k $. We can also define regular maps, which go from one algebraic set $ V $ to another algebraic set $ W $.

\begin{definition*}
Let $ V \subseteq \AA^m $ and $ W \subseteq \AA^n $ be affine algebraic sets. A \textbf{regular map} $ \phi : V \to W $ is a function $ V \to W $ such that there exist polynomials $ F_1, \dots, F_n \in k\sbr{X_1, \dots, X_n} $ such that $ \phi\br{\underline{x}} = \br{F_1\br{\underline{x}}, \dots, F_n\br{\underline{x}}} $ for all $ \underline{x} \in V $. Regular maps are often called \textbf{morphisms}.
\end{definition*}

\begin{note*}
In order to check that a given list of polynomials $ F_1, \dots, F_n $ defines a regular map $ V \to W $, it is necessary to check that $ \br{F_1\br{\underline{x}}, \dots, F_n\br{\underline{x}}} \in W $ for every $ \underline{x} \in V $. Equivalently, we need to check that the regular functions $ \eval{F_1}_V, \dots, \eval{F_n}_V \in k\sbr{V} $ satisfy the equations $ g\br{\eval{F_1}_V, \dots, \eval{F_n}_V} = 0 $ in the coordinate ring $ k\sbr{V} $, for each polynomial $ g \in \II\br{W} $.
\end{note*}

\pagebreak

\begin{example*}
\hfill
\begin{itemize}
\item Let $ V \subseteq \AA^m $ be an affine algebraic set. For any $ n < m $, the projection defined by
$$ \function[\pi]{V}{\AA^n}{\br{x_1, \dots, x_m}}{\br{x_1, \dots, x_n}} $$
is a regular map.
\item A regular function on $ V $ is the same thing as a regular map $ V \to \AA^1 $.
\item Let $ C = \cbr{\br{x, y} \st y^2 = x^3} $. Then
$$ \function{\AA^1}{C}{t}{\br{t^2, t^3}} $$
is a regular map.
\item Consider $ \SL_n $, the set of $ n \times n $ matrices with determinant one. This is an affine algebraic set in $ \AA^{n^2} $ because the determinant is a polynomial in the entries of a matrix. The map
$$ \function{\SL_n}{\SL_n}{a}{a^{-1}} $$
is a regular map. Cramer's rule tells us how to write each entry of $ a^{-1} $ as a polynomial in the entries of $ a $ divided by $ \det a $, and because we are only considering $ a \in \SL_n $ we can drop the division by $ \det a $.
\end{itemize}
\end{example*}

A regular map $ \phi : V \to W $ is a continuous function with respect to the Zariski topology. This is because, if $ A \subseteq W $ is a Zariski closed subset defined by polynomials $ f_1, \dots, f_r $, then $ \phi^{-1}\br{A} $ is the zero set
$$ \phi^{-1}\br{A} = \cbr{x \in V \st \br{f_1 \circ \phi}\br{x} = 0, \ \dots, \ \br{f_r \circ \phi}\br{x} = 0}, $$
and therefore $ \phi^{-1}\br{A} $ is a Zariski closed subset of $ V $. In complex analysis, holomorphic is a much stricter condition than continuous in the Euclidean topology, and similarly regular is much stricter than continuous in the Zariski topology. The following fact is very useful.

\begin{lemma}
\label{lem:regulardense}
Let $ \phi, \psi : V \to W $ be regular maps. If there exists a Zariski dense subset $ A \subseteq V $ such that $ \eval{\phi}_A = \eval{\psi}_A $, then $ \phi = \psi $ on all of $ V $.
\end{lemma}

\begin{note*}
If $ X $ and $ Y $ are Hausdorff topological spaces, then any continuous maps $ X \to Y $ which agree on a dense set must agree everywhere. However Lemma \ref{lem:regulardense} does not follow immediately from the fact that regular maps are continuous, because the Zariski topology is not Hausdorff, and is definitely false if we try to generalise it to all continuous maps with respect to the Zariski topology. Thus in order to prove Lemma \ref{lem:regulardense}, we have to use something special about regular maps as opposed to general continuous maps.
\end{note*}

\begin{proof}
Write $ \phi = \br{F_1, \dots, F_m} $ and $ \psi = \br{G_1, \dots, G_m} $, where $ F_1, \dots, F_m, G_1, \dots, G_m $ are polynomials. Then $ F_i - G_i $ is also a polynomial for each $ i $, and so
$$ V' = \cbr{\underline{x} \in V \st \phi\br{\underline{x}} = \psi\br{\underline{x}}} = \cbr{\underline{x} \in V \st \forall i, \ \br{F_i - G_i}\br{\underline{x}} = 0} $$
is a Zariski closed subset of $ V $. But we know that $ V' $ contains $ A $, which is Zariski dense in $ V $. Hence $ V' = V $.
\end{proof}

\subsubsection{Isomorphisms}

\lecture{7}{Monday}{27/01/20}

\begin{definition*}
A regular map $ \phi : V \to W $ is an \textbf{isomorphism} if there exists a regular map $ \psi : W \to V $ such that $ \psi \circ \phi = \id_V $ and $ \phi \circ \psi = \id_W $.
\end{definition*}

\begin{example*}
If $ V $ is the parabola $ \cbr{\br{x, y} \st y - x^2 = 0} $, then the regular map given by
$$ \function[\phi]{V}{\AA^1}{\br{x, y}}{x} $$
is an isomorphism because it has an inverse given by
$$ \function[\psi]{\AA^1}{V}{x}{\br{x, x^2}}. $$
\end{example*}

\pagebreak

\begin{example*}
On the other hand, if $ H $ is the hyperbola $ \cbr{\br{x, y} \st xy = 1} $, then the projection
$$ \function{H}{\AA^1}{\br{x, y}}{x} $$
is not an isomorphism because it is not surjective so it cannot possibly have an inverse. This is not enough to prove that $ H $ is not isomorphic to $ \AA^1 $, because maybe there is some other regular map $ H \to \AA^1 $ which is an isomorphism. We will soon prove that $ H $ is not isomorphic to $ \AA^1 $.
\end{example*}

\begin{example*}
Consider the affine algebraic set $ W = \cbr{\br{x, y} \st y^2 - x^3 = 0} $. The regular map given by
$$ \function[\phi]{\AA^1}{W}{t}{\br{t^2, t^3}} $$
is a bijection but it is not an isomorphism. Note that we should expect $ W $ not to be isomorphic to $ \AA^1 $ because it has a singularity at the origin. To prove that $ \phi : \AA^1 \to W $ is not an isomorphism, consider a regular map $ \psi : W \to \AA^1 $. It must be given by a polynomial $ g\br{X, Y} \in k\sbr{X, Y} $ and so $ \br{\psi \circ \phi}\br{t} = \psi\br{t^2, t^3} $ is a polynomial in $ t $ which can have a constant term and terms of degree two or greater, but no term of degree one. Hence we cannot find $ \psi $ such that $ \br{\psi \circ \phi}\br{t} = t $.
\end{example*}

\subsubsection{Regular maps and \texorpdfstring{$ k $}{k}-algebra homomorphisms}

Suppose we have a regular map $ \phi : V \to W $ between affine algebraic sets. For each regular function $ g $ on $ W $, we get a regular function $ \phi^*g $ on $ V $ defined by
$$ \function[\phi^*]{k\sbr{W}}{k\sbr{V}}{g}{g \circ \phi}. $$
We call $ \phi^*g \in k\sbr{V} $ the \textbf{pull-back} of $ g \in k\sbr{W} $. Thus $ \phi $ induces a $ k $-algebra homomorphism $ \phi^* : k\sbr{W} \to k\sbr{V} $.

\begin{note*}
$ \phi^* $ goes in the opposite direction to $ \phi $.
\end{note*}

If we have two regular maps $ \phi : V \to W $ and $ \psi : W \to Z $, then we can compose them to get $ \psi \circ \phi : V \to Z $. One can easily check that the associated pull-back maps on coordinate rings satisfy
$$ \br{\psi \circ \phi}^* = \phi^* \circ \psi^* : k\sbr{Z} \to k\sbr{V}. $$
For those who know category theory, we say that $ V \mapsto k\sbr{V} $ is a contravariant functor
$$ \cbr{\text{affine algebraic sets}} \to \cbr{\text{$ k $-algebras}}. $$
In particular, this tells us that if $ \phi : V \to W $ is an isomorphism with inverse $ \psi : W \to V $, then $ \psi^* \circ \phi^* = \id $ and $ \phi^* \circ \psi^* = \id $. Thus if $ V $ and $ W $ are isomorphic affine algebraic sets, then their coordinate rings $ k\sbr{V} $ and $ k\sbr{W} $ are isomorphic as $ k $-algebras.

\begin{example*}
Now we can prove that the hyperbola $ H $ is not isomorphic to $ \AA^1 $, because $ k\sbr{H} = k\sbr{X, X^{-1}} $ is not isomorphic to $ k\sbr{\AA^1} = k\sbr{X} $. To verify that these $ k $-algebras are not isomorphic, observe that in $ k\sbr{X} $ the only invertible elements are the scalars, while $ k\sbr{X, X^{-1}} $ contains non-scalar invertible elements, such as $ X $.
\end{example*}

\begin{example*}
We can similarly prove that $ \AA^1 $ is not isomorphic to the singular cubic $ W = \cbr{\br{x, y} \st y^2 = x^3} $. We saw earlier that $ k\sbr{W} $ is the ring of polynomials in one variable with no term of degree one, that is
$$ k\sbr{W} = \cbr{a_0 + \sum_{r = 2}^m a_rX^r \st a_0, a_2, \dots, a_m \in k}. $$
To prove that $ k\sbr{W} $ is not isomorphic to $ k\sbr{\AA^1} = k\sbr{X} $, observe that $ k\sbr{X} $ is a unique factorisation domain but $ k\sbr{W} $ is not because $ \abr{X^2}^3 = \abr{X^3}^2 $, and $ X^2 $ and $ X^3 $ are both irreducible in $ k\sbr{W} $.
\end{example*}

\pagebreak

\subsubsection{Rational functions}

Informally, rational functions are functions on varieties defined by polynomial fractions, for example the function $ x \mapsto 1 / x $ on $ \AA^1 $. Observe that this is not really a function $ \AA^1 \to \AA^1 $ because it is not defined at $ x = 0 $, but it is a genuine function on the Zariski open subset $ \AA^1 \setminus \cbr{0} $. These are analogues of meromorphic functions in complex analysis. Just as with regular functions and regular maps, we first define rational functions, which take values in $ k $, then rational maps, which go into any algebraic set. We make this definition only for irreducible affine algebraic sets because, as we saw in the example of $ 1 / x $, a rational function defines a genuine function on a Zariski open subset of $ V $, and irreducibility guarantees that all open subsets of $ V $ are dense in $ V $, so that a function defined on an open subset really is defined almost everywhere on $ V $.

\begin{definition*}
Let $ V $ be an irreducible affine algebraic set. The \textbf{function field} of $ V $ is the field of fractions of the coordinate ring $ k\sbr{V} $. We denote this by $ k\br{V} $.
\end{definition*}

\begin{note*}
$ k\sbr{V} $ is an integral domain because $ V $ is irreducible, and therefore $ k\sbr{V} $ has a field of fractions.
\end{note*}

\begin{example*}
The function field of $ \AA^1 $ is $ k\br{X} $, the fraction field of the polynomial ring $ k\sbr{X} $.
\end{example*}

\begin{definition*}
A \textbf{rational function} on $ V $ is an element of the function field $ k\br{V} $. Thus a rational function can be written in the form $ f / g $, where $ f $ and $ g $ are regular functions. There may be many different choices for $ f $ and $ g $ which define the same rational function $ f / g $.
\end{definition*}

\begin{definition*}
We say that a rational function $ \phi \in k\br{V} $ is \textbf{regular} at a point $ x \in V $ if there exist regular functions $ f, g \in k\sbr{V} $ such that $ \phi = f / g $ and $ g\br{x} \ne 0 $.
\end{definition*}

Thus regular points are precisely the points at which we can assign a value to $ \phi\br{x} $. If $ g\br{x} \ne 0 $, then we can define $ \phi\br{x} = f\br{x} / g\br{x} $.

\begin{note*}
We are allowed to choose different fractions $ f / g $ representing $ \phi $ at different points $ x \in V $, in order to show that those points are regular. The value $ \phi\br{x} $ is independent of which fraction representing $ \phi $ we choose, as long as it has $ g\br{x} \ne 0 $.
\end{note*}

\begin{example*}
Consider the algebraic set defined by the equation $ XY = ZT $ in $ \AA^4 $. Let $ \phi = X / Z \in k\br{V} $. The defining equation implies that we also have $ \phi = T / Y $. Looking at the fraction $ X / Z $ shows us that $ \phi $ is regular wherever $ Z \ne 0 $, and looking at the fraction $ T / Y $ shows us that $ \phi $ is regular wherever $ Y \ne 0 $. On the other hand, $ \phi $ is not regular on the closed subset $ Y = Z = 0 $. One can verify that there is no other fraction representing $ \phi $ which is non-zero on this closed subset.
\end{example*}

\lecture{8}{Thursday}{30/01/20}

Let $ V $ be an irreducible affine algebraic set. Let $ \phi \in k\br{V} $ be a rational function.

\begin{definition*}
The set of points where $ \phi $ is regular is called the \textbf{domain of definition} of $ \phi $, and denoted $ \dom \phi $.
\end{definition*}

This is the set of points where it makes sense to assign a value to $ \phi\br{x} $. For $ x \in \dom \phi $, the value $ \phi\br{x} $ is independent of which fraction $ f / g $ we choose to represent $ \phi $, as long as $ g\br{x} \ne 0 $.

\begin{lemma}
The domain of definition of a rational function $ \phi \in k\br{V} $ is a non-empty Zariski open subset of $ V $.
\end{lemma}

\begin{proof}
Consider the set of all possible fractions $ f / g $ with $ f, g \in k\sbr{V} $ representing $ \phi \in k\br{V} $. The set of points at which $ \phi $ is not regular is the intersection of the Zariski closed sets $ \cbr{x \in V \st g\br{x} = 0} $ across all these fractions. Hence the set of points at which $ \phi $ is not regular is a Zariski closed subset of $ V $. The domain of definition is the complement of this set, and therefore is Zariski open. To show that the domain of definition is non-empty, pick a single fraction $ f / g $ representing $ \phi \in k\br{V} $. The regular function $ g $ is not equal to zero as an element of $ k\sbr{V} $, by the definition of the field of fractions, so $ \cbr{x \in V \st g\br{x} = 0} $ is a proper closed subset of $ V $. The domain of definition contains the complement of this set, namely $ \cbr{x \in V \st g\br{x} \ne 0} $, and hence is non-empty.
\end{proof}

\begin{note*}
Every regular function $ f \in k\sbr{V} $ is also a rational function $ f / 1 \in k\br{V} $, and its domain of definition is all of $ V $.
\end{note*}

\pagebreak

The converse also holds.

\begin{lemma}
Let $ \phi \in k\br{V} $ be a rational function whose domain of definition is equal to $ V $. Then $ \phi $ is a regular function on $ V $.
\end{lemma}

\begin{proof}
Since $ \dom \phi = V $, for each point $ x \in V $, we can choose regular functions $ f_x, g_x \in k\sbr{V} $ such that $ \phi = f_x / g_x $ and $ g_x\br{x} \ne 0 $. Let $ I \subseteq k\sbr{V} $ denote the ideal generated by the functions $ g_x $. Because $ k\sbr{V} $ is Noetherian, we can pick finitely many of these functions $ g_{x_1}, \dots, g_{x_m} $ which still generate $ I $. For each $ x \in V $, there is some $ g_x \in I $ which is non-zero at $ x $. Hence the Zariski closed subset of $ V $ defined by $ \cbr{x \in V \st \forall h \in I, \ h\br{x} = 0} $ is empty. Then the Nullstellensatz implies that $ I $ is all of $ k\sbr{V} $. In particular, $ 1 \in I $. Since $ I = \abr{g_{x_1}, \dots, g_{x_m}} $, there exist $ u_1, \dots, u_m \in k\sbr{V} $ such that $ 1 = u_1g_{x_1} + \dots + u_mg_{x_m} $ in $ k\sbr{V} $. We can now calculate
$$ \phi = \br{u_1g_{x_1} + \dots + u_mg_{x_m}}\phi = u_1g_{x_1}\dfrac{f_{x_1}}{g_{x_1}} + \dots + u_mg_{x_m}\dfrac{f_{x_m}}{g_{x_m}} = u_1f_{x_1} + \dots + u_mf_{x_m}. $$
Since $ u_i, f_{x_i} \in k\sbr{V} $, so is $ \phi $. Note that it might appear that we have only proved the above equation $ \phi = u_1f_{x_1} + \dots + u_mf_{x_m} $ on a Zariski open subset of $ V $, namely the intersections of the domains of definition of $ f_{x_1} / g_{x_1}, \dots, f_{x_m} / g_{x_m} $. Because $ V $ is irreducible, this open subset must be dense, but the subset where an equation of polynomials holds is closed, so it is equal to all of $ V $.
\end{proof}

\subsubsection{Rational maps}

Let $ V \subseteq \AA^m $ and $ W \subseteq \AA^n $ be irreducible affine algebraic sets.

\begin{definition*}
A \textbf{rational map} $ \phi : V \dashrightarrow W $ is an $ n $-tuple of rational functions $ \phi_1, \dots, \phi_n \in k\br{V} $ such that, for every point $ x \in V $ where $ \phi_1, \dots, \phi_n $ are all regular, the point $ \br{\phi_1\br{x}, \dots, \phi_n\br{x}} $ is in $ W $.
\end{definition*}

We use the broken arrow symbol instead of the usual arrow because a rational map is not a function on $ V $ in the usual set-theoretic sense. It only defines a genuine function $ U \to W $, where $ U $ is the domain of definition of $ \phi $. This is defined as follows.

\begin{definition*}
The \textbf{domain of definition} of a rational map $ \phi : V \dashrightarrow W $ is the intersection of the domains of definition of the component rational functions $ \br{\phi_1, \dots, \phi_n} $.
\end{definition*}

The two lemmas we proved for rational functions also hold for rational maps. The domain of definition of a rational map $ \phi : V \dashrightarrow W $ is a non-empty Zariski open subset of $ V $, and if a rational map is regular everywhere then it is a regular map. In order to prove that the domain of definition of a rational map is non-empty, we have to use the fact that $ V $ is irreducible, and therefore every open subset of $ V $ is dense.

\begin{example*}
An important example of a rational map is the projection from a point onto a hyperplane. Let $ H $ be a hyperplane in $ \AA^n $, that is a set defined by a single linear equation. Let $ p $ be a point in $ \AA^n \setminus H $. For simplicity, we shall assume that $ p $ is the origin and that
$$ H = \cbr{\br{x_1, \dots, x_n} \in \AA^n \st x_n = 1}. $$
We could always reduce to this case by a suitable change of coordinates. Let us write $ H_p $ for the hyperplane through $ p $ parallel to $ H $, that is
$$ H_p = \cbr{\br{x_1, \dots, x_n} \in \AA^n \st x_n = 0}. $$
For each point $ x \in \AA^n \setminus H_p $, let $ L_x $ denote the line which passes through $ p $ and $ x $. Since $ x \notin H_p $, $ L_x $ intersects $ H $ in exactly one point. Call this point $ \phi\br{x} $. We can write this algebraically as
$$ \rational[\phi]{\AA^n}{H}{\br{x_1, \dots, x_n}}{\br{\dfrac{x_1}{x_n}, \dots, \dfrac{x_{n - 1}}{x_n}, 1}}, $$
and so $ \phi $ is a rational map. This map is called the \textbf{projection from $ p $ onto $ H $}. We have $ \dom \phi = \AA^n \setminus H_p $. Note that we have not proved this, because we have not proved that there is no other list of fractions which define the same rational map but have non-zero denominators at points in $ H_p $. One can prove this. For any affine algebraic set $ V \subseteq \AA^n $ such that $ V \not\subseteq H_p $, we can restrict $ \phi $ to get a rational map $ V \dashrightarrow H $. Note that $ p $ might be in $ V $, or it might not.
\end{example*}

\pagebreak

\begin{example*}
Let $ V $ be the circle $ \cbr{\br{x, y} \st x^2 + y^2 = 1} $. Consider the projection from the point $ p = \br{1, 0} $ on to the line $ x = 0 $. This is a rational map with the formula
$$ \rational[\pi]{V}{\AA^1}{\br{x, y}}{\dfrac{y}{1 - x}}. $$
We can see geometrically that this projection induces a bijection between the circle, excluding $ p $, and the line, at least for real points. If we compute the formula for the inverse map, we get
$$ \rational[\psi]{\AA^1}{V}{t}{\br{\dfrac{t^2 - 1}{t^2 + 1}, \dfrac{2t}{t^2 + 1}}}, $$
a well-known parameterisation of the circle. Thus we see that the inverse is a rational map. Note that $ \psi $ is not regular at $ t = \pm i $. We do not see this on the picture, which only shows the real points.
\end{example*}

We would like to define formally what it means to say that the rational maps $ \pi $ and $ \psi $ are inverse to each other, taking into account that they are not true functions between the sets $ V $ and $ \AA^1 $ because they are not regular everywhere. These maps are inverses in that composing them, either way round, gives the identity, if we ignore the points where the maps are not regular.

\subsubsection{Birational equivalences}

\lecture{9}{Friday}{31/01/20}

In order to do this, we first define what it means to compose rational maps. But it does not always make sense to compose rational maps. In order to rigorously define composition of rational maps, we need to notice that sometimes the set of points where a composite map is undefined is everywhere and exclude that situation.

\begin{example*}
Consider the rational map defined by
$$ \rational[\xi]{\AA^2}{\AA^1}{\br{x, y}}{\dfrac{1}{1 - x^2 - y^2}}. $$
This map is not regular anywhere on the circle $ V $, and hence it does not make sense to try to define the composite map $ \xi \circ \psi : \AA^1 \dashrightarrow \AA^1 $, since it is not defined anywhere.
\end{example*}

This problem can occur because the image of $ \psi $ is not dense in $ \AA^2 $. So to rule it out this problem, we make the following definition of dominant rational maps.

\begin{definition*}
The \textbf{image} of a rational map $ \phi : V \dashrightarrow W $ is the set of points
$$ \cbr{\phi\br{x} \in W \st x \in \dom \phi}. $$
A rational map is \textbf{dominant} if its image is Zariski dense in $ W $.
\end{definition*}

\begin{example*}
$ \psi $ from the end of the previous lecture is dominant if we consider it as a rational map $ \AA^1 \dashrightarrow V $ but it is not dominant if we consider it as a rational map $ \AA^1 \dashrightarrow \AA^2 $. This is like surjectivity. Whether a function is surjective or not depends on what codomain you declare it to have.
\end{example*}

Let $ V, W, T $ be irreducible affine algebraic sets. If $ \phi : V \dashrightarrow W $ is a dominant rational map and $ \psi : W \dashrightarrow T $ is a rational map, where $ \psi $ is not required to be dominant, then it makes sense to compose them because we know that $ \dom \psi $ is a Zariski open subset of $ W $, while $ \Im \phi $ is a Zariski dense subset of $ W $ and so $ \dom \psi \cap \Im \phi \ne \emptyset $. Thus there are at least some points where $ \psi \circ \phi $ is defined. One can check, by writing out $ \psi $ in terms of fractions of polynomials, then substituting in fractions of polynomials representing $ \phi $, that $ \psi \circ \phi $ is a rational map $ V \dashrightarrow T $.

\begin{definition*}
Rational maps $ \phi : V \dashrightarrow W $ and $ \psi : W \to V $ are \textbf{rational inverses} if both are dominant and $ \phi \circ \psi = \id_W $ and $ \psi \circ \phi = \id_V $, everywhere these composite rational maps are well-defined. A rational map $ \phi : V \dashrightarrow W $ is a \textbf{birational equivalence} if it is dominant and has a rational inverse. We say that irreducible algebraic sets $ V $ and $ W $ are \textbf{birational}, or \textbf{birationally equivalent}, if there exists a birational equivalence $ V \dashrightarrow W $.
\end{definition*}

\begin{example*}
Our example from the previous lecture showed that the circle is birational to $ \AA^1 $.
\end{example*}

\pagebreak

\begin{example*}
Another example is the cuspidal cubic $ W = \cbr{\br{x, y} \st y^2 = x^3} $. This is also birational to $ \AA^1 $, as shown by the rational maps
$$ \birational{W}{\AA^1}{\br{x, y}}{\dfrac{y}{x}}{\br{t^2, t^3}}{t}. $$
\end{example*}

Birationally equivalent affine algebraic sets look the same almost everywhere.

\begin{example*}
The cuspidal cubic is the same as the affine line everywhere except at the origin.
\end{example*}

\begin{example*}
$ \AA^1 $ is not birationally equivalent to $ \AA^2 $ or to an elliptic curve $ \cbr{\br{x, y} \st y^2 = f\br{x}} $ where $ f $ is a cubic polynomial with no repeated roots. We will prove this later in the course once we have more tools.
\end{example*}

\subsubsection{Dominant rational maps and \texorpdfstring{$ k $}{k}-field homomorphisms}

If $ \phi : V \dashrightarrow W $ is a dominant rational map, then we can use it to pull back rational functions from $ W $ to $ V $, just like we earlier used regular maps to pull back regular functions. We get a $ k $-homomorphism of fields defined by
$$ \function[\phi^*]{k\br{W}}{k\br{V}}{g}{g \circ \phi}. $$
A \textbf{$ k $-homomorphism} means that $ \phi^* $ restricts to the identity on the copies of $ k $ which are contained in $ k\br{W} $ and $ k\br{V} $, namely the constant functions. If $ \phi $ is a birational equivalence, then $ \phi^* $ is a $ k $-isomorphism of fields.

\subsection{Equivalence of algebra and geometry}

\subsubsection{From algebra homomorphisms to regular maps}

We have seen that each regular map $ f : V \to W $ induces a $ k $-algebra homomorphism $ f^* : k\sbr{W} \to k\sbr{V} $, and that each dominant rational map $ \phi : V \dashrightarrow W $ induces a $ k $-field homomorphism $ \phi^* : k\br{W} \to k\br{V} $. We can also carry out these constructions in the reverse direction. Starting with a $ k $-algebra homomorphism and getting a regular map, or similarly for rational maps. Observe that if $ f : V \to W $ is a regular map and $ W \subseteq \AA^n $, we can recover $ f $ from $ f^* : k\sbr{W} \to k\sbr{V} $ by taking the coordinate functions $ X_1, \dots, X_n \in k\sbr{W} $ on $ W $ and pulling them back to get $ f_1 = f^*\br{X_1}, \dots, f_n = f^*\br{X_n} \in k\sbr{V} $. These are precisely the regular functions on $ V $ such that $ f = \br{f_1, \dots, f_n} $. We generalise this procedure for any $ k $-algebra homomorphism $ \alpha : k\sbr{W} \to k\sbr{V} $. Starting from an arbitrary k-algebra homomorphism $ \alpha : k\sbr{W} \to k\sbr{V} $, we define a regular map $ s : V \to W $ by
$$ s = \br{\alpha\br{X_1}, \dots, \alpha\br{X_n}}. $$
Here $ \alpha\br{X_1}, \dots, \alpha\br{X_n} \in k\sbr{V} $. Then $ \alpha = s^* : k\sbr{W} \to k\sbr{V} $. Thus every $ k $-algebra homomorphism $ k\sbr{W} \to k\sbr{V} $ is the pull-back by some regular map $ V \to W $. We conclude the following.

\begin{proposition}
$ \phi \mapsto \phi^* $ is a bijection
$$ \cbr{\text{regular maps} \ V \to W} \to \cbr{\text{$ k $-algebra homomorphisms} \ k\sbr{W} \to k\sbr{V}}. $$
\end{proposition}

\begin{corollary}
Affine algebraic sets $ V $ and $ W $ are isomorphic if and only if their coordinate rings $ k\sbr{V} $ and $ k\sbr{W} $ are isomorphic as $ k $-algebras.
\end{corollary}

The moral is that if we only care about affine algebraic sets up to isomorphism, then coordinate rings contain exactly the same information as algebraic sets themselves. In the language of category theory, the functor $ V \to k\sbr{V} $ is fully faithful. One can do the same thing for rational maps.

\begin{proposition}
$ \phi \mapsto \phi^* $ is a bijection
$$ \cbr{\text{dominant rational maps} \ V \dashrightarrow W} \to \cbr{\text{$ k $-field homomorphisms} \ k\br{W} \to k\br{V}}. $$
\end{proposition}

\begin{corollary}
\label{cor:algebrageometry}
Irreducible affine algebraic sets $ V $ and $ W $ are birationally equivalent if and only if their function fields $ k\br{V} $ and $ k\br{W} $ are $ k $-isomorphic.
\end{corollary}

\pagebreak

\subsubsection{Dictionary between algebraic subsets and ideals}

Can we do something similar with Zariski closed subsets of $ V $, and work them out from the algebra of $ k\sbr{V} $? Suppose that $ V \subseteq \AA^n $. In $ \AA^n $, the Nullstellensatz tells us that the functions $ \II $ and $ \VV $ are bijections
$$ \correspondence{\text{Zariski closed subsets of} \ \AA^n}{\text{radical ideals in} \ k\sbr{X_1, \dots, X_n}}. $$
Since $ \II $ and $ \VV $ reverse the direction of inclusions, we deduce that they restrict to bijections
$$ \correspondence{\text{Zariski closed subsets of} \ V}{\text{radical ideals in} \ k\sbr{X_1, \dots, X_n} \ \text{containing} \ \II\br{V}}. $$
We know that $ k\sbr{V} \cong k\sbr{X_1, \dots, X_n} / \II\br{V} $. It is a basic algebraic fact that
$$ \correspondence{\text{ideals in} \ k\sbr{X_1, \dots, X_n} \ \text{containing} \ \II\br{V}}{\text{ideals in} \ k\sbr{X_1, \dots, X_n} / \II\br{V}}. $$
Under this correspondence, radical ideals on one side correspond to radical ideals on the other side and similarly for prime ideals. We conclude that the natural maps are bijections
$$ \correspondence{\text{Zariski closed subsets of} \ V}{\text{radical ideals in} \ k\sbr{V}}, $$
and
$$ \correspondence{\text{irreducible Zariski closed subsets of} \ V}{\text{prime ideals in} \ k\sbr{V}}. $$
Can we describe the points of an affine algebraic set $ V $ in terms of the algebra of $ k\sbr{V} $? The points of $ V $ are the smallest non-empty Zariski closed subsets. Since the bijection between Zariski closed subsets and ideals reverses direction of inclusion, they correspond to maximal ideals, so
$$ \correspondence{\text{points of} \ V}{\text{maximal ideals in} \ k\sbr{V}}. $$

\lecture{10}{Monday}{03/02/20}

Lecture 10 is a problems class.

\subsubsection{Reduced finitely generated \texorpdfstring{$ k $}{k}-algebras}

\lecture{11}{Thursday}{06/02/20}

We have seen that $ V \mapsto k\sbr{V} $ leads to bijections on maps between affine algebraic sets. To fully understand the relationship between affine algebraic sets and $ k $-algebras, there is one more question to answer. Which $ k $-algebras can occur as $ k\sbr{V} $ where $ V $ is an affine algebraic set? We write down some algebraic properties which obviously hold for $ A = k\sbr{V} $, the coordinate ring of an affine algebraic set $ V $.
\begin{itemize}
\item $ A $ is finitely generated, because if $ V \subseteq \AA^n $ then $ A $ is generated by the coordinate functions $ X_1, \dots, X_n $.
\item $ A $ is reduced, meaning that if $ f \in A $ and $ f^k = 0 $ for some $ k > 0 $, then $ f = 0 $. This is because $ A $ is a ring of functions in the usual set-theoretic sense. If $ f^k = 0 $ then $ f\br{x}^k = 0 $ for all $ x \in V $, so $ f\br{x} = 0 $ for all $ x \in V $.
\end{itemize}
Using the Nullstellensatz, we can prove that these properties are enough to characterise the $ k $-algebras which are coordinate rings of affine algebraic sets.

\begin{proposition}
\label{prop:kva}
Let $ A $ be a finitely generated reduced $ k $-algebra. Then there exists an affine algebraic set $ V $ such that $ k\sbr{V} \cong A $.
\end{proposition}

\begin{proof}
Pick a finite set $ f_1, \dots, f_n \in A $ which generates $ A $ as a $ k $-algebra. We can define a homomorphism
$$ \function[\alpha]{k\sbr{X_1, \dots, X_n}}{A}{\br{X_1, \dots, X_n}}{\br{f_1, \dots, f_n}}. $$
Let $ I = \Ker \phi $ and let $ V = \VV\br{I} \subseteq \AA^n $. The homomorphism $ \alpha $ is surjective because $ f_1, \dots, f_n $ generate $ A $, and so $ A \cong k\sbr{X_1, \dots, X_n} / I $. Thus $ k\sbr{X_1, \dots, X_n} / I $ is a reduced $ k $-algebra. It follows that $ I $ is a radical ideal. Hence the Nullstellensatz tells us that $ I = \II\br{V} $. Thus
$$ k\sbr{V} \cong k\sbr{X_1, \dots, X_n} / \II\br{V} \cong k\sbr{X_1, \dots, X_n} / I \cong A. $$
\end{proof}

\pagebreak

\subsubsection{The notion of an affine variety}

Often in mathematics, it is convenient to consider objects only up to isomorphism.

\begin{example*}
One might talk about the group with seven elements, ignoring the fact that there are many different groups with seven elements because they are all isomorphic to each other, and therefore they all behave in the same ways.
\end{example*}

Similarly, in algebraic geometry we often want to consider affine algebraic sets up to isomorphism. But affine algebraic sets are always defined in a concrete way. They are a subset of some specific affine space $ \AA^n $. It is as if we had defined all finite groups to be subgroups of a symmetric group $ \SSS_n $. And we have seen that affine algebraic sets can be isomorphic even when they appear to be quite different as subsets of affine space.

\begin{example*}
The line $ \AA^1 $ is isomorphic to the parabola $ \VV\br{Y - X^2} \subseteq \AA^2 $.
\end{example*}

Thus it is useful to use different terminology. We talk about affine algebraic sets when we mean subsets of $ \AA^n $, and we talk about \textbf{affine varieties} when we mean an affine algebraic set up to isomorphism, forgetting its embedding into $ \AA^n $. Proposition \ref{prop:kva} is more naturally stated in terms of affine varieties rather than affine algebraic sets. In the proof we had to choose a generating set for $ A $, for which there is no distinguished choice. Different choices of generating set would lead to isomorphic affine algebraic sets, but embedded differently into affine space. So it is better to say that each finitely generated reduced $ k $-algebra $ A $ is the coordinate ring of some affine variety $ V $, with no distinguished choice of embedding into $ \AA^n $. I mentioned this philosophy about affine varieties before, and I will mention it again after we have defined quasi-projective varieties. For those who know some fancy categorical language, we can sum up all the results on the equivalence between affine geometric objects and their coordinate rings by saying that $ V \mapsto k\sbr{V} $ is an equivalence of categories
$$ \cbr{\text{affine varieties over} \ k} \to \cbr{\text{reduced finitely generated $ k $-algebras}}^{\op}, $$
where the superscript $ \op $ indicates that the directions of morphisms are reversed. Let $ A $ be a reduced finitely generated $ k $-algebra and $ V $ an affine variety such that $ A \cong k\sbr{V} $. How can we work out the geometry of $ V $ from the algebra of $ A $? If we choose an embedding of $ V $ into $ \AA^n $, then we get an isomorphism $ k\sbr{X_1, \dots, X_n} / \II\br{V} \to A $. We conclude that
$$ \correspondence{\text{Zariski closed subsets of} \ V}{\text{radical ideals in} \ A}, $$
$$ \correspondence{\text{irreducible Zariski closed subsets of} \ V}{\text{prime ideals in} \ A}, $$
$$ \correspondence{\text{points of} \ V}{\text{maximal ideals in} \ A}. $$

\subsubsection{The weak and strong Nullstellensatz}

Now we aim to prove Hilbert's Nullstellensatz. There are many different proofs, all of which require some difficult algebra. We will roughly follow the method in Shafarevich appendix A, which incorporates the hard algebra into one statement which we can quote, and then do the rest as geometrically as possible. Recall the statement of Hilbertâ€™s Nullstellensatz, Theorem \ref{thm:strongnullstellensatz}, also called the strong Nullstellensatz. In order to prove this, we will first prove a weaker version, which is called the weak Nullstellensatz, then use that to deduce the strong Nullstellensatz.

\begin{theorem}[Weak Nullstellensatz]
Let $ I $ be an ideal in the polynomial ring $ k\sbr{X_1, \dots, X_n} $ over an algebraically closed field $ k $. If $ \VV\br{I} = \emptyset $, then $ I = k\sbr{X_1, \dots, X_n} $.
\end{theorem}

This is a statement about the existence of solutions to polynomial equations, so it is necessary to require $ k $ to be algebraically closed.

\begin{example*}
To show that it fails when $ k $ is not algebraically closed, consider the ideal $ \abr{X^2 + Y^2 + 1} $ in $ \RR\sbr{X, Y} $. This ideal is not the full polynomial ring, but there are no real solutions to the equation $ x^2 + y^2 + 1 = 0 $.
\end{example*}

\begin{note*}
The strong Nullstellensatz easily implies the weak Nullstellensatz. If $ \VV\br{I} = \emptyset $ then the strong Nullstellensatz tells us that $ \rad I = \II\br{\emptyset} = k\sbr{X_1, \dots, X_n} $. In particular, $ 1 \in \rad I $ but then $ 1 \in I $ so $ I = k\sbr{X_1, \dots, X_n} $.
\end{note*}

\pagebreak

\begin{proof}[Proof of Theorem \ref{thm:strongnullstellensatz}]
We use a method called the Rabinowitsch trick, introducing an extra variable. Let $ I $ be an ideal in $ k\sbr{X_1, \dots, X_n} $ and let $ V = \VV\br{I} \subseteq \AA^n $. It is easy to see that $ \rad I \subseteq \II\br{V} $. Thus we have to prove that $ \II\br{V} \subseteq \rad I $. Let $ f \in \II\br{V} $. Define a new polynomial $ g $ with an extra variable $ Y $ by
$$ g\br{X_1, \dots, X_n, Y} = f\br{X_1, \dots, X_n} \cdot Y - 1. $$
Let $ J $ be the ideal in $ k\sbr{X_1, \dots, X_n, Y} $ generated by $ I $ and $ g $, and consider the affine algebraic set $ W = \VV\br{J} \subseteq \AA^{n + 1} $. Every point $ \br{x_1, \dots, x_n, y} \in W $ satisfies $ f\br{x_1, \dots, x_n} \ne 0 $, in order for there to exist some $ y $ such that $ f\br{x_1, \dots, x_n}y - 1 = 0 $. This is generalising the fact that the hyperbola projects down to $ \AA^1 \setminus \cbr{0} $. Since $ I \subseteq J $, points $ \br{x_1, \dots, x_n, y} $ of $ W $ also satisfy $ \br{x_1, \dots, x_n} \in V $. Therefore, if $ \pi : \AA^{n + 1} \to \AA^n $ is the projection map, forgetting the extra $ Y $ coordinate, then
$$ \pi\br{W} \subseteq \cbr{\br{x_1, \dots, x_n} \in V \st f\br{x_1, \dots, x_n} \ne 0}. $$
Since $ f \in \II\br{V} $, the set on the right is empty. Thus $ \pi\br{W} = \emptyset $. This implies that $ W $ itself is empty. Therefore, by the weak Nullstellensatz, $ J = k\sbr{X_1, \dots, X_n, Y} $. In particular, $ 1 \in J $ and thus $ 1 = a + bg $ for some $ a \in I \cdot k\sbr{X_1, \dots, X_n, Y} $ and $ b \in k\sbr{X_1, \dots, X_n, Y} $. Expanding out $ a $ and $ b $ as sums over powers of $ Y $,
$$ a = \sum_{j \ge 0} a_jY^j, \qquad b = \sum_{j \ge 0} b_jY^j, \qquad a_j \in I, \qquad b_j \in k\sbr{X_1, \dots, X_n}. $$
The equation $ 1 = a + bg $ can be expanded and rearranged to give
$$ 1 = a_0 - b_0 + \sum_{j \ge 1} \br{a_j + b_{j - 1}f - b_j}Y^j. $$
Looking at the terms of degree zero in $ Y $ gives $ b_0 = a_0 - 1 \in I - 1 $, then terms of degree one in $ Y $ gives $ b_1 = a_1 + b_0f \in I - f $, using $ a_1 \in I $ and $ b_0 \in I - 1 $. Continuing by induction on $ j $, these imply that
$$ b_j = a_j + b_{j - 1}f \in I - f^j, \qquad j \ge 0, $$
where $ I - f^j $ means the coset $ \cbr{t - f^j \st t \in I} $. But $ b $ is a polynomial, so $ b_j = 0 $ once $ j $ gets large enough. Thus for some $ j $, we get $ 0 \in I - f^j $, that is $ f^j \in I $. This proves that $ f \in \rad I $.
\end{proof}

\lecture{12}{Friday}{07/02/20}

We can restate the weak Nullstellensatz in elementary terms as, if $ f_1, \dots, f_m \in k\sbr{X_1, \dots, X_n} $ are a finite set of polynomials, and the ideal $ I $ which they generate is not the whole polynomial ring, then there exists a common solution $ \br{x_1, \dots, x_n} \in k^n $ to the equations
$$ f_1\br{x_1, \dots, x_n} = 0, \qquad, \dots, \qquad f_m\br{x_1, \dots, x_n} = 0. $$
We prove this in two steps.
\begin{enumerate}[label=Step \arabic*., leftmargin=0.5in]
\item There exists a larger field $ K $ containing $ k $ such that these equations have a common solution in $ K^n $.
\item If the equations have a common solution in $ K^n $, then they also have a common solution in $ k^n $.
\end{enumerate}

\subsubsection{Finding a solution in a bigger field}

The proof of step $ 1 $ is fairly short, and relies on Zorn's lemma.

\begin{lemma}
Let $ f_1, \dots, f_m $ be polynomials in $ k\sbr{X_1, \dots, X_n} $, such that the ideal $ I = \abr{f_1, \dots, f_m} $ is not equal to $ k\sbr{X_1, \dots, X_n} $. Then there exists a field $ K $ which is a finitely generated extension of $ k $ such that the equations $ f_1 = \dots = f_m = 0 $ have a common solution $ \br{x_1, \dots, x_n} \in K^n $.
\end{lemma}

Because $ I \ne k\sbr{X_1, \dots, X_n} $, we can use Zorn's lemma to show that $ I $ is contained in some maximal ideal $ M \subseteq k\sbr{X_1, \dots, X_n} $. This is a natural way to start. We are trying to show that $ \VV\br{I} $ has a point, and last time we saw that points in $ \VV\br{I} $ correspond to maximal ideals in $ k\sbr{X_1, \dots, X_n} $ containing $ I $. We cannot just quote the correspondence from the previous lecture because we used the Nullstellensatz in proving that correspondence, but this justifies why obtaining a maximal ideal is a good first step.

\begin{proof}
Let $ K = k\sbr{X_1, \dots, X_n} / M $. Let $ x_1, \dots, x_n $ denote the images of $ X_1, \dots, X_n $ in $ K $. Then $ K $ is a field because $ M $ is a maximal ideal, and it is finitely generated as an extension of $ k $ because it is generated by $ x_1, \dots, x_n $. Since $ f_j\br{X_1, \dots, X_n} \in I \subseteq M $, we get that $ f_j\br{x_1, \dots, x_n} = 0 $ in $ K $ for each $ j $. Thus $ \br{x_1, \dots, x_n} $ is the required common solution to $ f_1, \dots, f_m $ in $ K^n $.
\end{proof}

\pagebreak

\subsubsection{Shrinking the field required}

Before proving step $ 2 $, we begin by quoting an algebraic result.

\begin{lemma}
\label{lem:algebraicallyindependent}
Let $ k $ be an algebraically closed field and let $ K $ be a finitely generated extension field of $ k $. Then there exist $ t_1, \dots, t_d, u \in K $ such that
\begin{itemize}
\item $ K = k\br{t_1, \dots, t_d, u} $,
\item $ t_1, \dots, t_d $ are algebraically independent over $ k $, that is there is no non-zero polynomial in $ d $ variables with coefficients in $ k $ whose value at $ \br{t_1, \dots, t_d} $ is zero, and
\item $ u $ is algebraic over $ k\br{t_1, \dots, t_d} $, that is there exists a non-zero polynomial in one variable with coefficients in the field $ k\br{t_1, \dots, t_d} $ which is zero at $ u $.
\end{itemize}
\end{lemma}

\begin{proof}
This follows from the primitive element theorem in field theory. For a full proof, see Proposition A.7 in the appendix of Shafarevich basic algebraic geometry.
\end{proof}

Lemma \ref{lem:algebraicallyindependent} has a nice geometric interpretation. Every finitely generated extension of $ k $ is isomorphic to the field of fractions of a hypersurface. We need to use the Nullstellensatz to prove this geometric interpretation, so that is postponed until after we have finished the proof of the Nullstellensatz.

\begin{theorem}
\label{thm:shrinkingfield}
Let $ k $ be an algebraically closed field and let $ K $ be a finitely generated extension field of $ k $. Let $ f_1, \dots, f_m \in k\sbr{X_1, \dots, X_n} $. Suppose there exists a common solution $ \br{x_1, \dots, x_n} \in K^n $ to the equations $ f_1 = \dots = f_m = 0 $. Then there exists a common solution $ \br{y_1, \dots, y_n} \in k^n $ to the equations $ f_1 = \dots = f_m = 0 $.
\end{theorem}

\begin{proof}
Write $ K = k\br{t_1, \dots, t_d, u} $ as in Lemma \ref{lem:algebraicallyindependent}. Let $ K' = k\br{t_1, \dots, t_d} $. Because $ t_1, \dots, t_d $ are algebraically independent, we can identify $ K' $ with $ k\br{T_1, \dots, T_d} $, the field of fractions of the polynomial ring $ k\sbr{T_1, \dots, T_d} $. This will allow us to substitute a vector $ \underline{z} \in k^d $ into an element $ \alpha \in K' $ and get out an element $ \alpha\br{\underline{z}} \in k $, as long as the denominator of $ \alpha $ does not vanish at $ \underline{z} $. We use two facts about the finite algebraic extension $ K / K' $.
\begin{enumerate}[label=Fact \arabic*., leftmargin=0.5in]
\item There exists a minimal polynomial $ p\br{U} \in K'\sbr{U} $ for $ u $. That is, $ p\br{u} = 0 $, $ p $ has leading coefficient one, and $ p $ divides every other polynomial $ q\br{U} \in K'\sbr{U} $ such that $ q\br{u} = 0 $.
\item Every element of $ K $ can be written in the form $ a\br{u} $ for some polynomial $ a\br{U} \in K'\sbr{U} $.
\end{enumerate}
The idea of the proof is to consider the almost hypersurface
$$ H = \cbr{\br{z_1, \dots, z_d, s} \in k^{d + 1} \st p\br{z_1, \dots, z_d, s} = 0}. $$
The almost is because $ p $ is not a polynomial in $ k\sbr{T_1, \dots, T_d, U} $ but rather may have denominators, so we have to ignore the places where these denominators vanish. Then we construct a rational map $ \phi : H \dashrightarrow \VV\br{f_1, \dots, f_m} $. The domain of definition of $ \phi $ is an open subset of an almost hypersurface, and we can easily check that this is non-empty. Then a point in the image of $ \phi $ gives us a point in $ \VV\br{f_1, \dots, f_m} $, as desired. In particular, we apply fact $ 2 $ to $ x_1, \dots, x_n \in K $, our common solution to $ f_1 = \dots = f_m = 0 $, so we can write $ x_i = a_i\br{u} $ where $ a_i\br{U} \in K'\sbr{U} $. In the informal outline, these $ a_i \in k\br{T_1, \dots, T_d}\sbr{U} $ define a rational map $ \phi : H \dashrightarrow \AA^n $. Next we check that the image of this rational map is contained in $ \VV\br{f_1, \dots, f_m} $. We know that $ \br{x_1, \dots, x_n} $ is a common solution to the polynomials $ f_1, \dots, f_m $. Hence
$$ f_j\br{a_1\br{u}, \dots, a_n\br{u}} = 0 \in K, \qquad j = 1, \dots, m. $$
In other words, the single-variable polynomial $ f_j\br{a_1\br{U}, \dots, a_n\br{U}} \in K'\sbr{U} $ has $ u $ as a root. Therefore, fact $ 1 $ tells us that this polynomial is divisible by $ p\br{U} $. Thus there exist polynomials $ q_1, \dots, q_m \in K'\sbr{U} $ such that
\begin{equation}
\label{eq:1}
f_j\br{a_1\br{U}, \dots, a_n\br{U}} = q_j\br{U}p\br{U} \in K'\sbr{U}, \qquad j = 1, \dots, m.
\end{equation}
Now, if $ \br{z_1, \dots, z_d, s} \in k^{d + 1} $ satisfies $ p\br{z_1, \dots, z_d, s} = 0 $, then $ \br{\ref{eq:1}} $ implies that
$$ f_j\br{a_1\br{z_1, \dots, z_d, s}, \dots, a_n\br{z_1, \dots, z_d, s}} = 0, \qquad j = 1, \dots, m, $$

\pagebreak

so long as all the denominators involved are non-zero. Thus we just have to find $ \br{z_1, \dots, z_d, s} $ where all these denominators will be non-zero. So consider the polynomials
$$ p\br{U}, a_i\br{U}, q_j\br{U} \in K'\sbr{U}. $$
Their coefficients are elements of the field $ K' $ which we are identifying with the field of fractions $ k\br{T_1, \dots, T_d} $. Let $ \sigma \in k\sbr{T_1, \dots, T_d} $ denote the product of the denominators of all these fractions. Because the denominator of a fraction is never zero, $ \sigma $ is not the zero polynomial in $ k\sbr{T_1, \dots, T_d} $. Therefore, there exists $ \br{s_1, \dots, s_d} \in k^d $ such that $ \sigma\br{s_1, \dots, s_d} \ne 0 $. Then the denominators of the coefficients of $ p, a_i, q_j $ do not vanish at $ s_1, \dots, s_d $, so we can substitute $ \br{s_1, \dots, s_d} $ into each of these coefficients, as elements of $ K' $, and get out values in $ k $. Thus we get new polynomials
$$ \widetilde{p}\br{U}, \widetilde{a_i}\br{U}, \widetilde{q_j}\br{U} \in k\sbr{U}. $$
The leading coefficient of $ \widetilde{p}\br{U} $ is one, which is unchanged by this process. So $ \widetilde{p}\br{U} $ has the same degree as $ p\br{U} $. In particular $ \widetilde{p}\br{U} $ is not a constant polynomial. Hence as $ k $ is algebraically closed, there exists $ s \in k $ such that $ \widetilde{p}\br{s} = 0 $. Let $ y_i = \widetilde{a_i}\br{s} \in k $. Then $ \br{\ref{eq:1}} $ tells us that
$$ f_j\br{y_1, \dots, y_n} = \widetilde{q_j}\br{s}\widetilde{p}\br{s}, \qquad j = 1, \dots, m. $$
But we chose $ s $ such that $ \widetilde{p}\br{s} = 0 $, and so we conclude that $ \br{y_1, \dots, y_n} \in k^n $ is a common solution to $ f_1 = \dots = f_m = 0 $.
\end{proof}

Combining Lemma \ref{lem:algebraicallyindependent} and Theorem \ref{thm:shrinkingfield} proves the weak Nullstellensatz.

\subsubsection{Hypersurfaces and birational equivalence}

Now we prove the geometrical interpretation of Lemma \ref{lem:algebraicallyindependent}.

\begin{proposition}
\label{prop:irreduciblehypersurface}
Let $ K $ be a finitely generated extension of $ k $. Then there exists an irreducible hypersurface $ H \subseteq \AA^{d + 1} $ for some $ d $ such that $ K $ is isomorphic to the field of functions $ k\br{H} $.
\end{proposition}

\begin{corollary}
\label{cor:irreduciblehypersurface}
Let $ V \subseteq \AA^n $ be an irreducible affine algebraic set. Then there exists an irreducible hypersurface $ H \subseteq \AA^{d + 1} $ for some $ d $ such that $ V $ is birationally equivalent to $ H $.
\end{corollary}

Corollary \ref{cor:irreduciblehypersurface} tells us that, even if $ V $ is a complicated algebraic set defined by many equations, provided we only care about properties of $ V $ which are preserved by birational equivalence, we can replace $ V $ by a simpler set defined by just one equation, that is a hypersurface.

\begin{note*}
It is not true that every irreducible affine algebraic set is isomorphic to a hypersurface.
\end{note*}

\begin{proof}[Proof of Proposition \ref{prop:irreduciblehypersurface}]
Write $ K = k\br{t_1, \dots, t_d, u} $ as in Lemma \ref{lem:algebraicallyindependent}, and let $ K' = k\br{t_1, \dots, t_d} $. Because $ u $ is algebraic over $ K' $, let $ p\br{U} \in K'\sbr{U} $ be the minimal polynomial of $ u $ over $ K' $. Each coefficient of $ p\br{U} $ is a fraction whose numerator and denominator are polynomials in $ t_1, \dots, t_d $. We can multiply up by a suitable element of $ k\sbr{t_1, \dots, t_d} $ to clear the denominators, and also replace $ t_1, \dots, t_d $ by indeterminates $ T_1, \dots, T_d $ to get a polynomial $ g \in k\sbr{T_1, \dots, T_d, U} $ such that $ g\br{t_1, \dots, t_d, u} = 0 $ in the field $ K $. Assuming we multiplied up by a lowest common denominator for the coefficients of $ p $, $ g $ is irreducible. Let $ H $ be the hypersurface in $ \AA^{d + 1} $ defined by the polynomial $ g $. Because $ g $ is irreducible, it generates a radical ideal in $ k\sbr{X_1, \dots, X_n} $ and so the strong Nullstellensatz implies that $ \II\br{H} = \abr{g} $. Thus the coordinate ring is given by
$$ k\sbr{H} = k\sbr{T_1, \dots, T_d, U} / \abr{g}. $$
There is a $ k $-algebra homomorphism
$$ \function[\alpha]{k\sbr{T_1, \dots, T_d, U}}{K}{\br{T_1, \dots, T_d, U}}{\br{t_1, \dots, t_d, u}}. $
A little algebra, using Gauss' lemma, shows that the kernel of $ \alpha $ is generated by $ g $, so $ \alpha $ induces an injection $ k\sbr{H} \hookrightarrow K $. Furthermore, the image of $ \alpha $ generates $ K $ as a field, so $ \alpha $ induces an isomorphism from the fraction field of $ k\sbr{H} $ to $ K $. The fraction field of $ k\sbr{H} $ is the function field $ k\br{H} $. Thus we have shown that $ k\br{H} \cong k\br{V} $. By Corollary \ref{cor:algebrageometry}, this implies that $ V $ is birationally equivalent to $ H $.
\end{proof}

\begin{proof}[Proof of Corollary \ref{cor:irreduciblehypersurface}]
Apply Proposition \ref{prop:irreduciblehypersurface} to the function field $ K = k\br{V} $.
\end{proof}

\end{document}