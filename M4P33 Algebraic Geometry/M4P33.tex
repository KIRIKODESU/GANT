\def\module{M4P33 Algebraic Geometry}
\def\lecturer{Prof Kevin Buzzard}
\def\term{Spring 2020}
\def\cover{}
\def\syllabus{}
\def\thm{section}

\input{../style/header}

\begin{document}

\input{../style/cover}

\section{Introduction}

\subsection{B\'ezout's theorem}

\lecture{1}{Monday}{13/01/20}

Here is an example of a theorem in algebraic geometry and an outline of a geometric method for proving it which illustrates some of the main themes in algebraic geometry.

\begin{theorem}[B\'ezout]
Let $ C $ be a plane algebraic curve $ \cbr{\br{x, y} \st f\br{x, y} = 0} $ where $ f $ is a polynomial of degree $ m $. Let $ D $ be a plane algebraic curve $ \cbr{\br{x, y} \st g\br{x, y} = 0} $ where $ g $ is a polynomial of degree $ n $. Suppose that $ C $ and $ D $ have no component in common, since if they had a component in common, then their intersection would obviously be infinite. Then $ C \cap D $ consists of $ mn $ points, provided that
\begin{itemize}
\item we work over the complex numbers $ \CC $,
\item we work in the projective plane, which consists of the ordinary plane together with some points at infinity, and
\item we count intersections with the correct multiplicities, so if the curves are tangent at a point, it counts as more than one intersection.
\end{itemize}
\end{theorem}

Consider the cases where $ C $ is a line of degree one and $ D $ has either degree one or two. The projective plane will be formally defined later in the course. We will not define intersection multiplicities in this course, but the idea is that multiple intersections resemble multiple roots of a polynomial in one variable.

\begin{proof}
We prove a special case, where $ C $ is the union of $ m $ lines, then use this to prove the general case of the theorem.
\begin{itemize}
\item First for the special case, suppose we have $ m $ lines in the plane, with equations
$$ a_1x + b_1y + c_1 = 0, \qquad \dots, \qquad a_mx + b_my + c_m = 0. $$
We can multiply these equations together to get
$$ \br{a_1x + b_1y + c_1} \dots \br{a_mx + b_my + c_m} = 0. $$
This is an equation of degree $ m $ and its solution set is the union of the lines. Each line intersects $ D $ in $ n $ points, counted with multiplicities, because we can rearrange the equation of the line into the form $ x = \dots $ or $ y = \dots $ then substitute into the equation for $ D $. This usually gives a polynomial of degree $ n $ in one variable, and this has $ n $ roots if we count them correctly. There are also special cases to worry about where the line intersects $ D $ at infinity. Combining all the $ m $ lines, we deduce that their union intersects $ D $ in $ mn $ points.
\item Now we deduce the general case from the special case. We let the curve $ C $ vary in a family of curves of degree $ m $. What exactly we mean by varying in a family will be defined later in the course. As an example, consider the family of curves
$$ \FFF : \cbr{\br{x, y} \st x^2 - y^2 = t}, $$
where $ t $ is a parameter, so for different values of $ t $ we get different curves. When the curve $ C $ varies in a family like this, the number of intersection points in $ C \cap D $ does not change, counting with multiplicity. This is the core of the proof. It requires a lot of work to justify which we will not do here. For any degree $ m $ curve $ C $, it is possible to find a family of curves which contains both $ C $ itself and a union of $ m $ lines $ X $. For example, if $ C $ is the hyperbola defined by the equation $ x^2 - y^2 = 1 $, then it is found in the family $ \FFF $, with $ t = 1 $. If we let $ t = 0 $ in this family, then the equation factors as $ \br{x - y}\br{x + y} $ and this defines the union of two lines in the plane. We have already proved that $ X \cap D $ has $ mn $ points, and we stated that $ X \cap D $ has the same number of points as $ C \cap D $ because $ C $ and $ X $ are in the same family. We conclude that $ C \cap D $ has $ mn $ points.
\end{itemize}
\end{proof}

\pagebreak

The idea that something stays the same everywhere, or almost everywhere, in a family of varying algebraic sets is a key theme in algebraic geometry. Note that this proof uses not just curves but also higher-dimensional algebraic sets. Instead of thinking about a family of curves such as $ \FFF $, with coordinates $ \br{x, y} $ and a parameter $ t $, we can regard $ x, y, t $ all as coordinates in three-dimensional space and consider the surface
$$ \cbr{\br{x, y, t} \st x^2 - y^2 = t}. $$
Then we use facts about this surface as part of the proof. We will not prove B\'ezout's theorem in this course. In particular, we will not define intersection multiplicities. But we will set up many of the tools needed to fill in the gaps in this outline proof.

\subsection{Practical information about the course}

The following are books.
\begin{itemize}
\item M Reid, Undergraduate algebraic geometry, 1988
\item R Hartshorne, Algebraic geometry, 1977
\end{itemize}
During the course we will sometimes assume results from commutative algebra. Books which contain these results, and much much more, include the following.
\begin{itemize}
\item H Matsumura, Commutative ring theory, 1986
\item M F Atiyah and I G Macdonald, Introduction to commutative algebra, 1969
\item D Eisenbud, Commutative algebra: with a view toward algebraic geometry, 2011
\end{itemize}
The following is the course outline.
\begin{itemize}
\item Affine varieties.
\begin{itemize}
\item Definition and examples.
\item Maps between varieties.
\item Translating between geometry and commutative algebra and the Nullstellensatz.
\end{itemize}
\item Projective varieties.
\begin{itemize}
\item Definition and examples.
\item Maps between varieties.
\item Rigidity and images of maps.
\end{itemize}
\item Dimension.
\begin{itemize}
\item Several different definitions, all equivalent, but useful for different purposes.
\item Calculating dimensions of examples.
\end{itemize}
\end{itemize}
What is not in the course?
\begin{itemize}
\item Schemes.
\item Sheaves and cohomology.
\item Curves, divisors, and the Riemannâ€“Roch theorem.
\end{itemize}

\pagebreak

\section{Affine varieties}

\subsection{Affine algebraic sets}

Let $ k $ be an algebraically closed field. We are going to be thinking about solutions to polynomials, so everything is much simpler over algebraically closed fields. We already saw this in B\'ezout's theorem. Number theorists might be interested in other fields, but you generally have to start by understanding the algebraically closed case first. In this course we will stop with the algebraically closed case too. Apart from being algebraically closed, it usually does not matter much which field we use to do algebraic geometry, except sometimes it matters whether the characteristic is zero or positive. In this course I will take care to mention results which depend on the characteristic, and sometimes we might consider only the characteristic zero case. You will not lose much if you just assume that $ k = \CC $ throughout the course, except when it will be explicitly something else. Indeed it is often useful to think about $ k = \CC $ because then you can use your usual geometric intuition. When I draw pictures on the whiteboard, I am usually only drawing the real solutions because it is hard to draw shapes in $ \CC^2 $. This is cheating but it is often very useful. The real solutions are not the full picture but in many cases we can still see the important features there.

\subsubsection{Affine space}

\begin{definition*}
Algebraic geometers write $ \AA^n $ to mean $ k^n $, and call it \textbf{affine $ n $-space}.
\end{definition*}

You may think of this as just a funny choice of notation, but there are at least two reasons for it.
\begin{itemize}
\item When we write $ k^n $, it makes us think of a vector space, equipped with operations of addition and scalar multiplication. But $ \AA^n $ means just a set of points, described by coordinates $ \br{x_1, \dots, x_n} $ with $ x_i \in k $, without the vector space structure.
\item Because it usually does not matter much what our base field $ k $ is, as long as it is algebraically closed, it is convenient to have notation which does not prominently mention $ k $.
\end{itemize}
On occasions when it is important to specify which field $ k $ we are using, we write $ \AA_k^n $ for affine $ n $-space.

\subsubsection{Definition and examples}

\lecture{2}{Thursday}{16/01/20}

\begin{definition*}
An \textbf{affine algebraic set} is a subset $ V \subseteq \AA^n $ which consists of the common zeroes of some finite set of polynomials $ f_1, \dots, f_m $ with coefficients in $ k $. More formally, an affine algebraic set is a set of the form
$$ V = \cbr{\br{x_1, \dots, x_n} \in \AA^n \st f_1\br{x_1, \dots, x_n} = \dots = f_m\br{x_1, \dots, x_n} = 0}, \qquad f_1, \dots, f_m \in k\sbr{X_1, \dots, X_n}. $$
\end{definition*}

\begin{example*}
Examples.
\begin{itemize}
\item The empty set, defined by the polynomial $ f_1 = 3 $, for example.
\item The whole space $ \AA^n $, defined by the polynomial $ f_1 = 0 $, or by the empty set of polynomials.
\item Any finite subset $ \cbr{a_1, \dots, a_n} $ in $ \AA^1 $, defined by the polynomial $ f_1 = \br{X - a_1} \dots \br{X - a_n} $.
\item Any single-point set $ \cbr{\br{a_1, \dots, a_n}} $ in $ \AA^n $, defined by the polynomials $ f_i = X_i - a_i $. Note that this is different from the example of a finite set in $ \AA^1 $, because that example had a single polynomial in one variable of degree $ n $, while here we have $ n $ distinct polynomials in $ n $ variables of degree one.
\item Any algebraic curve in $ \AA^n $, that is, a set of the form
$$ \cbr{\br{x_1, \dots, x_n} \in \AA^n \st f\br{x_1, \dots, x_n} = 0}, \qquad f \in k\sbr{X_1, \dots, X_n}. $$
\item Embeddings of $ \AA^m $ in $ \AA^n $ where $ m < n $,
$$ \cbr{\br{x_1, \dots, x_m, 0, \dots, 0} \in \AA^n} = \cbr{\br{x_1, \dots, x_n} \in \AA^n \st x_{m + 1} = \dots = x_n = 0}. $$
More generally, the image of a linear map $ \AA^m \to \AA^n $,
$$ \cbr{\br{x_1, \dots, x_n} \in \AA^n \st \text{some linear conditions}}. $$
\end{itemize}
\end{example*}

\pagebreak

\begin{example*}
Non-examples.
\begin{itemize}
\item Any infinite subset of $ \AA^1 $, other than $ \AA^1 $ itself, such as a line segment, a line with a double point, or an infinite discrete set. This is because a one-variable polynomial with infinitely many roots must be the zero polynomial. This also tells us that $ \cbr{x \in \AA^1 \st x \ne 0} $ is not an affine algebraic set. However there is an affine algebraic set which is isomorphic to $ \AA^1 \setminus \cbr{0} $, namely $ \cbr{\br{x, y} \in \AA^2 \st xy - 1 = 0} $. By looking at just the $ x $ coordinate, this set bijects to $ \AA^1 \setminus \cbr{0} $.
\item A sine wave. If $ \cbr{\br{x, y} \st y = \sin x} $ were an affine algebraic set, then $ \cbr{\br{x, y} \st y = \sin x, \ y = 0} $ would also be an affine algebraic set because it is defined by imposing an extra polynomial condition, but the latter is an infinite discrete set.
\item The example of the image of a linear map $ \AA^m \to \AA^n $ does not generalise to images of maps where each coordinate is given by a polynomial. For example, consider the map
$$ \function[\phi]{\AA^2}{\AA^2}{\br{x, y}}{\br{x, xy}}. $$
The image of $ \phi $ is $ S = \AA^2 \setminus \cbr{\br{0, y}} \cup \cbr{\br{0, 0}} $. To prove that $ S $ is not an affine algebraic set, consider a polynomial $ g\br{X, Y} \in k\sbr{X, Y} $ which vanishes on $ S $. For each fixed $ y \in k $, the one-variable polynomial $ g\br{X, y} $ vanishes at all $ x \ne 0 $. This implies that $ g\br{X, y} $ is the zero polynomial. Thus $ g\br{x, y} = 0 $ for all $ \br{x, y} \in k^2 $, that is, $ g $ is the zero polynomial.
\end{itemize}
\end{example*}

\begin{remark}
The words affine variety mean more or less the same thing as affine algebraic set but there is an ontological difference. Affine algebraic set means a subset which lives inside $ \AA^n $ and knows how it lives inside $ \AA^n $, while affine variety means an object in its own right which is considered outside of $ \AA^n $. I will try to use these words consistently, but the difference is quite subtle and books may not always use it consistently. For the first few weeks, we will talk about affine algebraic sets only. Note that some books, such as Reid and Hartshorne, have another difference between affine varieties and affine algebraic sets. They require varieties to be irreducible, which we will define next time. Other books, such as Shafarevich, do not require varieties to be irreducible. In this course we will not require varieties to be irreducible.
\end{remark}

\subsubsection{New algebraic sets from old}

Now we prove that the union of two affine algebraic sets is an affine algebraic set. Consider two points $ \br{a_1, \dots, a_n} $ and $ \br{b_1, \dots, b_n} $ in $ \AA^n $. The two-point set $ \cbr{\br{a_1, \dots, a_n}, \br{b_1, \dots, b_n}} $ can be defined by taking the product for each possible pair of equations, one from each list, so $ \br{X_i - a_i}\br{X_j - b_j} = 0 $ for all $ i, j \in \cbr{1, \dots, n} $.

\begin{note*}
It is necessary to consider all the pairs between the lists, not just the ones with $ i = j $, because otherwise we would be allowing points like $ \br{a_1, \dots, a_{n - 1}, b_n} $.
\end{note*}

\begin{lemma}
If $ V, W \subseteq \AA^n $ are affine algebraic sets, then their union $ V \cup W \subseteq \AA^n $ is also an affine algebraic set.
\end{lemma}

% We see that any finite subset of $ \AA^n $ is an affine algebraic set.

\begin{proof}
We have to take the product for each possible pair of defining polynomials. If
$$ V = \cbr{\underline{x} \in \AA^n \st f_1\br{\underline{x}} = \dots = f_r\br{\underline{x}} = 0}, \qquad W = \cbr{\underline{x} \in \AA^n \st g_1\br{\underline{x}} = \dots = g_s\br{\underline{x}} = 0}, $$
then
$$ V \cup W = \cbr{\underline{x} \in \AA^n \st \forall 1 \le i \le r, \ \forall 1 \le j \le s, \ f_i\br{\underline{x}}g_j\br{\underline{x}} = 0}. $$
Let us check that these equations really do define $ V \cup W $. First, suppose that $ \underline{x} \in V \cup W $. Then either $ \underline{x} \in V $, so $ f_i\br{\underline{x}} = 0 $ for every $ i $, so we can multiply by $ g_j\br{\underline{x}} $ to get $ f_i\br{\underline{x}}g_j\br{\underline{x}} = 0 $ for every $ i $ and $ j $, or $ \underline{x} \in W $, in which case the same argument works with $ g_j $ in place of $ f_i $. The reverse direction is a little trickier. Suppose that we have $ \underline{x} \in \AA^n $ satisfying $ f_i\br{\underline{x}}g_j\br{\underline{x}} = 0 $ for all $ i $ and $ j $. Looking just at $ f_1 $, we get
$$ f_1\br{\underline{x}}g_1\br{\underline{x}} = 0 \implies f_1\br{\underline{x}} = 0 \ \text{or} \ g_1\br{\underline{x}} = 0, \qquad \dots, \qquad f_1\br{\underline{x}}g_s\br{\underline{x}} = 0 \implies f_1\br{\underline{x}} = 0 \ \text{or} \ g_s\br{\underline{x}} = 0. $$
Putting these all together, we get $ f_1\br{\underline{x}} = 0 $ or $ g_j\br{\underline{x}} = 0 $ for every $ j $. We can do the same thing for $ f_2 $ to get $ f_2\br{\underline{x}} = 0 $ or $ g_j\br{\underline{x}} = 0 $ for every $ j $, and so on for each $ f_i $. Putting all these together, we get $ f_i\br{\underline{x}} = 0 $ for every $ i $ or $ g_j\br{\underline{x}} = 0 $ for every $ j $. This says precisely that $ \underline{x} \in V \cup W $.
\end{proof}

\pagebreak

It is even easier to check that the intersection of finitely many affine algebraic sets is an affine algebraic set.

\begin{lemma}
If $ V, W \subseteq \AA^n $ are affine algebraic sets, then their intersection $ V \cap W \subseteq \AA^n $ is also an affine algebraic set.
\end{lemma}

\begin{proof}
Just combine the lists of defining equations. That is, say
$$ V = \cbr{\underline{x} \in \AA^m \st f_1\br{\underline{x}} = \dots = f_r\br{\underline{x}} = 0}, \qquad W = \cbr{\underline{y} \in \AA^n \st g_1\br{\underline{y}} = \dots = g_s\br{\underline{y}} = 0}. $$
Then $ V \cap W $ is simply the set where all the polynomials in both lists vanish, that is
$$ V \cap W = \cbr{\underline{x} \in \AA^n \st f_1\br{\underline{x}} = \dots = f_r\br{\underline{x}} = g_1\br{\underline{x}} = \dots = g_s\br{\underline{x}} = 0}. $$
\end{proof}

Just a remark on one other way of constructing new affine algebraic sets from existing ones.

\begin{lemma}
If $ V \subseteq \AA^m $ and $ W \subseteq \AA^n $ are affine algebraic sets, then their Cartesian product $ V \times W \subseteq \AA^{m + n} $ is an affine algebraic set.
\end{lemma}

\begin{proof}
Write
$$ V = \cbr{\underline{x} \in \AA^m \st f_1\br{\underline{x}} = \dots = f_r\br{\underline{x}} = 0}, \qquad W = \cbr{\underline{y} \in \AA^n \st g_1\br{\underline{y}} = \dots = g_s\br{\underline{y}} = 0}. $$
Then
$$ V \times W = \cbr{\br{\underline{x}, \underline{y}} \in \AA^{m + n} \st f_1\br{\underline{x}} = \dots = f_r\br{\underline{x}} = g_1\br{\underline{y}} = \dots = g_s\br{\underline{y}} = 0}. $$
\end{proof}

This looks a bit like the equations defining $ V \cap W $, but here the $ f_i $ involve different variables from the $ g_j $, while for $ V \cap W $ both used the same variables.

\subsubsection{Ideals and algebraic sets}

\lecture{3}{Friday}{17/01/20}

The union of infinitely many affine algebraic sets is not always an affine algebraic set. I do not mean that it is never an affine algebraic set, just that there exist counter-examples. Indeed, any subset of $ \AA^n $ can be written as a union of single-point sets. The intersection of infinitely many affine algebraic sets always an affine algebraic set. If we try to prove this by combining the lists of defining equations, we run into a problem. In our definition of affine algebraic sets we only allowed a finite list of polynomial equations. We introduce ideals to remove this restriction.

\begin{definition*}
Recall from commutative algebra that, if $ R $ is a ring, an \textbf{ideal} is a subset $ I \subseteq R $ with the properties that
\begin{itemize}
\item if $ f, g \in I $, then $ f + g \in I $, and
\item if $ f \in I $ and $ q \in R $, then $ qf \in I $.
\end{itemize}
Given any subset $ S \subseteq R $, we define the \textbf{ideal generated by $ S $} to be the smallest ideal which contains $ S $, and denote it by $ \abr{S} $. In particular, if $ S $ is the finite set $ \cbr{f_1, \dots, f_m} $ then it generates the ideal
$$ \abr{f_1, \dots, f_m} = \cbr{q_1f_1 + \dots + q_mf_m \st q_1, \dots, q_m \in R}. $$
\end{definition*}

Let us introduce some notation.

\begin{definition*}
For any set $ S \subseteq k\sbr{X_1, \dots, X_n} $, let
$$ \VV\br{S} = \cbr{\underline{x} \in \AA^n \st \forall f \in S, \ f\br{\underline{x}} = 0}. $$
\end{definition*}

\begin{lemma}
\label{lem:vs}
If $ S \subseteq k\sbr{X_1, \dots, X_n} $ generates the ideal $ I $, then $ \VV\br{S} = \VV\br{I} $.
\end{lemma}

\begin{proof}
We have $ S \subseteq I $ and so it is easy to see that $ \VV\br{I} \subseteq \VV\br{S} $. Suppose that $ \underline{x} \in \VV\br{S} $, and $ f \in \VV\br{I} $. Then there are $ f_1, \dots, f_m \in S $ and $ q_1, \dots, q_m \in k\sbr{X_1, \dots, X_n} $ such that $ f = q_1f_1 + \dots + q_mf_m $. Since $ f_1\br{\underline{x}} = \dots = f_m\br{\underline{x}} = 0 $, it follows that $ f\br{\underline{x}} = 0 $. Since this holds for every $ f \in I $, $ \underline{x} \in \VV\br{I} $.
\end{proof}

\pagebreak

\begin{theorem}[Hilbert basis theorem]
From commutative algebra, if $ k $ is any field, then the polynomial ring $ k\sbr{X_1, \dots, X_n} $ is Noetherian. That means that the following two equivalent conditions hold.
\begin{itemize}
\item Let $ I $ be an ideal in $ k\sbr{X_1, \dots, X_n} $. Then there exists a finite set $ \cbr{f_1, \dots, f_m} \subseteq k\sbr{X_1, \dots, X_n} $ which generates $ I $.
\item Let $ I_1 \subseteq I_2 \subseteq \dots $ be an ascending chain of ideals in $ k\sbr{X_1, \dots, X_n} $. Then there is some $ N $ such that $ I_n = I_N $ for every $ n > N $.
\end{itemize}
\end{theorem}

Using the Hilbert basis theorem, we can deduce that the restriction to finite lists of polynomials in the definition of affine algebraic sets is unnecessary.

\begin{corollary}
\label{cor:vs}
$ \VV\br{S} $ is an affine algebraic set for any set of polynomials $ S \subseteq k\sbr{X_1, \dots, X_n} $.
\end{corollary}

\begin{proof}
Let $ I $ be the ideal in $ k\sbr{X_1, \dots, X_n} $ generated by $ S $. By the Hilbert basis theorem, $ k\sbr{X_1, \dots, X_n} $ is Noetherian and so we can choose a finite set $ \cbr{f_1, \dots, f_m} $ which generates $ I $. Then Lemma \ref{lem:vs} tells us that $ \VV\br{S} = \VV\br{I} = \VV\br{f_1, \dots, f_m} $.
\end{proof}

\begin{corollary}
The intersection of finitely many affine algebraic sets is an affine algebraic set.
\end{corollary}

\begin{proof}
Combine the lists of defining polynomials for all the algebraic sets, and apply Corollary \ref{cor:vs}.
\end{proof}

We can also go in the other direction, from affine algebraic sets to ideals. Say $ V_n = \VV\br{I_n} $. Does $ V_1 \supseteq V_2 $ imply that $ I_1 \subseteq I_2 $? No. The problem is that there is more than one ideal defining the same algebraic set.

\begin{example*}
Let $ I_1 = \abr{X} $ and $ I_2 = \abr{X^2} $ in $ k\sbr{X} $. We have $ \VV\br{I_1} = \cbr{0} = \VV\br{I_2} $.
\end{example*}

However, there is a natural choice we can make for one ideal canonically associated with an affine algebraic set, the set of all polynomials which vanish on that set.

\begin{definition*}
Formally, if $ A $ is any subset of $ \AA^n $, usually $ A $ will be an affine algebraic set, we define
$$ \II\br{A} = \cbr{f \in k\sbr{X_1, \dots, X_n} \st \forall \underline{x} \in A, \ f\br{\underline{x}} = 0}. $$
\end{definition*}

\begin{note*}
$ \II\br{A} $ is an ideal in $ k\sbr{X_1, \dots, X_n} $.
\end{note*}

We have now defined two functions
$$ \VV : \cbr{\text{ideals in} \ k\sbr{X_1, \dots, X_n}} \to \cbr{\text{affine algebraic sets in} \ \AA^n}, $$
$$ \II : \cbr{\text{affine algebraic sets in} \ \AA^n} \to \cbr{\text{ideals in} \ k\sbr{X_1, \dots, X_n}}. $$
These functions are not inverses of each other. The example of $ \abr{X} $ and $ \abr{X^2} $ shows that $ \II\br{\VV\br{\abr{X^2}}} = \abr{X} \ne \abr{X^2} $. But composing $ \VV $ and $ \II $ in the other order gives the identity.

\begin{lemma}
\label{lem:viv}
If $ V $ is an affine algebraic set, then $ \VV\br{\II\br{V}} = V $.
\end{lemma}

\begin{proof}
It is clear that $ V \subseteq \VV\br{\II\br{V}} $, and this works when $ V $ is any subset of $ \AA^n $, not necessarily algebraic. For the reverse inclusion, we have to use the hypothesis that $ V $ is an affine algebraic set. By the definition of affine algebraic sets, $ V = \VV\br{J} $ for some ideal $ J \subseteq k\sbr{X_1, \dots, X_n} $. Suppose that $ \underline{y} \notin V $. We shall show that $ \underline{y} \notin \VV\br{\II\br{V}} $. Because $ \underline{y} \notin V = \VV\br{J} $, there exists $ f \in J $ such that $ f\br{\underline{y}} \ne 0 $. By definition, $ J \subseteq \II\br{V} $ and so $ f \in \II\br{V} $. Hence $ f\br{\underline{y}} \ne 0 $ tells us that $ \underline{y} \notin \VV\br{\II\br{V}} $.
\end{proof}

What is the geometric interpretation of the Hilbert basis theorem?

\begin{note*}
It is clear that $ \VV $ and $ \II $ reverse the direction of inclusions, so if $ I_1 \subseteq I_2 $, then $ \VV\br{I_2} \subseteq \VV\br{I_1} $.
\end{note*}

Hence the ascending chain condition for ideals translates into the descending chain condition for affine algebraic sets. The following statement is the translation into affine algebraic sets of the Hilbert basis theorem.

\begin{lemma}
\label{lem:descendingchain}
Let $ V_1 \supseteq V_2 \supseteq \dots $ be a descending chain of affine algebraic sets in $ \AA^n $. Then there exists $ N $ such that $ V_n = V_N $ for all $ n > N $.
\end{lemma}

\begin{proof}
The fact that $ V_1 \supseteq V_2 \supseteq \dots $ implies that $ \II\br{V_1} \subseteq \II\br{V_2} \subseteq \dots $. Because $ k\sbr{X_1, \dots, X_n} $ is Noetherian, there exists $ N $ such that $ \II\br{V_n} = \II\br{V_N} $ for all $ n > N $. By Lemma \ref{lem:viv}, $ V_n = \VV\br{\II\br{V_n}} $ for every $ n $ and so this proves the proposition.
\end{proof}

\pagebreak

\subsubsection{Statement of the Nullstellensatz}

When does $ \II\br{\VV\br{I}} = I $? It turns out that the only reason that this can fail is where elements of the ideal $ I $ have $ n $-th roots which are not in $ I $, just as with the example of $ I = \abr{X^2} $ where $ X^2 \in I $ has a square root $ X $ which is not in $ I $. To state this precisely, we need to recall the definition of the radical of an ideal from commutative algebra.

\begin{definition*}
Let $ I $ be an ideal in a ring $ R $. The \textbf{radical} of $ I $ is
$$ \rad I = \sqrt{I} = \cbr{f \in R \st \exists n > 0, \ f^n \in I}. $$
We say that $ I $ is a \textbf{radical ideal} if $ \rad I = I $.
\end{definition*}

\begin{note*}
If $ I $ is any ideal, then $ \rad I $ is always a radical ideal.
\end{note*}

\begin{theorem}[Hilbert's Nullstellensatz]
\label{thm:strongnullstellensatz}
Let $ I $ be any ideal in the polynomial ring $ k\sbr{X_1, \dots, X_n} $ over an algebraically closed field $ k $. Then we have
$$ \II\br{\VV\br{I}} = \rad I. $$
\end{theorem}

This is a substantial theorem, fundamental to algebraic geometry. We will prove it in a few lectures' time, not because we need to develop more theory, just because I would like to introduce some more concepts first which will allow us to do more with examples.

\begin{note*}
To calculate $ \rad I $, we need to add in $ n $-th roots of all elements of $ I $, not just the generators.
\end{note*}

\begin{example*}
If $ I = \abr{X, Y^2 - X} \subseteq k\sbr{X, Y} $, then we can rewrite this as $ I = \abr{X, Y^2} $ and so $ \rad I = \abr{X, Y} \ne I $, even though neither of the original generators of $ I $ had any non-trivial $ n $-th roots.
\end{example*}

\subsubsection{Basic facts about the Zariski topology}

We have seen that affine algebraic sets in $ \AA^n $ satisfy the following conditions.
\begin{itemize}
\item $ \AA^n $ and $ \emptyset $ are affine algebraic sets.
\item A finite union of affine algebraic sets is an affine algebraic set.
\item An arbitrary intersection of affine algebraic sets is an affine algebraic set.
\end{itemize}
The are precisely the conditions satisfied by the closed sets in a topological space. Therefore, we can define a topological space in which the underlying set is $ \AA^n $ and closed sets are the affine algebraic sets. This is called the \textbf{Zariski topology}. This is a very different topology from the ones you are used to in analysis. In particular, it is a very long way from being Hausdorff. For any affine algebraic set $ V \subseteq \AA^n $, we define the \textbf{Zariski topology} on $ V $ to be the subspace topology on $ V $ induced by the Zariski topology on $ \AA^n $. Thus, a subset of $ V $ is Zariski closed in $ V $ if and only if it is Zariski closed in $ \AA^n $. Thus for closed sets it does not matter whether we say Zariski closed in $ V $ or Zariski closed in $ \AA^n $.

\lecture{4}{Monday}{20/01/20}

\begin{example*}
The Zariski topology on $ \AA^1 $ is the same as the cofinite topology. Prove that the Zariski topology on $ \AA^1 $ is not Hausdorff. \footnote{Exercise}
\end{example*}

Thus we see that the Zariski topology has much fewer closed sets, or much fewer open sets, than for example the Euclidean topology.

\begin{lemma}
Suppose that $ k = \CC $, so there is a Euclidean topology on $ \AA_\CC^n $. If $ V $ is a Zariski closed subset of $ \AA_\CC^n $, then $ V $ is closed in the Euclidean topology, so the Euclidean topology is finer than the Zariski topology.
\end{lemma}

\begin{proof}
Let $ f \in \CC\sbr{X_1, \dots, X_n} $ be a polynomial. It is a continuous function $ \AA_\CC^n \to \CC $ for the Euclidean topology. Since $ \cbr{0} $ is a closed subset of $ \CC $, $ \VV\br{f} = f^{-1}\br{0} $ is a closed subset of $ \AA_\CC^n $ in the Euclidean topology. We conclude by noting that intersections of closed sets are closed.
\end{proof}

\pagebreak

On the other hand, for open sets Zariski open in $ V $ does not mean the same thing as Zariski open in $ \AA^n $. A Zariski open subset of $ V $ need not be Zariski open in $ \AA^n $.

\begin{example*}
Let $ V $ be the $ x $-axis in $ \AA^2 $. Then $ V \setminus \cbr{0} $ is open in $ V $, but not open in $ \AA^2 $.
\end{example*}

The open subsets of the Zariski topology are all very big. This is made precise, for $ \AA^1 $, by the following lemma.

\begin{lemma}
Prove that every pair $ U_1 $ and $ U_2 $ of non-empty open sets in $ \AA^1 $ has a non-empty intersection $ U_1 \cap U_2 $.
\end{lemma}

Hence the Zariski topology on $ \AA^1 $ is not Hausdorff. A subset of $ \AA^1 $ is dense in the Zariski topology if and only if it is infinite. At the moment, the Zariski topology is likely to seem very strange. It might also seem like, what is the point of such a strange topology? We will not use it in a very deep way, it is just a convenient language to be able to talk about open and closed sets. It does get used more seriously in the theory of schemes.

\subsubsection{Connected and irreducible sets}

Recall the definition of a connected topological space.

\begin{definition*}
A topological space $ S $ is \textbf{connected} if it is not possible to write it as the union of two disjoint non-empty open sets. This is equivalent to, it is not possible to write $ S $ as the union of two disjoint non-empty closed sets.
\end{definition*}

It is possible to talk about connectedness in the Zariski topology.

\begin{example*}
A finite set of points of size greater than one is not connected in the Zariski topology, since every subset is closed.
\end{example*}

Consider the following affine algebraic sets in $ \AA^2 $. Do they have one or two pieces? Do they have one or two pieces? I have deliberately not specified what I mean by pieces. There are multiple sensible interpretations, so there is not always a unique correct answer.
\begin{itemize}
\item The union of two disjoint lines $ \VV\br{X\br{X - 1}} $.
\item The union of two intersecting lines $ \VV\br{XY} $.
\item The hyperbola $ \VV\br{XY - 1} $.
\end{itemize}

\begin{example*}
The union of two disjoint lines $ \VV\br{X\br{X - 1}} $ is not connected, since it unambiguously has two pieces, the two lines $ \VV\br{X} $ and $ \VV\br{X - 1} $, and each line is a non-empty closed subset.
\end{example*}

But there is a more refined notion for the Zariski topology.

\begin{example*}
The set $ \VV\br{XY} $ has more than one answer. The two axes form two pieces. It is a union of two lines, intersecting at the origin, joining them into one piece. Describe the Zariski closed subsets. \footnote{Exercise}
\end{example*}

The following notion gives us a way of formally understanding the example described.

\begin{definition*}
A topological space $ S $ is \textbf{reducible} if it is empty, or there exist closed sets $ S_1, S_2 \subseteq S $ such that $ S = S_1 \cup S_2 $, and neither $ S_1 $ nor $ S_2 $ is equal to $ S $. A topological space $ S $ is \textbf{irreducible} if it is non-empty and it is not possible to write it as the union $ S_1 \cup S_2 $ of two closed sets, unless at least one of $ S_1 $ and $ S_2 $ is equal to $ S $ itself. Compared to the second definition of connected, we no longer require $ S_1 $ and $ S_2 $ to be disjoint.
\end{definition*}

This is not a very useful notion for the topological spaces we consider in analysis.

\begin{example*}
Considering the real line with the Euclidean topology, we can write it as a union of proper closed subsets,
$$ \RR = \cbr{x \in \RR \st x \le 0} \cup \cbr{x \in \RR \st x \ge 0}. $$
These subsets are not disjoint because they intersect at zero. Of course, there are many other ways to write $ \RR $ as a union of proper closed subsets in the usual topology. The same is true for any other Hausdorff space.
\end{example*}

\pagebreak

\begin{example*}
The drawing of $ \VV\br{XY - 1} $ in $ \RR^2 $ is misleading. It looks like it has two pieces, but, as mentioned before, we are missing a lot by only looking at real solutions. For algebraic geometry, we need to look at complex solutions, and then over $ \CC $ it unambiguously has one piece. One way to visualise this is to note that, if we project down to the $ x $ coordinate, $ \VV\br{XY - 1} $ looks like the set $ \AA^1 \setminus \cbr{0} $. This is not a formal statement. We have not yet defined a notion of isomorphism of affine algebraic sets, and even if we had, $ \AA^1 \setminus \cbr{0} $ is not an affine algebraic set. In a few weeks we will develop technology to make this into a rigorous statement. But for now we use it as a heuristic. Then $ \RR \setminus \cbr{0} $ unambiguously has two pieces, but $ \CC \setminus \cbr{0} $ is connected in the usual analytic topology on $ \CC $ and unambiguously has one piece. So the hyperbola, over an algebraically closed field, should have only one piece.
\end{example*}

We prove below in the lecture that $ \VV\br{XY - 1} $ is irreducible, and also connected.

\begin{lemma}
The hyperbola $ H = \VV\br{XY - 1} $ is irreducible.
\end{lemma}

\begin{proof}
We need to describe the Zariski closed subsets of $ H $. So let $ V \subseteq H $ be a proper Zariski closed subset. Since $ V \ne H $ there must be some polynomial $ f \in k\sbr{X, Y} $ which vanishes on $ V $ but does not vanish on all of $ H $. Because $ V \subseteq H $ and $ y = 1 / x $ on $ H $, we have $ f\br{x, y} = f\br{x, 1 / x} $ when $ \br{x, y} \in V $. Now $ f\br{X, 1 / X} $ is almost a polynomial in the single variable $ X $, except that it may contain negative powers of $ X $, so
$$ f\br{X, \dfrac{1}{X}} = \sum_{n \in \ZZ} a_nX^n. $$
We can multiply up by $ X^m $ where $ -m $ is the lowest exponent of $ X $ which appears in this expression. Then $ X^mf\br{X, 1 / X} $ is a polynomial in $ X $, which vanishes on $ V $. Furthermore $ f\br{X, 1 / X} $ is not identically zero because $ f $ does not vanish identically on $ H $. Hence $ X^mf\br{X, 1 / X} $ is a non-zero single-variable polynomial, therefore it has only finitely many roots. The roots of $ X^mf\br{X, 1 / X} = 0 $ are the possible $ x $ coordinates for points in $ V $. For each value of $ x $, there is at most one possible $ y $ such that $ \br{x, y} \in V $ because $ y = 1 / x $ on $ V $. Therefore $ V $ is finite. Thus we have shown that all proper Zariski closed subsets of $ H $ are finite. In particular, if $ V_1 $ and $ V_2 $ are two proper Zariski closed subsets of $ H $, they are both finite and so their union is finite. Hence $ V_1 \cup V_2 \ne H $ so $ H $ is irreducible.
\end{proof}

Thus the Zariski topology on $ H $ is the cofinite topology. Here is a bonus fact about connected sets in the Zariski topology which I did not mention in the lecture. The proof is surprisingly hard.

\begin{theorem}
Over $ \CC $, an affine algebraic set is connected in the Zariski topology if and only if it is connected in the Euclidean topology.
\end{theorem}

\subsubsection{Prime ideals and irreducible sets}

If $ V $ is an affine algebraic set, what condition on the ideal $ \II\br{V} $ is equivalent to $ V $ being irreducible?

\lecture{5}{Thursday}{23/01/20}

\begin{definition*}
From commutative algebra, an ideal $ I $ in a ring $ R $ is a \textbf{prime ideal} if $ I \ne R $ and for every $ f, g \in R $, if $ fg \in I $, then $ f \in I $ or $ g \in I $, or both.
\end{definition*}

\begin{lemma}
\label{lem:irreducibleprime}
An affine algebraic set $ V \subseteq \AA^n $ is irreducible if and only if $ \II\br{V} $ is a prime ideal in $ k\sbr{X_1, \dots, X_n} $.
\end{lemma}

\begin{proof}
First suppose that $ V $ is irreducible. Suppose we have $ f, g \in k\sbr{X_1, \dots, X_n} $ such that $ fg \in \II\br{V} $. Let
$$ V_1 = \cbr{\underline{x} \in V \st f\br{\underline{x}} = 0}, \qquad V_2 = \cbr{\underline{x} \in V \st g\br{\underline{x}} = 0}. $$
For every $ \underline{x} \in V $, $ f\br{\underline{x}}g\br{\underline{x}} = 0 $ and hence either $ f\br{\underline{x}} = 0 $ or $ g\br{\underline{x}} = 0 $. Thus for every $ \underline{x} \in V $, either $ \underline{x} \in V_1 $ or $ \underline{x} \in V_2 $. In other words, $ V = V_1 \cup V_2 $. Furthermore $ V_1 $ and $ V_2 $ are closed subsets of $ V $. Hence as $ V $ is irreducible, either $ V_1 = V $ or $ V_2 = V $. If $ V_1 = V $ then $ f \in \II\br{V} $ and if $ V_2 = V $ then $ g \in \II\br{V} $. Now suppose that $ V $ is reducible. Then we can write it as a union $ V_1 \cup V_2 $ of proper closed subsets. Since $ V_1 $ is a proper closed subset of $ V $, there exists some $ f \in k\sbr{X_1, \dots, X_n} $ vanishing on $ V_1 $ but not on all of $ V $. Similarly there exists $ g $ vanishing on $ V_2 $ but not on all of $ V $. Thus neither $ f $ nor $ g $ is in $ \II\br{V} $, but the product $ fg $ vanishes on $ V_1 \cup V_2 $ and hence we have $ fg \in \II\br{V} $. Thus $ \II\br{V} $ is not prime. Then $ V $ is empty if and only if $ \II\br{V} = k\sbr{X_1, \dots, X_n} $, which is explicitly defined to not be a prime ideal. So it was ok to ignore this case above.
\end{proof}

\pagebreak

\begin{definition*}
A \textbf{hypersurface} is an affine algebraic set in $ \AA^n $ defined by one polynomial equation, that is,
$$ \cbr{\underline{x} \in \AA^n \st f\br{\underline{x}} = 0}, \qquad f \in k\sbr{X_1, \dots, X_n}. $$
\end{definition*}

It follows from Lemma \ref{lem:irreducibleprime} together with Hilbert's Nullstellensatz that a hypersurface defined by a polynomial $ f $ is irreducible if and only if $ f $ is a power of an irreducible polynomial. See problem sheet $ 1 $.

\begin{example*}
We can use this to prove that the circle $ \cbr{\br{x, y} \st x^2 + y^2 = 1} $ is irreducible, by proving that the polynomial $ X^2 + Y^2 - 1 $ is irreducible. This is because, if $ f = X^2 + Y^2 - 1 = f_1f_2 $ then we can scale $ f_1 $ and $ f_2 $ by constants to get
$$ f_1 = X + g_1\br{Y}, \qquad f_2 = X + g_2\br{Y}, $$
since $ f $ has degree two in $ X $ and its $ X^2 $ term has coefficient one. Since $ f $ has no $ X $ term, we must have $ g_1 + g_2 = 0 $. But then
$$ f_1f_2 = \br{X + g_1\br{Y}}\br{X - g_1\br{Y}} = X^2 - g_1\br{Y}^2, $$
so $ g_1\br{Y}^2 = -Y^2 + 1 $, and $ -Y^2 + 1 $ is not a square. On the other hand, the hypersurface $ \cbr{\br{x, y} \st x^2 + y^2 = 0} $ is reducible, because $ X^2 + Y^2 $ factors as $ \br{X - iY}\br{X + iY} $.
\end{example*}

It can often be convenient to rewrite the definition of irreducible spaces in terms of open sets instead of closed sets.

\begin{lemma}
\label{lem:irreducibleopen}
The following conditions on a topological space $ S $ are equivalent to irreducibility.
\begin{itemize}
\item $ S $ is non-empty, and every pair of non-empty open subsets $ U_1, U_2 \subseteq S $ have non-empty intersection $ U_1 \cap U_2 $.
\item $ S $ is non-empty, and every non-empty open subset of $ S $ is dense in $ S $.
\end{itemize}
\end{lemma}

\begin{proof}
Just manipulation of the topological definition.
\end{proof}

\begin{corollary}
\label{cor:irreducibleopen}
Let $ S $ be a irreducible topological space and $ U \subseteq S $ a non-empty open subset. Then $ U $ is irreducible, in the subspace topology.
\end{corollary}

Lemma \ref{lem:irreducibleopen} says that irreducible is a very long way from Hausdorff. The Hausdorff condition says that a space has lots of pairs of disjoint non-empty open subsets, while an irreducible space has none.

\begin{example*}
We saw that $ \RR $, with the Euclidean topology, is reducible in many ways.
\end{example*}

Corollary \ref{cor:irreducibleopen} implies that $ \AA^1 \setminus \cbr{0} $ is irreducible, in the subspace topology induced by the Zariski topology on $ \AA^1 $, because it is open in $ \AA^1 $. Compare this to the fact that the hyperbola $ H $ is irreducible. This lends support to the heuristic argument that the hyperbola $ H $ is irreducible, but it is not a proof. Checking that the subspace topology on $ \AA^1 \setminus \cbr{0} $ is the same as the Zariski topology on $ H $ would require exactly the same work as the proof that $ H $ is irreducible to prove that the Zariski topology on $ H \subseteq \AA^2 $.

\subsubsection{Irreducible components}

Just like the definition of connected components, we can define the following.

\begin{definition*}
Let $ S $ be a topological space. An \textbf{irreducible component} of $ S $ is a maximal irreducible subset of $ S $.
\end{definition*}

Unlike connected components, irreducible components need not be disjoint.

\begin{example*}
The irreducible components of $ \cbr{\br{x, y} \st xy = 0} $ are the lines $ x = 0 $ and $ y = 0 $, which intersect in $ \cbr{\br{0, 0}} $.
\end{example*}

More generally, the irreducible components of a hypersurface $ \VV\br{f} $ correspond to the irreducible factors of $ f $. If $ f = f_1^{a_1} \dots f_m^{a_m} $, where the $ f_i $ are distinct irreducible polynomials, then the irreducible components of $ \VV\br{f} $ are $ \VV\br{f_1}, \dots, \VV\br{f_m} $. Irreducible components have the following key properties.

\pagebreak

\begin{proposition}
\label{prop:irreduciblecomponent}
Let $ V $ be an affine algebraic set. Then
\begin{enumerate}
\item the union of the irreducible components of $ V $ is all of $ V $, and
\item $ V $ has only finitely many irreducible components.
\end{enumerate}
\end{proposition}

Proposition \ref{prop:irreduciblecomponent}.$ 1 $ matches a property of connected components. Proposition \ref{prop:irreduciblecomponent}.$ 2 $ does not apply to the connected components of an arbitrary topological space.

\begin{example*}
$ \ZZ $ or $ \QQ $ with the subspace topology from $ \RR $.
\end{example*}

\begin{note*}
Proposition \ref{prop:irreduciblecomponent}.$ 2 $ does imply that an affine algebraic set has only finitely many connected components for the Zariski topology, because each connected component must be a union of irreducible components.
\end{note*}

Proposition \ref{prop:irreduciblecomponent}.$ 2 $ is a finiteness statement, so it is not surprising that it follows from the Noetherian property, the descending chain condition on closed subsets. The key idea in the proof is as follows. If an affine algebraic set is reducible, then we can write it as a union of proper closed subsets. If these subsets are reducible, then we can write them in turn as unions of proper closed subsets. The following lemma says that this process eventually stops. After finitely many steps, we reach irreducible sets.

\begin{lemma}
\label{lem:irreducibleclosed}
Every affine algebraic set can be written as a union of finitely many irreducible closed subsets.
\end{lemma}

\begin{proof}
Suppose that $ V $ is an affine algebraic set which cannot be written as a union of finitely many irreducible closed subsets. Then $ V $ must be reducible, otherwise we could write it as a union of one irreducible closed subset. So $ V = V_1 \cup W_1 $, with $ V_1 $ and $ W_1 $ proper closed subsets of $ V $. Then $ V_1 $ and $ W_1 $ cannot both be unions of finitely many irreducible closed subsets, because taking the union of those decompositions would give us $ V $ as a union of finitely many irreducible closed subsets. Thus at least one of $ V_1 $ and $ W_1 $ does not satisfy Lemma \ref{lem:irreducibleclosed}. Without loss of generality, we may suppose that $ V_1 $ does not satisfy Lemma \ref{lem:irreducibleclosed}. Then $ V_1 $ must be reducible, so we can write $ V_1 = V_2 \cup W_2 $. We can repeat the argument. At least one of $ V_2 $ and $ W_2 $ does not satisfy Lemma \ref{lem:irreducibleclosed}, without loss of generality $ V_2 $, etc. Thus we build up a chain of closed subsets $ V \supset V_1 \supset V_2 \supset \dots $ where all these sets do not satisfy Lemma \ref{lem:irreducibleclosed}, and all the inclusions are strict. This contradicts Lemma \ref{lem:descendingchain}, the descending chain condition for affine algebraic sets.
\end{proof}

In order to prove Proposition \ref{prop:irreduciblecomponent}, we want to show that the finitely many irreducible closed subsets in Lemma \ref{lem:irreducibleclosed} are the irreducible components. There is just one wrinkle. Consider $ V = \VV\br{XY} $. The irreducible components are $ \VV\br{X} $ and $ \VV\br{Y} $. But we could write $ V $ as a union of finitely many irreducible closed subsets by saying
$$ V = \VV\br{X} \cup \VV\br{Y} \cup \cbr{\br{0, 2}}. $$
Thus we can always add in extra sets to a decomposition as in Lemma \ref{lem:irreducibleclosed}, where the extra sets are contained in one of the other sets in the decomposition. Of course we can always just throw away these empty sets from the list without changing the union. Let $ V = V_1 \cup \dots \cup V_r $, as in Lemma \ref{lem:irreducibleclosed}. By throwing away any $ V_i $ which is contained in another $ V_j $, we can assume that $ V_i \not\subseteq V_j $ whenever $ i \ne j $, and still the union of the $ V_j $'s will be $ V $. Subject to this non-redundancy condition, there is only one way to write $ V $ as a finite union of irreducible closed subsets and we can prove the following.

\begin{proposition}
\label{prop:irreducibleclosed}
Let $ V $ be an affine algebraic set. Write $ V = V_1 \cup \dots \cup V_r $, where the $ V_i $ are irreducible closed subsets and $ V_i \not\subseteq V_j $ for $ i \ne j $. Then $ V_1, \dots, V_r $ are precisely the irreducible components of $ V $.
\end{proposition}

\begin{proof}
First we show that each $ V_i $ is an irreducible component. By hypothesis, $ V_i $ is irreducible. So if $ V_i $ is not an irreducible component, it is not a maximal irreducible set and must be contained in a larger irreducible set $ W \subseteq V $. But then
$$ W = \br{V_1 \cap W} \cup \dots \cup \br{V_r \cap W}, $$
where $ V_1 \cap W, \dots, V_r \cap W $ are closed subsets of $ W $. Because $ W $ is irreducible, we must have $ W = V_j \cap W $ for some $ j $. Thus $ V_i \subseteq W \subseteq V_j $. By the condition $ V_i \not\subseteq V_j $ for any $ j \ne i $, we must have $ i = j $ and $ W = V_i $. Thus $ V_i $ is an irreducible component of $ V $. Conversely, let $ C $ be an irreducible component of $ V $. Then
$$ C = \br{V_1 \cap C} \cup \dots \cup \br{V_r \cap C}. $$
By the same argument as before, the irreducibility of $ C $ implies that $ C \subseteq V_i $ for some $ i $. Then the maximality of $ C $ implies that $ C = V_i $.
\end{proof}

The combination of Lemma \ref{lem:irreducibleclosed} and Proposition \ref{prop:irreducibleclosed} proves both Proposition \ref{prop:irreduciblecomponent}.$ 1 $ and Proposition \ref{prop:irreduciblecomponent}.$ 2 $.

\pagebreak

\subsubsection{Primary decomposition of ideals}

The irreducible component decomposition of an affine algebraic set can give a geometric understanding of the primary decomposition of ideals in the Noetherian ring $ k\sbr{X_1, \dots, X_n} $. However, the irreducible decomposition gives only partial information about the primary decomposition of an ideal, because ideals contain more information than affine algebraic sets. Recall that the algebraic set depends only on the radical of the ideal.

\begin{example*}
Let $ I = \abr{X^2, XY} \subseteq k\sbr{X, Y} $. Then $ \VV\br{I} $ is simply the line $ X = 0 $, which of course is irreducible. However a primary decomposition of $ I $ is
$$ I = \abr{X} \cap \abr{X^2, XY, Y^2}. $$
Here $ \abr{X} $ is the ideal of the line $ X = 0 $, the unique irreducible component of $ V = \VV\br{I} $. The ideal $ \abr{X^2, XY, Y^2} $ defines the point $ \cbr{\br{0, 0}} $, which is contained in $ V $ so is not an irreducible component.
\end{example*}

Thus the minimal associated primes of the primary decomposition of $ I $ corespond to the irreducible components of $ \VV\br{I} $, while non-minimal associated primes correspond to additional smaller sets strictly contained in the irreducible components, called \textbf{embedded components}. In scheme theory, we can think of $ \VV\br{I} $ as containing multiple copies of these embedded components.

\begin{example*}
The ideal $ I = \abr{X^2, XY} $ corresponds, in the world of schemes, to the line $ X = 0 $ with two copies of the origin.
\end{example*}

\subsection{Regular and rational maps}

\subsubsection{Regular functions}

\lecture{6}{Friday}{24/01/20}

So far we have only considered algebraic sets as sets, sitting individually. Now we look at functions between them. Just as one uses continuous functions for topological spaces, holomorphic functions for complex manifolds, homomorphisms for groups, etc, so algebraic geometry has its own type of functions, regular functions. Of course, these are given by polynomials.

\begin{definition*}
Let $ V \subseteq \AA^n $ be an affine algebraic set. A \textbf{regular function} on $ V $ is a function $ f : V \to k $ such that there exists a polynomial $ F \in k\sbr{X_1, \dots, X_n} $ with $ f\br{\underline{x}} = F\br{\underline{x}} $ for all $ \underline{x} \in V $.
\end{definition*}

\begin{note*}
The polynomial $ F $ is not uniquely determined by the function $ f $, since $ F, G \in k\sbr{X_1, \dots, X_n} $ determine the same regular function on $ V $ if and only if $ F - G $ vanishes on $ V $, that is if and only if $ F - G \in \II\br{V} $.
\end{note*}

\begin{definition*}
The regular functions on $ V $ form a $ k $-algebra. They can be added and multiplied by each other, and multiplied by scalars in $ k $. This is called the \textbf{coordinate ring} of $ V $ and denoted $ k\sbr{V} $.
\end{definition*}

There is a ring homomorphism $ k\sbr{X_1, \dots, X_n} \to k\sbr{V} $ which sends a polynomial $ F $ to the function $ \eval{F}_V $ which it defines on $ V $. This homomorphism is surjective and its kernel is $ \II\br{V} $, so
$$ k\sbr{V} \cong k\sbr{X_1, \dots, X_n} / \II\br{V}. $$

\begin{example*}
What are the coordinate rings of the following affine algebraic sets?
\begin{itemize}
\item The coordinate ring of $ \AA^n $ is $ k\sbr{X_1, \dots, X_n} $.
\item The coordinate ring of a point is $ k $. A regular function on a point is just a single value.
\item The coordinate ring of two points $ \cbr{x \in \AA^1 \st x\br{x - 1} = 0} $ is $ k \times k $. A regular function on two points is determined by two scalars, namely its value on each of the two points. For any pair of values $ \br{a, b} \in k \times k $, one can easily write down a polynomial $ f \in k\sbr{X} $ such that $ f\br{1} = a $ and $ f\br{0} = b $. Alternatively, one can check algebraically that the map
$$ \function{k \times k}{k\sbr{X} / \abr{X\br{X - 1}}}{\br{a, b}}{\br{a - 1}X + b \mod \abr{X\br{X - 1}}} $$
is a $ k $-algebra isomorphism. This example generalises. If $ V $ is a disconnected affine algebraic set, we can write $ V $ as a union $ V_1 \cup V_2 $ of disjoint Zariski closed subsets, and then $ k\sbr{V} = k\sbr{V_1} \times k\sbr{V_2} $. On the other hand, if $ V $ is reducible but connected, so that the sets $ V_1 $ and $ V_2 $ are not disjoint, then $ k\sbr{V} $ is a proper subset of $ k\sbr{V_1} \times k\sbr{V_2} $.

\pagebreak

\item The coordinate ring of two intersecting lines $ \cbr{\br{x, y} \in \AA^2 \st xy = 0} $ is
$$ \cbr{\br{f, g} \in k\sbr{X} \times k\sbr{Y} \st f\br{0} = g\br{0}}. $$
To prove this, one can also interpret this as
$$ k\sbr{X, Y} / \abr{XY} \cong \cbr{a_0 + \sum_{r = 1}^m b_rX^r + \sum_{s = 1}^n c_sY^s \st a_0, b_1, \dots, b_m, c_1, \dots, c_n \in k, \ m, n \in \NN}. $$
We can compare these two descriptions by observing that
$$ k\sbr{X} = \cbr{a_0 + \sum_{r = 1}^m b_rX^r}, \qquad k\sbr{Y} = \cbr{a_0 + \sum_{s = 1}^n c_sY^s}, $$
and the condition that $ f\br{0} = g\br{0} $ is equivalent to insisting that these two polynomials have the same constant coefficient $ a_0 $. This does not generalise to arbitrary reducible algebraic sets. We may have $ V = V_1 \cup V_2 $ where $ V_1 $ and $ V_2 $ are closed subsets, but
$$ k\sbr{V} \ne \cbr{\br{f, g} \in k\sbr{V_1} \times k\sbr{V_2} \st \eval{f}_{V_1 \cap V_2} = \eval{g}_{V_1 \cap V_2}}. $$
There will be an example of this on problem sheet $ 2 $.
\item The coordinate ring of a hyperbola $ \cbr{\br{x, y} \in \AA^2 \st xy - 1 = 0} $ is the quotient ring $ k\sbr{X, Y} / \abr{XY - 1} $. To describe this more explicitly, note that any term of a two-variable polynomial is
$$ a_{r, s}X^rY^s \equiv
\begin{cases}
a_{r, s}X^{r - s} & r \ge s \\
a_{r, s}Y^{s - r} & s > r
\end{cases}
\mod \abr{XY - 1}.
$$
Thus every coset in $ k\sbr{X, Y} / \abr{XY - 1} $ has a representative of the form
$$ \sum_{i = 0}^m a_iX^i + \sum_{j = 1}^n a_jY^j. $$
The polynomials of this form determine different functions on $ V $, so we have written down exactly one representative of each coset. Furthermore, since $ XY = 1 $ in $ k\sbr{V} $, we may relabel $ Y $ as $ X^{-1} $. Then the multiplication rule will be what the notation leads us to expect. So we can write
$$ k\sbr{V} = k\sbr{X, X^{-1}} = \cbr{\sum_{j = -n}^m a_jX^m \st a_{-n}, \dots, a_m \in k, \ m, n \in \NN}. $$
\end{itemize}
\end{example*}

\begin{lemma}
An affine algebraic set $ V $ is irreducible if and only if $ k\sbr{V} $ is an integral domain.
\end{lemma}

\begin{proof}
$ V $ is irreducible if and only if $ \II\br{V} $ is a prime ideal in $ k\sbr{X_1, \dots, X_n} $.
\end{proof}

\subsubsection{Regular maps}

A regular function goes from an algebraic set $ V $ to the field $ k $. We can also define regular maps, which go from one algebraic set $ V $ to another algebraic set $ W $.

\begin{definition*}
Let $ V \subseteq \AA^m $ and $ W \subseteq \AA^n $ be affine algebraic sets. A \textbf{regular map} $ \phi : V \to W $ is a function $ V \to W $ such that there exist polynomials $ F_1, \dots, F_n \in k\sbr{X_1, \dots, X_n} $ such that $ \phi\br{\underline{x}} = \br{F_1\br{\underline{x}}, \dots, F_n\br{\underline{x}}} $ for all $ \underline{x} \in V $. Regular maps are often called \textbf{morphisms}.
\end{definition*}

\begin{note*}
In order to check that a given list of polynomials $ F_1, \dots, F_n $ defines a regular map $ V \to W $, it is necessary to check that $ \br{F_1\br{\underline{x}}, \dots, F_n\br{\underline{x}}} \in W $ for every $ \underline{x} \in V $. Equivalently, we need to check that the regular functions $ \eval{F_1}_V, \dots, \eval{F_n}_V \in k\sbr{V} $ satisfy the equations $ g\br{\eval{F_1}_V, \dots, \eval{F_n}_V} = 0 $ in the coordinate ring $ k\sbr{V} $, for each polynomial $ g \in \II\br{W} $.
\end{note*}

\pagebreak

\begin{example*}
\hfill
\begin{itemize}
\item Let $ V \subseteq \AA^m $ be an affine algebraic set. For any $ n < m $, the projection defined by
$$ \function[\pi]{V}{\AA^n}{\br{x_1, \dots, x_m}}{\br{x_1, \dots, x_n}} $$
is a regular map.
\item A regular function on $ V $ is the same thing as a regular map $ V \to \AA^1 $.
\item Let $ C = \cbr{\br{x, y} \st y^2 = x^3} $. Then
$$ \function{\AA^1}{C}{t}{\br{t^2, t^3}} $$
is a regular map.
\item Consider $ \SL_n $, the set of $ n \times n $ matrices with determinant one. This is an affine algebraic set in $ \AA^{n^2} $ because the determinant is a polynomial in the entries of a matrix. The map
$$ \function{\SL_n}{\SL_n}{a}{a^{-1}} $$
is a regular map. Cramer's rule tells us how to write each entry of $ a^{-1} $ as a polynomial in the entries of $ a $ divided by $ \det a $, and because we are only considering $ a \in \SL_n $ we can drop the division by $ \det a $.
\end{itemize}
\end{example*}

A regular map $ \phi : V \to W $ is a continuous function with respect to the Zariski topology. This is because, if $ A \subseteq W $ is a Zariski closed subset defined by polynomials $ f_1, \dots, f_r $, then $ \phi^{-1}\br{A} $ is the zero set
$$ \phi^{-1}\br{A} = \cbr{x \in V \st \br{f_1 \circ \phi}\br{x} = 0, \ \dots, \ \br{f_r \circ \phi}\br{x} = 0}, $$
and therefore $ \phi^{-1}\br{A} $ is a Zariski closed subset of $ V $. In complex analysis, holomorphic is a much stricter condition than continuous in the Euclidean topology, and similarly regular is much stricter than continuous in the Zariski topology. The following fact is very useful.

\begin{lemma}
\label{lem:affinedense}
Let $ \phi, \psi : V \to W $ be regular maps. If there exists a Zariski dense subset $ A \subseteq V $ such that $ \eval{\phi}_A = \eval{\psi}_A $, then $ \phi = \psi $ on all of $ V $.
\end{lemma}

\begin{note*}
If $ X $ and $ Y $ are Hausdorff topological spaces, then any continuous maps $ X \to Y $ which agree on a dense set must agree everywhere. However Lemma \ref{lem:affinedense} does not follow immediately from the fact that regular maps are continuous, because the Zariski topology is not Hausdorff, and is definitely false if we try to generalise it to all continuous maps with respect to the Zariski topology. Thus in order to prove Lemma \ref{lem:affinedense}, we have to use something special about regular maps as opposed to general continuous maps.
\end{note*}

\begin{proof}
Write $ \phi = \br{F_1, \dots, F_m} $ and $ \psi = \br{G_1, \dots, G_m} $, where $ F_1, \dots, F_m, G_1, \dots, G_m $ are polynomials. Then $ F_i - G_i $ is also a polynomial for each $ i $, and so
$$ V' = \cbr{\underline{x} \in V \st \phi\br{\underline{x}} = \psi\br{\underline{x}}} = \cbr{\underline{x} \in V \st \forall i, \ \br{F_i - G_i}\br{\underline{x}} = 0} $$
is a Zariski closed subset of $ V $. But we know that $ V' $ contains $ A $, which is Zariski dense in $ V $. Hence $ V' = V $.
\end{proof}

\subsubsection{Isomorphisms}

\lecture{7}{Monday}{27/01/20}

\begin{definition*}
A regular map $ \phi : V \to W $ is an \textbf{isomorphism} if there exists a regular map $ \psi : W \to V $ such that $ \psi \circ \phi = \id_V $ and $ \phi \circ \psi = \id_W $.
\end{definition*}

\begin{example*}
If $ V $ is the parabola $ \cbr{\br{x, y} \st y - x^2 = 0} $, then the regular map given by
$$ \function[\phi]{V}{\AA^1}{\br{x, y}}{x} $$
is an isomorphism because it has an inverse given by
$$ \function[\psi]{\AA^1}{V}{x}{\br{x, x^2}}. $$
\end{example*}

\pagebreak

\begin{example*}
On the other hand, if $ H $ is the hyperbola $ \cbr{\br{x, y} \st xy = 1} $, then the projection
$$ \function{H}{\AA^1}{\br{x, y}}{x} $$
is not an isomorphism because it is not surjective so it cannot possibly have an inverse. This is not enough to prove that $ H $ is not isomorphic to $ \AA^1 $, because maybe there is some other regular map $ H \to \AA^1 $ which is an isomorphism. We will soon prove that $ H $ is not isomorphic to $ \AA^1 $.
\end{example*}

\begin{example*}
Consider the affine algebraic set $ W = \cbr{\br{x, y} \st y^2 - x^3 = 0} $. The regular map given by
$$ \function[\phi]{\AA^1}{W}{t}{\br{t^2, t^3}} $$
is a bijection but it is not an isomorphism. Note that we should expect $ W $ not to be isomorphic to $ \AA^1 $ because it has a singularity at the origin. To prove that $ \phi : \AA^1 \to W $ is not an isomorphism, consider a regular map $ \psi : W \to \AA^1 $. It must be given by a polynomial $ g\br{X, Y} \in k\sbr{X, Y} $ and so $ \br{\psi \circ \phi}\br{t} = \psi\br{t^2, t^3} $ is a polynomial in $ t $ which can have a constant term and terms of degree two or greater, but no term of degree one. Hence we cannot find $ \psi $ such that $ \br{\psi \circ \phi}\br{t} = t $.
\end{example*}

\subsubsection{Regular maps and \texorpdfstring{$ k $}{k}-algebra homomorphisms}

Suppose we have a regular map $ \phi : V \to W $ between affine algebraic sets. For each regular function $ g $ on $ W $, we get a regular function $ \phi^*g $ on $ V $ defined by
$$ \function[\phi^*]{k\sbr{W}}{k\sbr{V}}{g}{g \circ \phi}. $$
We call $ \phi^*g \in k\sbr{V} $ the \textbf{pull-back} of $ g \in k\sbr{W} $. Thus $ \phi $ induces a $ k $-algebra homomorphism $ \phi^* : k\sbr{W} \to k\sbr{V} $.

\begin{note*}
$ \phi^* $ goes in the opposite direction to $ \phi $.
\end{note*}

If we have two regular maps $ \phi : V \to W $ and $ \psi : W \to Z $, then we can compose them to get $ \psi \circ \phi : V \to Z $. One can easily check that the associated pull-back maps on coordinate rings satisfy
$$ \br{\psi \circ \phi}^* = \phi^* \circ \psi^* : k\sbr{Z} \to k\sbr{V}. $$
For those who know category theory, we say that $ V \mapsto k\sbr{V} $ is a contravariant functor
$$ \cbr{\text{affine algebraic sets}} \to \cbr{\text{$ k $-algebras}}. $$
In particular, this tells us that if $ \phi : V \to W $ is an isomorphism with inverse $ \psi : W \to V $, then $ \psi^* \circ \phi^* = \id $ and $ \phi^* \circ \psi^* = \id $. Thus if $ V $ and $ W $ are isomorphic affine algebraic sets, then their coordinate rings $ k\sbr{V} $ and $ k\sbr{W} $ are isomorphic as $ k $-algebras.

\begin{example*}
Now we can prove that the hyperbola $ H $ is not isomorphic to $ \AA^1 $, because $ k\sbr{H} = k\sbr{X, X^{-1}} $ is not isomorphic to $ k\sbr{\AA^1} = k\sbr{X} $. To verify that these $ k $-algebras are not isomorphic, observe that in $ k\sbr{X} $ the only invertible elements are the scalars, while $ k\sbr{X, X^{-1}} $ contains non-scalar invertible elements, such as $ X $.
\end{example*}

\begin{example*}
We can similarly prove that $ \AA^1 $ is not isomorphic to the singular cubic $ W = \cbr{\br{x, y} \st y^2 = x^3} $. We saw earlier that $ k\sbr{W} $ is the ring of polynomials in one variable with no term of degree one, that is
$$ k\sbr{W} = \cbr{a_0 + \sum_{r = 2}^m a_rX^r \st a_0, a_2, \dots, a_m \in k}. $$
To prove that $ k\sbr{W} $ is not isomorphic to $ k\sbr{\AA^1} = k\sbr{X} $, observe that $ k\sbr{X} $ is a unique factorisation domain but $ k\sbr{W} $ is not because $ \abr{X^2}^3 = \abr{X^3}^2 $, and $ X^2 $ and $ X^3 $ are both irreducible in $ k\sbr{W} $.
\end{example*}

\pagebreak

\subsubsection{Rational functions}

Informally, rational functions are functions on varieties defined by polynomial fractions, for example the function $ x \mapsto 1 / x $ on $ \AA^1 $. Observe that this is not really a function $ \AA^1 \to \AA^1 $ because it is not defined at $ x = 0 $, but it is a genuine function on the Zariski open subset $ \AA^1 \setminus \cbr{0} $. These are analogues of meromorphic functions in complex analysis. Just as with regular functions and regular maps, we first define rational functions, which take values in $ k $, then rational maps, which go into any algebraic set. We make this definition only for irreducible affine algebraic sets because, as we saw in the example of $ 1 / x $, a rational function defines a genuine function on a Zariski open subset of $ V $, and irreducibility guarantees that all open subsets of $ V $ are dense in $ V $, so that a function defined on an open subset really is defined almost everywhere on $ V $.

\begin{definition*}
Let $ V $ be an irreducible affine algebraic set. The \textbf{function field} of $ V $ is the field of fractions of the coordinate ring $ k\sbr{V} $. We denote this by $ k\br{V} $.
\end{definition*}

\begin{note*}
$ k\sbr{V} $ is an integral domain because $ V $ is irreducible, and therefore $ k\sbr{V} $ has a field of fractions.
\end{note*}

\begin{example*}
The function field of $ \AA^1 $ is $ k\br{X} $, the fraction field of the polynomial ring $ k\sbr{X} $.
\end{example*}

\begin{definition*}
A \textbf{rational function} on $ V $ is an element of the function field $ k\br{V} $. Thus a rational function can be written in the form $ f / g $, where $ f $ and $ g $ are regular functions. There may be many different choices for $ f $ and $ g $ which define the same rational function $ f / g $.
\end{definition*}

\begin{definition*}
We say that a rational function $ \phi \in k\br{V} $ is \textbf{regular} at a point $ x \in V $ if there exist regular functions $ f, g \in k\sbr{V} $ such that $ \phi = f / g $ and $ g\br{x} \ne 0 $.
\end{definition*}

Thus regular points are precisely the points at which we can assign a value to $ \phi\br{x} $. If $ g\br{x} \ne 0 $, then we can define $ \phi\br{x} = f\br{x} / g\br{x} $.

\begin{note*}
We are allowed to choose different fractions $ f / g $ representing $ \phi $ at different points $ x \in V $, in order to show that those points are regular. The value $ \phi\br{x} $ is independent of which fraction representing $ \phi $ we choose, as long as it has $ g\br{x} \ne 0 $.
\end{note*}

\begin{example*}
Consider the algebraic set defined by the equation $ XY = ZT $ in $ \AA^4 $. Let $ \phi = X / Z \in k\br{V} $. The defining equation implies that we also have $ \phi = T / Y $. Looking at the fraction $ X / Z $ shows us that $ \phi $ is regular wherever $ Z \ne 0 $, and looking at the fraction $ T / Y $ shows us that $ \phi $ is regular wherever $ Y \ne 0 $. On the other hand, $ \phi $ is not regular on the closed subset $ Y = Z = 0 $. One can verify that there is no other fraction representing $ \phi $ which is non-zero on this closed subset.
\end{example*}

\lecture{8}{Thursday}{30/01/20}

Let $ V $ be an irreducible affine algebraic set. Let $ \phi \in k\br{V} $ be a rational function.

\begin{definition*}
The set of points where $ \phi $ is regular is called the \textbf{domain of definition} of $ \phi $, and denoted $ \dom \phi $.
\end{definition*}

This is the set of points where it makes sense to assign a value to $ \phi\br{x} $. For $ x \in \dom \phi $, the value $ \phi\br{x} $ is independent of which fraction $ f / g $ we choose to represent $ \phi $, as long as $ g\br{x} \ne 0 $.

\begin{lemma}
\label{lem:domaindefinition}
The domain of definition of a rational function $ \phi \in k\br{V} $ is a non-empty Zariski open subset of $ V $.
\end{lemma}

\begin{proof}
Consider the set of all possible fractions $ f / g $ with $ f, g \in k\sbr{V} $ representing $ \phi \in k\br{V} $. The set of points at which $ \phi $ is not regular is the intersection of the Zariski closed sets $ \cbr{x \in V \st g\br{x} = 0} $ across all these fractions. Hence the set of points at which $ \phi $ is not regular is a Zariski closed subset of $ V $. The domain of definition is the complement of this set, and therefore is Zariski open. To show that the domain of definition is non-empty, pick a single fraction $ f / g $ representing $ \phi \in k\br{V} $. The regular function $ g $ is not equal to zero as an element of $ k\sbr{V} $, by the definition of the field of fractions, so $ \cbr{x \in V \st g\br{x} = 0} $ is a proper closed subset of $ V $. The domain of definition contains the complement of this set, namely $ \cbr{x \in V \st g\br{x} \ne 0} $, and hence is non-empty.
\end{proof}

\begin{note*}
Every regular function $ f \in k\sbr{V} $ is also a rational function $ f / 1 \in k\br{V} $, and its domain of definition is all of $ V $.
\end{note*}

\pagebreak

The converse also holds.

\begin{lemma}
\label{lem:rationalregular}
Let $ \phi \in k\br{V} $ be a rational function whose domain of definition is equal to $ V $. Then $ \phi $ is a regular function on $ V $.
\end{lemma}

\begin{proof}
Since $ \dom \phi = V $, for each point $ x \in V $, we can choose regular functions $ f_x, g_x \in k\sbr{V} $ such that $ \phi = f_x / g_x $ and $ g_x\br{x} \ne 0 $. Let $ I \subseteq k\sbr{V} $ denote the ideal generated by the functions $ g_x $. Because $ k\sbr{V} $ is Noetherian, we can pick finitely many of these functions $ g_{x_1}, \dots, g_{x_m} $ which still generate $ I $. For each $ x \in V $, there is some $ g_x \in I $ which is non-zero at $ x $. Hence the Zariski closed subset of $ V $ defined by $ \cbr{x \in V \st \forall h \in I, \ h\br{x} = 0} $ is empty. Then the Nullstellensatz implies that $ I $ is all of $ k\sbr{V} $. In particular, $ 1 \in I $. Since $ I = \abr{g_{x_1}, \dots, g_{x_m}} $, there exist $ u_1, \dots, u_m \in k\sbr{V} $ such that $ 1 = u_1g_{x_1} + \dots + u_mg_{x_m} $ in $ k\sbr{V} $. We can now calculate
$$ \phi = \br{u_1g_{x_1} + \dots + u_mg_{x_m}}\phi = u_1g_{x_1}\dfrac{f_{x_1}}{g_{x_1}} + \dots + u_mg_{x_m}\dfrac{f_{x_m}}{g_{x_m}} = u_1f_{x_1} + \dots + u_mf_{x_m}. $$
Since $ u_i, f_{x_i} \in k\sbr{V} $, so is $ \phi $. Note that it might appear that we have only proved the above equation $ \phi = u_1f_{x_1} + \dots + u_mf_{x_m} $ on a Zariski open subset of $ V $, namely the intersections of the domains of definition of $ f_{x_1} / g_{x_1}, \dots, f_{x_m} / g_{x_m} $. Because $ V $ is irreducible, this open subset must be dense, but the subset where an equation of polynomials holds is closed, so it is equal to all of $ V $.
\end{proof}

\subsubsection{Rational maps}

Let $ V \subseteq \AA^m $ and $ W \subseteq \AA^n $ be irreducible affine algebraic sets.

\begin{definition*}
A \textbf{rational map} $ \phi : V \dashrightarrow W $ is an $ n $-tuple of rational functions $ \phi_1, \dots, \phi_n \in k\br{V} $ such that, for every point $ x \in V $ where $ \phi_1, \dots, \phi_n $ are all regular, the point $ \br{\phi_1\br{x}, \dots, \phi_n\br{x}} $ is in $ W $.
\end{definition*}

We use the broken arrow symbol instead of the usual arrow because a rational map is not a function on $ V $ in the usual set-theoretic sense. It only defines a genuine function $ U \to W $, where $ U $ is the domain of definition of $ \phi $. This is defined as follows.

\begin{definition*}
The \textbf{domain of definition} of a rational map $ \phi : V \dashrightarrow W $ is the intersection of the domains of definition of the component rational functions $ \br{\phi_1, \dots, \phi_n} $.
\end{definition*}

The two lemmas we proved for rational functions also hold for rational maps. The domain of definition of a rational map $ \phi : V \dashrightarrow W $ is a non-empty Zariski open subset of $ V $, and if a rational map is regular everywhere then it is a regular map. In order to prove that the domain of definition of a rational map is non-empty, we have to use the fact that $ V $ is irreducible, and therefore every open subset of $ V $ is dense.

\begin{example*}
An important example of a rational map is the projection from a point onto a hyperplane. Let $ H $ be a hyperplane in $ \AA^n $, that is a set defined by a single linear equation. Let $ p $ be a point in $ \AA^n \setminus H $. For simplicity, we shall assume that $ p $ is the origin and that
$$ H = \cbr{\br{x_1, \dots, x_n} \in \AA^n \st x_n = 1}, $$
since we could always reduce to this case by a suitable change of coordinates. Let us write $ H_p $ for the hyperplane through $ p $ parallel to $ H $, that is
$$ H_p = \cbr{\br{x_1, \dots, x_n} \in \AA^n \st x_n = 0}. $$
For each point $ x \in \AA^n \setminus H_p $, let $ L_x $ denote the line which passes through $ p $ and $ x $. Since $ x \notin H_p $, $ L_x $ intersects $ H $ in exactly one point. Call this point $ \phi\br{x} $. We can write this algebraically as
$$ \rational[\phi]{\AA^n}{H}{\br{x_1, \dots, x_n}}{\br{\dfrac{x_1}{x_n}, \dots, \dfrac{x_{n - 1}}{x_n}, 1}}, $$
and so $ \phi $ is a rational map. This map is called the \textbf{projection from $ p $ onto $ H $}. We have $ \dom \phi = \AA^n \setminus H_p $. Note that we have not proved this, because we have not proved that there is no other list of fractions which define the same rational map but have non-zero denominators at points in $ H_p $. One can prove this. For any affine algebraic set $ V \subseteq \AA^n $ such that $ V \not\subseteq H_p $, we can restrict $ \phi $ to get a rational map $ V \dashrightarrow H $. Note that $ p $ might be in $ V $, or it might not.
\end{example*}

\pagebreak

\begin{example*}
Let $ V $ be the circle $ \cbr{\br{x, y} \st x^2 + y^2 = 1} $. Consider the projection from the point $ p = \br{1, 0} $ on to the line $ x = 0 $. This is a rational map with the formula
$$ \rational[\pi]{V}{\AA^1}{\br{x, y}}{\dfrac{y}{1 - x}}. $$
We can see geometrically that this projection induces a bijection between the circle, excluding $ p $, and the line, at least for real points. If we compute the formula for the inverse map, we get
$$ \rational[\psi]{\AA^1}{V}{t}{\br{\dfrac{t^2 - 1}{t^2 + 1}, \dfrac{2t}{t^2 + 1}}}, $$
a well-known parameterisation of the circle. Thus we see that the inverse is a rational map. Note that $ \psi $ is not regular at $ t = \pm i $. We do not see this on the picture, which only shows the real points.
\end{example*}

We would like to define formally what it means to say that the rational maps $ \pi $ and $ \psi $ are inverse to each other, taking into account that they are not true functions between the sets $ V $ and $ \AA^1 $ because they are not regular everywhere. These maps are inverses in that composing them, either way round, gives the identity, if we ignore the points where the maps are not regular.

\subsubsection{Birational equivalences}

\lecture{9}{Friday}{31/01/20}

In order to do this, we first define what it means to compose rational maps. But it does not always make sense to compose rational maps. In order to rigorously define composition of rational maps, we need to notice that sometimes the set of points where a composite map is undefined is everywhere and exclude that situation.

\begin{example*}
Consider the rational map defined by
$$ \rational[\xi]{\AA^2}{\AA^1}{\br{x, y}}{\dfrac{1}{1 - x^2 - y^2}}. $$
This map is not regular anywhere on the circle $ V $, and hence it does not make sense to try to define the composite map $ \xi \circ \psi : \AA^1 \dashrightarrow \AA^1 $, since it is not defined anywhere.
\end{example*}

This problem can occur because the image of $ \psi $ is not dense in $ \AA^2 $. So to rule it out this problem, we make the following definition of dominant rational maps.

\begin{definition*}
The \textbf{image} of a rational map $ \phi : V \dashrightarrow W $ is the set of points
$$ \cbr{\phi\br{x} \in W \st x \in \dom \phi}. $$
A rational map is \textbf{dominant} if its image is Zariski dense in $ W $.
\end{definition*}

\begin{example*}
$ \psi $ from the end of the previous lecture is dominant if we consider it as a rational map $ \AA^1 \dashrightarrow V $ but it is not dominant if we consider it as a rational map $ \AA^1 \dashrightarrow \AA^2 $. This is like surjectivity, since whether a function is surjective or not depends on what codomain you declare it to have.
\end{example*}

Let $ V, W, T $ be irreducible affine algebraic sets. If $ \phi : V \dashrightarrow W $ is a dominant rational map and $ \psi : W \dashrightarrow T $ is a rational map, where $ \psi $ is not required to be dominant, then it makes sense to compose them because we know that $ \dom \psi $ is a Zariski open subset of $ W $, while $ \Im \phi $ is a Zariski dense subset of $ W $ and so $ \dom \psi \cap \Im \phi \ne \emptyset $. Thus there are at least some points where $ \psi \circ \phi $ is defined. One can check, by writing out $ \psi $ in terms of fractions of polynomials, then substituting in fractions of polynomials representing $ \phi $, that $ \psi \circ \phi $ is a rational map $ V \dashrightarrow T $.

\begin{definition*}
Rational maps $ \phi : V \dashrightarrow W $ and $ \psi : W \to V $ are \textbf{rational inverses} if both are dominant and $ \phi \circ \psi = \id_W $ and $ \psi \circ \phi = \id_V $, everywhere these composite rational maps are well-defined. A rational map $ \phi : V \dashrightarrow W $ is a \textbf{birational equivalence} if it is dominant and has a rational inverse. We say that irreducible algebraic sets $ V $ and $ W $ are \textbf{birational}, or \textbf{birationally equivalent}, if there exists a birational equivalence $ V \dashrightarrow W $.
\end{definition*}

\begin{example*}
Our example from the previous lecture showed that the circle is birational to $ \AA^1 $.
\end{example*}

\pagebreak

\begin{example*}
Another example is the cuspidal cubic $ W = \cbr{\br{x, y} \st y^2 = x^3} $. This is also birational to $ \AA^1 $, as shown by the rational maps
$$ \birational{W}{\AA^1}{\br{x, y}}{\dfrac{y}{x}}{\br{t^2, t^3}}{t}. $$
\end{example*}

Birationally equivalent affine algebraic sets look the same almost everywhere.

\begin{example*}
The cuspidal cubic is the same as the affine line everywhere except at the origin.
\end{example*}

\begin{example*}
$ \AA^1 $ is not birationally equivalent to $ \AA^2 $ or to an elliptic curve $ \cbr{\br{x, y} \st y^2 = f\br{x}} $ where $ f $ is a cubic polynomial with no repeated roots. We will prove this later in the course once we have more tools.
\end{example*}

\subsubsection{Dominant rational maps and \texorpdfstring{$ k $}{k}-field homomorphisms}

If $ \phi : V \dashrightarrow W $ is a dominant rational map, then we can use it to pull back rational functions from $ W $ to $ V $, just like we earlier used regular maps to pull back regular functions. We get a $ k $-homomorphism of fields defined by
$$ \function[\phi^*]{k\br{W}}{k\br{V}}{g}{g \circ \phi}. $$
A \textbf{$ k $-homomorphism} means that $ \phi^* $ restricts to the identity on the copies of $ k $ which are contained in $ k\br{W} $ and $ k\br{V} $, namely the constant functions. If $ \phi $ is a birational equivalence, then $ \phi^* $ is a $ k $-isomorphism of fields.

\subsection{Equivalence of algebra and geometry}

\subsubsection{From algebra homomorphisms to regular maps}

We have seen that each regular map $ f : V \to W $ induces a $ k $-algebra homomorphism $ f^* : k\sbr{W} \to k\sbr{V} $, and that each dominant rational map $ \phi : V \dashrightarrow W $ induces a $ k $-field homomorphism $ \phi^* : k\br{W} \to k\br{V} $. We can also carry out these constructions in the reverse direction. Starting with a $ k $-algebra homomorphism and getting a regular map, or similarly for rational maps. Observe that if $ f : V \to W $ is a regular map and $ W \subseteq \AA^n $, we can recover $ f $ from $ f^* : k\sbr{W} \to k\sbr{V} $ by taking the coordinate functions $ X_1, \dots, X_n \in k\sbr{W} $ on $ W $ and pulling them back to get $ f_1 = f^*\br{X_1}, \dots, f_n = f^*\br{X_n} \in k\sbr{V} $. These are precisely the regular functions on $ V $ such that $ f = \br{f_1, \dots, f_n} $. We generalise this procedure for any $ k $-algebra homomorphism $ \alpha : k\sbr{W} \to k\sbr{V} $. Starting from an arbitrary $ k $-algebra homomorphism $ \alpha : k\sbr{W} \to k\sbr{V} $, we define a regular map $ s : V \to W $ by
$$ s = \br{\alpha\br{X_1}, \dots, \alpha\br{X_n}}. $$
Here $ \alpha\br{X_1}, \dots, \alpha\br{X_n} \in k\sbr{V} $. Then $ \alpha = s^* : k\sbr{W} \to k\sbr{V} $. Thus every $ k $-algebra homomorphism $ k\sbr{W} \to k\sbr{V} $ is the pull-back by some regular map $ V \to W $. We conclude the following.

\begin{proposition}
$ \phi \mapsto \phi^* $ is a bijection
$$ \cbr{\text{regular maps} \ V \to W} \to \cbr{\text{$ k $-algebra homomorphisms} \ k\sbr{W} \to k\sbr{V}}. $$
\end{proposition}

\begin{corollary}
Affine algebraic sets $ V $ and $ W $ are isomorphic if and only if their coordinate rings $ k\sbr{V} $ and $ k\sbr{W} $ are isomorphic as $ k $-algebras.
\end{corollary}

The moral is that if we only care about affine algebraic sets up to isomorphism, then coordinate rings contain exactly the same information as algebraic sets themselves. In the language of category theory, the functor $ V \to k\sbr{V} $ is fully faithful. One can do the same thing for rational maps.

\begin{proposition}
$ \phi \mapsto \phi^* $ is a bijection
$$ \cbr{\text{dominant rational maps} \ V \dashrightarrow W} \to \cbr{\text{$ k $-field homomorphisms} \ k\br{W} \to k\br{V}}. $$
\end{proposition}

\begin{corollary}
\label{cor:algebrageometry}
Irreducible affine algebraic sets $ V $ and $ W $ are birationally equivalent if and only if their function fields $ k\br{V} $ and $ k\br{W} $ are $ k $-isomorphic.
\end{corollary}

\pagebreak

\subsubsection{Dictionary between algebraic subsets and ideals}

Can we do something similar with Zariski closed subsets of $ V $, and work them out from the algebra of $ k\sbr{V} $? Suppose that $ V \subseteq \AA^n $. In $ \AA^n $, the Nullstellensatz tells us that the functions $ \II $ and $ \VV $ are bijections
$$ \correspondence{\text{Zariski closed subsets of} \ \AA^n}{\text{radical ideals in} \ k\sbr{X_1, \dots, X_n}}. $$
Since $ \II $ and $ \VV $ reverse the direction of inclusions, we deduce that they restrict to bijections
$$ \correspondence{\text{Zariski closed subsets of} \ V}{\text{radical ideals in} \ k\sbr{X_1, \dots, X_n} \ \text{containing} \ \II\br{V}}. $$
We know that $ k\sbr{V} \cong k\sbr{X_1, \dots, X_n} / \II\br{V} $. It is a basic algebraic fact that
$$ \correspondence{\text{ideals in} \ k\sbr{X_1, \dots, X_n} \ \text{containing} \ \II\br{V}}{\text{ideals in} \ k\sbr{X_1, \dots, X_n} / \II\br{V}}. $$
Under this correspondence, radical ideals on one side correspond to radical ideals on the other side and similarly for prime ideals. We conclude that the natural maps are bijections
$$ \correspondence{\text{Zariski closed subsets of} \ V}{\text{radical ideals in} \ k\sbr{V}}, $$
and
$$ \correspondence{\text{irreducible Zariski closed subsets of} \ V}{\text{prime ideals in} \ k\sbr{V}}. $$
Can we describe the points of an affine algebraic set $ V $ in terms of the algebra of $ k\sbr{V} $? The points of $ V $ are the smallest non-empty Zariski closed subsets. Since the bijection between Zariski closed subsets and ideals reverses direction of inclusion, they correspond to maximal ideals, so
$$ \correspondence{\text{points of} \ V}{\text{maximal ideals in} \ k\sbr{V}}. $$

\lecture{10}{Monday}{03/02/20}

Lecture 10 is a problems class.

\subsubsection{Reduced finitely generated \texorpdfstring{$ k $}{k}-algebras}

\lecture{11}{Thursday}{06/02/20}

We have seen that $ V \mapsto k\sbr{V} $ leads to bijections on maps between affine algebraic sets. To fully understand the relationship between affine algebraic sets and $ k $-algebras, there is one more question to answer. Which $ k $-algebras can occur as $ k\sbr{V} $ where $ V $ is an affine algebraic set? We write down some algebraic properties which obviously hold for $ A = k\sbr{V} $, the coordinate ring of an affine algebraic set $ V $.
\begin{itemize}
\item $ A $ is finitely generated, because if $ V \subseteq \AA^n $ then $ A $ is generated by the coordinate functions $ X_1, \dots, X_n $.
\item $ A $ is reduced, meaning that if $ f \in A $ and $ f^k = 0 $ for some $ k > 0 $, then $ f = 0 $. This is because $ A $ is a ring of functions in the usual set-theoretic sense. If $ f^k = 0 $ then $ f\br{x}^k = 0 $ for all $ x \in V $, so $ f\br{x} = 0 $ for all $ x \in V $.
\end{itemize}
Using the Nullstellensatz, we can prove that these properties are enough to characterise the $ k $-algebras which are coordinate rings of affine algebraic sets.

\begin{proposition}
\label{prop:kva}
Let $ A $ be a finitely generated reduced $ k $-algebra. Then there exists an affine algebraic set $ V $ such that $ k\sbr{V} \cong A $.
\end{proposition}

\begin{proof}
Pick a finite set $ f_1, \dots, f_n \in A $ which generates $ A $ as a $ k $-algebra. We can define a homomorphism
$$ \function[\alpha]{k\sbr{X_1, \dots, X_n}}{A}{\br{X_1, \dots, X_n}}{\br{f_1, \dots, f_n}}. $$
Let $ I = \Ker \alpha $ and let $ V = \VV\br{I} \subseteq \AA^n $. The homomorphism $ \alpha $ is surjective because $ f_1, \dots, f_n $ generate $ A $, and so $ A \cong k\sbr{X_1, \dots, X_n} / I $. Thus $ k\sbr{X_1, \dots, X_n} / I $ is a reduced $ k $-algebra. It follows that $ I $ is a radical ideal. Hence the Nullstellensatz tells us that $ I = \II\br{V} $. Thus
$$ k\sbr{V} \cong k\sbr{X_1, \dots, X_n} / \II\br{V} \cong k\sbr{X_1, \dots, X_n} / I \cong A. $$
\end{proof}

\pagebreak

\subsubsection{The notion of an affine variety}

Often in mathematics, it is convenient to consider objects only up to isomorphism.

\begin{example*}
One might talk about the group with seven elements, ignoring the fact that there are many different groups with seven elements because they are all isomorphic to each other, and therefore they all behave in the same ways.
\end{example*}

Similarly, in algebraic geometry we often want to consider affine algebraic sets up to isomorphism. But affine algebraic sets are always defined in a concrete way. They are a subset of some specific affine space $ \AA^n $. It is as if we had defined all finite groups to be subgroups of a symmetric group $ \SSS_n $. And we have seen that affine algebraic sets can be isomorphic even when they appear to be quite different as subsets of affine space.

\begin{example*}
The line $ \AA^1 $ is isomorphic to the parabola $ \VV\br{Y - X^2} \subseteq \AA^2 $.
\end{example*}

Thus it is useful to use different terminology. We talk about affine algebraic sets when we mean subsets of $ \AA^n $, and we talk about \textbf{affine varieties} when we mean an affine algebraic set up to isomorphism, forgetting its embedding into $ \AA^n $. Proposition \ref{prop:kva} is more naturally stated in terms of affine varieties rather than affine algebraic sets. In the proof we had to choose a generating set for $ A $, for which there is no distinguished choice. Different choices of generating set would lead to isomorphic affine algebraic sets, but embedded differently into affine space. So it is better to say that each finitely generated reduced $ k $-algebra $ A $ is the coordinate ring of some affine variety $ V $, with no distinguished choice of embedding into $ \AA^n $. I mentioned this philosophy about affine varieties before, and I will mention it again after we have defined quasi-projective varieties. For those who know some fancy categorical language, we can sum up all the results on the equivalence between affine geometric objects and their coordinate rings by saying that $ V \mapsto k\sbr{V} $ is an equivalence of categories
$$ \cbr{\text{affine varieties over} \ k} \to \cbr{\text{reduced finitely generated $ k $-algebras}}^{\op}, $$
where the superscript $ \op $ indicates that the directions of morphisms are reversed. Let $ A $ be a reduced finitely generated $ k $-algebra and $ V $ an affine variety such that $ A \cong k\sbr{V} $. How can we work out the geometry of $ V $ from the algebra of $ A $? If we choose an embedding of $ V $ into $ \AA^n $, then we get an isomorphism $ k\sbr{X_1, \dots, X_n} / \II\br{V} \to A $. We conclude that
$$ \correspondence{\text{Zariski closed subsets of} \ V}{\text{radical ideals in} \ A}, $$
$$ \correspondence{\text{irreducible Zariski closed subsets of} \ V}{\text{prime ideals in} \ A}, $$
$$ \correspondence{\text{points of} \ V}{\text{maximal ideals in} \ A}. $$

\subsubsection{The weak and strong Nullstellensatz}

Now we aim to prove Hilbert's Nullstellensatz. There are many different proofs, all of which require some difficult algebra. We will roughly follow the method in Shafarevich appendix A, which incorporates the hard algebra into one statement which we can quote, and then do the rest as geometrically as possible. Recall the statement of Hilbertâ€™s Nullstellensatz, Theorem \ref{thm:strongnullstellensatz}, also called the strong Nullstellensatz. In order to prove this, we will first prove a weaker version, which is called the weak Nullstellensatz, then use that to deduce the strong Nullstellensatz.

\begin{theorem}[Weak Nullstellensatz]
Let $ I $ be an ideal in the polynomial ring $ k\sbr{X_1, \dots, X_n} $ over an algebraically closed field $ k $. If $ \VV\br{I} = \emptyset $, then $ I = k\sbr{X_1, \dots, X_n} $.
\end{theorem}

This is a statement about the existence of solutions to polynomial equations, so it is necessary to require $ k $ to be algebraically closed.

\begin{example*}
To show that it fails when $ k $ is not algebraically closed, consider the ideal $ \abr{X^2 + Y^2 + 1} $ in $ \RR\sbr{X, Y} $. This ideal is not the full polynomial ring, but there are no real solutions to the equation $ x^2 + y^2 + 1 = 0 $.
\end{example*}

\begin{note*}
The strong Nullstellensatz easily implies the weak Nullstellensatz. If $ \VV\br{I} = \emptyset $ then the strong Nullstellensatz tells us that $ \rad I = \II\br{\emptyset} = k\sbr{X_1, \dots, X_n} $. In particular, $ 1 \in \rad I $ but then $ 1 \in I $ so $ I = k\sbr{X_1, \dots, X_n} $.
\end{note*}

\pagebreak

\begin{proof}[Proof of Theorem \ref{thm:strongnullstellensatz}]
We use a method called the Rabinowitsch trick, introducing an extra variable. Let $ I $ be an ideal in $ k\sbr{X_1, \dots, X_n} $ and let $ V = \VV\br{I} \subseteq \AA^n $. It is easy to see that $ \rad I \subseteq \II\br{V} $. Thus we have to prove that $ \II\br{V} \subseteq \rad I $. Let $ f \in \II\br{V} $. Define a new polynomial $ g $ with an extra variable $ Y $ by
$$ g\br{X_1, \dots, X_n, Y} = f\br{X_1, \dots, X_n} \cdot Y - 1. $$
Let $ J $ be the ideal in $ k\sbr{X_1, \dots, X_n, Y} $ generated by $ I $ and $ g $, and consider the affine algebraic set $ W = \VV\br{J} \subseteq \AA^{n + 1} $. Every point $ \br{x_1, \dots, x_n, y} \in W $ satisfies $ f\br{x_1, \dots, x_n} \ne 0 $, in order for there to exist some $ y $ such that $ f\br{x_1, \dots, x_n}y - 1 = 0 $. This is generalising the fact that the hyperbola projects down to $ \AA^1 \setminus \cbr{0} $. Since $ I \subseteq J $, points $ \br{x_1, \dots, x_n, y} $ of $ W $ also satisfy $ \br{x_1, \dots, x_n} \in V $. Therefore, if $ \pi : \AA^{n + 1} \to \AA^n $ is the projection map, forgetting the extra $ Y $ coordinate, then
$$ \pi\br{W} \subseteq \cbr{\br{x_1, \dots, x_n} \in V \st f\br{x_1, \dots, x_n} \ne 0}. $$
Since $ f \in \II\br{V} $, the set on the right is empty. Thus $ \pi\br{W} = \emptyset $. This implies that $ W $ itself is empty. Therefore, by the weak Nullstellensatz, $ J = k\sbr{X_1, \dots, X_n, Y} $. In particular, $ 1 \in J $ and thus $ 1 = a + bg $ for some $ a \in I \cdot k\sbr{X_1, \dots, X_n, Y} $ and $ b \in k\sbr{X_1, \dots, X_n, Y} $. Expanding out $ a $ and $ b $ as sums over powers of $ Y $,
$$ a = \sum_{j \ge 0} a_jY^j, \qquad b = \sum_{j \ge 0} b_jY^j, \qquad a_j \in I, \qquad b_j \in k\sbr{X_1, \dots, X_n}. $$
The equation $ 1 = a + bg $ can be expanded and rearranged to give
$$ 1 = a_0 - b_0 + \sum_{j \ge 1} \br{a_j + b_{j - 1}f - b_j}Y^j. $$
Looking at the terms of degree zero in $ Y $ gives $ b_0 = a_0 - 1 \in I - 1 $, then terms of degree one in $ Y $ gives $ b_1 = a_1 + b_0f \in I - f $, using $ a_1 \in I $ and $ b_0 \in I - 1 $. Continuing by induction on $ j $, these imply that
$$ b_j = a_j + b_{j - 1}f \in I - f^j, \qquad j \ge 0, $$
where $ I - f^j $ means the coset $ \cbr{t - f^j \st t \in I} $. But $ b $ is a polynomial, so $ b_j = 0 $ once $ j $ gets large enough. Thus for some $ j $, we get $ 0 \in I - f^j $, that is $ f^j \in I $. This proves that $ f \in \rad I $.
\end{proof}

\lecture{12}{Friday}{07/02/20}

We can restate the weak Nullstellensatz in elementary terms as, if $ f_1, \dots, f_m \in k\sbr{X_1, \dots, X_n} $ are a finite set of polynomials, and the ideal $ I $ which they generate is not the whole polynomial ring, then there exists a common solution $ \br{x_1, \dots, x_n} \in k^n $ to the equations
$$ f_1\br{x_1, \dots, x_n} = 0, \qquad, \dots, \qquad f_m\br{x_1, \dots, x_n} = 0. $$
We prove this in two steps.
\begin{enumerate}[label=Step \arabic*., leftmargin=0.5in]
\item There exists a larger field $ K $ containing $ k $ such that these equations have a common solution in $ K^n $.
\item If the equations have a common solution in $ K^n $, then they also have a common solution in $ k^n $.
\end{enumerate}

\subsubsection{Finding a solution in a bigger field}

The proof of step $ 1 $ is fairly short, and relies on Zorn's lemma.

\begin{lemma}
Let $ f_1, \dots, f_m $ be polynomials in $ k\sbr{X_1, \dots, X_n} $, such that the ideal $ I = \abr{f_1, \dots, f_m} $ is not equal to $ k\sbr{X_1, \dots, X_n} $. Then there exists a field $ K $ which is a finitely generated extension of $ k $ such that the equations $ f_1 = \dots = f_m = 0 $ have a common solution $ \br{x_1, \dots, x_n} \in K^n $.
\end{lemma}

Because $ I \ne k\sbr{X_1, \dots, X_n} $, we can use Zorn's lemma to show that $ I $ is contained in some maximal ideal $ M \subseteq k\sbr{X_1, \dots, X_n} $. This is a natural way to start. We are trying to show that $ \VV\br{I} $ has a point, and last time we saw that points in $ \VV\br{I} $ correspond to maximal ideals in $ k\sbr{X_1, \dots, X_n} $ containing $ I $. We cannot just quote the correspondence from the previous lecture because we used the Nullstellensatz in proving that correspondence, but this justifies why obtaining a maximal ideal is a good first step.

\begin{proof}
Let $ K = k\sbr{X_1, \dots, X_n} / M $. Let $ x_1, \dots, x_n $ denote the images of $ X_1, \dots, X_n $ in $ K $. Then $ K $ is a field because $ M $ is a maximal ideal, and it is finitely generated as an extension of $ k $ because it is generated by $ x_1, \dots, x_n $. Since $ f_j\br{X_1, \dots, X_n} \in I \subseteq M $, we get that $ f_j\br{x_1, \dots, x_n} = 0 $ in $ K $ for each $ j $. Thus $ \br{x_1, \dots, x_n} $ is the required common solution to $ f_1, \dots, f_m $ in $ K^n $.
\end{proof}

\pagebreak

\subsubsection{Shrinking the field required}

Before proving step $ 2 $, we begin by quoting an algebraic result.

\begin{lemma}
\label{lem:algebraicallyindependent}
Let $ k $ be an algebraically closed field and let $ K $ be a finitely generated extension field of $ k $. Then there exist $ t_1, \dots, t_d, u \in K $ such that
\begin{itemize}
\item $ K = k\br{t_1, \dots, t_d, u} $,
\item $ t_1, \dots, t_d $ are algebraically independent over $ k $, that is there is no non-zero polynomial in $ d $ variables with coefficients in $ k $ whose value at $ \br{t_1, \dots, t_d} $ is zero, and
\item $ u $ is algebraic over $ k\br{t_1, \dots, t_d} $, that is there exists a non-zero polynomial in one variable with coefficients in the field $ k\br{t_1, \dots, t_d} $ which is zero at $ u $.
\end{itemize}
\end{lemma}

\begin{proof}
This follows from the primitive element theorem in field theory. For a full proof, see Proposition A.7 in the appendix of Shafarevich basic algebraic geometry.
\end{proof}

Lemma \ref{lem:algebraicallyindependent} has a nice geometric interpretation. Every finitely generated extension of $ k $ is isomorphic to the field of fractions of a hypersurface. We need to use the Nullstellensatz to prove this geometric interpretation, so that is postponed until after we have finished the proof of the Nullstellensatz.

\begin{theorem}
\label{thm:shrinkingfield}
Let $ k $ be an algebraically closed field and let $ K $ be a finitely generated extension field of $ k $. Let $ f_1, \dots, f_m \in k\sbr{X_1, \dots, X_n} $. Suppose there exists a common solution $ \br{x_1, \dots, x_n} \in K^n $ to the equations $ f_1 = \dots = f_m = 0 $. Then there exists a common solution $ \br{y_1, \dots, y_n} \in k^n $ to the equations $ f_1 = \dots = f_m = 0 $.
\end{theorem}

\begin{proof}
Write $ K = k\br{t_1, \dots, t_d, u} $ as in Lemma \ref{lem:algebraicallyindependent}. Let $ K' = k\br{t_1, \dots, t_d} $. Because $ t_1, \dots, t_d $ are algebraically independent, we can identify $ K' $ with $ k\br{T_1, \dots, T_d} $, the field of fractions of the polynomial ring $ k\sbr{T_1, \dots, T_d} $. This will allow us to substitute a vector $ \underline{z} \in k^d $ into an element $ \alpha \in K' $ and get out an element $ \alpha\br{\underline{z}} \in k $, as long as the denominator of $ \alpha $ does not vanish at $ \underline{z} $. We use two facts about the finite algebraic extension $ K / K' $.
\begin{enumerate}[label=Fact \arabic*., leftmargin=0.5in]
\item There exists a minimal polynomial $ p\br{U} \in K'\sbr{U} $ for $ u $. That is, $ p\br{u} = 0 $, $ p $ has leading coefficient one, and $ p $ divides every other polynomial $ q\br{U} \in K'\sbr{U} $ such that $ q\br{u} = 0 $.
\item Every element of $ K $ can be written in the form $ a\br{u} $ for some polynomial $ a\br{U} \in K'\sbr{U} $.
\end{enumerate}
The idea of the proof is to consider the almost hypersurface
$$ H = \cbr{\br{z_1, \dots, z_d, s} \in k^{d + 1} \st p\br{z_1, \dots, z_d, s} = 0}. $$
The almost is because $ p $ is not a polynomial in $ k\sbr{T_1, \dots, T_d, U} $ but rather may have denominators, so we have to ignore the places where these denominators vanish. Then we construct a rational map $ \phi : H \dashrightarrow \VV\br{f_1, \dots, f_m} $. The domain of definition of $ \phi $ is an open subset of an almost hypersurface, and we can easily check that this is non-empty. Then a point in the image of $ \phi $ gives us a point in $ \VV\br{f_1, \dots, f_m} $, as desired. In particular, we apply fact $ 2 $ to $ x_1, \dots, x_n \in K $, our common solution to $ f_1 = \dots = f_m = 0 $, so we can write $ x_i = a_i\br{u} $ where $ a_i\br{U} \in K'\sbr{U} $. In the informal outline, these $ a_i \in k\br{T_1, \dots, T_d}\sbr{U} $ define a rational map $ \phi : H \dashrightarrow \AA^n $. Next we check that the image of this rational map is contained in $ \VV\br{f_1, \dots, f_m} $. We know that $ \br{x_1, \dots, x_n} $ is a common solution to the polynomials $ f_1, \dots, f_m $. Hence
$$ f_j\br{a_1\br{u}, \dots, a_n\br{u}} = 0 \in K, \qquad j = 1, \dots, m. $$
In other words, the single-variable polynomial $ f_j\br{a_1\br{U}, \dots, a_n\br{U}} \in K'\sbr{U} $ has $ u $ as a root. Therefore, fact $ 1 $ tells us that this polynomial is divisible by $ p\br{U} $. Thus there exist polynomials $ q_1, \dots, q_m \in K'\sbr{U} $ such that
\begin{equation}
\label{eq:1}
f_j\br{a_1\br{U}, \dots, a_n\br{U}} = q_j\br{U}p\br{U} \in K'\sbr{U}, \qquad j = 1, \dots, m.
\end{equation}
Now, if $ \br{z_1, \dots, z_d, s} \in k^{d + 1} $ satisfies $ p\br{z_1, \dots, z_d, s} = 0 $, then $ \br{\ref{eq:1}} $ implies that
$$ f_j\br{a_1\br{z_1, \dots, z_d, s}, \dots, a_n\br{z_1, \dots, z_d, s}} = 0, \qquad j = 1, \dots, m, $$

\pagebreak

so long as all the denominators involved are non-zero. Thus we just have to find $ \br{z_1, \dots, z_d, s} $ where all these denominators will be non-zero. So consider the polynomials
$$ p\br{U}, a_i\br{U}, q_j\br{U} \in K'\sbr{U}. $$
Their coefficients are elements of the field $ K' $ which we are identifying with the field of fractions $ k\br{T_1, \dots, T_d} $. Let $ \sigma \in k\sbr{T_1, \dots, T_d} $ denote the product of the denominators of all these fractions. Because the denominator of a fraction is never zero, $ \sigma $ is not the zero polynomial in $ k\sbr{T_1, \dots, T_d} $. Therefore, there exists $ \br{s_1, \dots, s_d} \in k^d $ such that $ \sigma\br{s_1, \dots, s_d} \ne 0 $. Then the denominators of the coefficients of $ p, a_i, q_j $ do not vanish at $ s_1, \dots, s_d $, so we can substitute $ \br{s_1, \dots, s_d} $ into each of these coefficients, as elements of $ K' $, and get out values in $ k $. Thus we get new polynomials
$$ \widetilde{p}\br{U}, \widetilde{a_i}\br{U}, \widetilde{q_j}\br{U} \in k\sbr{U}. $$
The leading coefficient of $ \widetilde{p}\br{U} $ is one, which is unchanged by this process. So $ \widetilde{p}\br{U} $ has the same degree as $ p\br{U} $. In particular $ \widetilde{p}\br{U} $ is not a constant polynomial. Hence as $ k $ is algebraically closed, there exists $ s \in k $ such that $ \widetilde{p}\br{s} = 0 $. Let $ y_i = \widetilde{a_i}\br{s} \in k $. Then $ \br{\ref{eq:1}} $ tells us that
$$ f_j\br{y_1, \dots, y_n} = \widetilde{q_j}\br{s}\widetilde{p}\br{s}, \qquad j = 1, \dots, m. $$
But we chose $ s $ such that $ \widetilde{p}\br{s} = 0 $, and so we conclude that $ \br{y_1, \dots, y_n} \in k^n $ is a common solution to $ f_1 = \dots = f_m = 0 $.
\end{proof}

Combining Lemma \ref{lem:algebraicallyindependent} and Theorem \ref{thm:shrinkingfield} proves the weak Nullstellensatz.

\subsubsection{Hypersurfaces and birational equivalence}

Now we prove the geometrical interpretation of Lemma \ref{lem:algebraicallyindependent}.

\begin{proposition}
\label{prop:irreduciblehypersurface}
Let $ K $ be a finitely generated extension of $ k $. Then there exists an irreducible hypersurface $ H \subseteq \AA^{d + 1} $ for some $ d $ such that $ K $ is isomorphic to the field of functions $ k\br{H} $.
\end{proposition}

\begin{corollary}
\label{cor:irreduciblehypersurface}
Let $ V \subseteq \AA^n $ be an irreducible affine algebraic set. Then there exists an irreducible hypersurface $ H \subseteq \AA^{d + 1} $ for some $ d $ such that $ V $ is birationally equivalent to $ H $.
\end{corollary}

Corollary \ref{cor:irreduciblehypersurface} tells us that, even if $ V $ is a complicated algebraic set defined by many equations, provided we only care about properties of $ V $ which are preserved by birational equivalence, we can replace $ V $ by a simpler set defined by just one equation, that is a hypersurface.

\begin{note*}
It is not true that every irreducible affine algebraic set is isomorphic to a hypersurface.
\end{note*}

\begin{proof}[Proof of Proposition \ref{prop:irreduciblehypersurface}]
Write $ K = k\br{t_1, \dots, t_d, u} $ as in Lemma \ref{lem:algebraicallyindependent}, and let $ K' = k\br{t_1, \dots, t_d} $. Because $ u $ is algebraic over $ K' $, let $ p\br{U} \in K'\sbr{U} $ be the minimal polynomial of $ u $ over $ K' $. Each coefficient of $ p\br{U} $ is a fraction whose numerator and denominator are polynomials in $ t_1, \dots, t_d $. We can multiply up by a suitable element of $ k\sbr{t_1, \dots, t_d} $ to clear the denominators, and also replace $ t_1, \dots, t_d $ by indeterminates $ T_1, \dots, T_d $ to get a polynomial $ g \in k\sbr{T_1, \dots, T_d, U} $ such that $ g\br{t_1, \dots, t_d, u} = 0 $ in the field $ K $. Assuming we multiplied up by a lowest common denominator for the coefficients of $ p $, $ g $ is irreducible. Let $ H $ be the hypersurface in $ \AA^{d + 1} $ defined by the polynomial $ g $. Because $ g $ is irreducible, it generates a radical ideal in $ k\sbr{X_1, \dots, X_n} $ and so the strong Nullstellensatz implies that $ \II\br{H} = \abr{g} $. Thus the coordinate ring is given by
$$ k\sbr{H} = k\sbr{T_1, \dots, T_d, U} / \abr{g}. $$
There is a $ k $-algebra homomorphism
$$ \function[\alpha]{k\sbr{T_1, \dots, T_d, U}}{K}{\br{T_1, \dots, T_d, U}}{\br{t_1, \dots, t_d, u}}. $$
A little algebra, using Gauss' lemma, shows that the kernel of $ \alpha $ is generated by $ g $, so $ \alpha $ induces an injection $ k\sbr{H} \hookrightarrow K $. Furthermore, the image of $ \alpha $ generates $ K $ as a field, so $ \alpha $ induces an isomorphism from the fraction field of $ k\sbr{H} $ to $ K $. The fraction field of $ k\sbr{H} $ is the function field $ k\br{H} $. Thus we have shown that $ k\br{H} \cong k\br{V} $. By Corollary \ref{cor:algebrageometry}, this implies that $ V $ is birationally equivalent to $ H $.
\end{proof}

\begin{proof}[Proof of Corollary \ref{cor:irreduciblehypersurface}]
Apply Proposition \ref{prop:irreduciblehypersurface} to the function field $ K = k\br{V} $.
\end{proof}

\pagebreak

\section{Projective varieties}

\subsection{Projective algebraic sets}

\subsubsection{Projective space}

\lecture{13}{Monday}{10/02/20}

Projective space consists of affine space together with points at infinity, one for each direction. The purpose for adding extra points is that it avoids special cases where a point disappears to infinity.

\begin{example*}
A pair of parallel lines do not intersect in affine space but they do intersect at a point at infinity in projective space.
\end{example*}

\begin{definition*}
\textbf{Projective $ n $-space}, $ \PP^n $, is the set of lines through the origin in $ \AA^{n + 1} $.
\end{definition*}

A convenient way to label points in $ \PP^n $ is via homogeneous coordinates. These are just coordinates in $ k^{n + 1} \setminus \cbr{\br{0, \dots, 0}} $. Any sequence of coordinates $ \underline{x} \in k^{n + 1} \setminus \cbr{\br{0, \dots, 0}} $ represents the unique line through the origin and $ \underline{x} $ in $ \AA^{n + 1} $. Two sequences of homogeneous coordinates $ \br{x_0, \dots, x_n} $ and $ \br{y_0, \dots, y_n} $ represent the same point in $ \PP^n $ if and only if there exists $ \lambda \in k \setminus \cbr{0} $ such that $ \br{x_0, \dots, x_n} = \br{\lambda y_0, \dots, \lambda y_n} $. Thus projective $ n $-space is the quotient of $ k^{n + 1} \setminus \cbr{\br{0, \dots, 0}} $ by the equivalence relation
$$ \br{x_0, \dots, x_n} \sim \br{\lambda x_0, \dots, \lambda x_n}, \qquad \lambda \in k \setminus \cbr{0}. $$
We call a representative for an equivalence class the \textbf{homogeneous coordinates} of that point in $ \PP^n $, and there are many choices for each point, by scaling by $ \lambda $. To avoid confusion between homogeneous coordinates for $ \PP^n $ and ordinary coordinates for $ \AA^n $, we usually write homogeneous coordinates as $ \sbr{x_0 : \dots : x_n} $. Observe that we can embed
$$ \function{\AA^n}{\PP^n}{\br{x_1, \dots, x_n}}{\sbr{1 : x_1 : \dots : x_n}}. $$
Any other homogeneous coordinates where the first coordinate is non-zero can be re-scaled to have first coordinate one. So we are left with the points with first coordinate equal to zero. These are the \textbf{points at infinity}. A point $ \sbr{0 : x_1 : \dots : x_n} $ can be seen as a point in $ \PP^{n - 1} $, by just dropping the initial zero. Thus
$$ \PP^n = \AA^n \cup \PP^{n - 1}. $$
Similarly, we can embed $ \AA^1 $ by the map $ x \mapsto \sbr{1 : x} $, and then the point at infinity is $ \sbr{0 : 1} $, so
$$ \PP^1 = \AA^1 \cup \cbr{\sbr{0 : 1}}. $$
Over the complex numbers, $ \PP_\CC^1 $ is also called the \textbf{Riemann sphere}. Thinking about projective space as affine space plus points at infinity can be useful if we want to make use of our geometric intuition about affine space or the algebraic tools we have developed for working with affine algebraic sets. On the other hand, thinking about projective space in terms of homogeneous coordinates emphasises that all points of projective space look the same. We can only distinguish points at infinity from points in affine space after choosing a convention for how we embed $ \AA^n $ into $ \PP^n $.

\begin{example*}
We could have used $ \sbr{x_1 : \dots : x_n : 1} $ instead.
\end{example*}

Throughout this lecture we will use the convention above.

\subsubsection{Definition and examples}

A projective algebraic set is a subset of projective space defined by the vanishing of a finite list of polynomials. What does it mean for a polynomial to vanish at a point in projective space? Because a single point in $ \PP^n $ can be represented by many different homogeneous coordinates, it does not make sense to evaluate a polynomial in $ k\sbr{X_0, \dots, X_n} $ at a point of $ \PP^n $. We have to restrict attention to homogeneous polynomials.

\begin{definition*}
A polynomial $ f \in k\sbr{X_0, \dots, X_n} $ is \textbf{homogeneous} if every term of $ f $ has the same degree.
\end{definition*}

\begin{example*}
$ X_0^3 + X_0^2X_1 + 3X_2^3 - X_0X_1X_2 $ is homogeneous of degree three while $ X_0X_1 - X_2 $ is not homogeneous because it has a term of degree two and a term of degree one.
\end{example*}

If $ \sbr{x_0 : \dots : x_n} $ and $ \sbr{y_0 : \dots : y_n} $ represent the same point $ p \in \PP^n $, then
$$ \br{x_0, \dots, x_n} = \lambda\br{y_0, \dots, y_n}, \qquad \lambda \in k \setminus \cbr{0}. $$

\pagebreak

Hence if $ f \in k\sbr{X_0, \dots, X_n} $ is a homogeneous polynomial of degree $ d $, then
$$ f\br{x_0, \dots, x_n} = \lambda^df\br{y_0, \dots, y_n}. $$
Thus the actual value of $ f $ at $ p $ is not well-defined, but it is well-defined to ask whether or not $ f $ is zero at $ p $.

\begin{definition*}
A \textbf{projective algebraic set} is a set of the form
$$ \cbr{\sbr{x_0 : \dots : x_n} \in \PP^n \st f_1\br{x_0, \dots, x_n} = \dots = f_m\br{x_0, \dots, x_n} = 0}, $$
for some finite list of homogeneous polynomials $ f_1, \dots, f_m \in k\sbr{X_0, \dots, X_n} $.
\end{definition*}

By definition, a projective algebraic set is the vanishing of finitely many homogeneous polynomials. We can use the Hilbert basis theorem to show that the vanishing set of an infinite collection of homogeneous polynomials is a projective algebraic set. This is similar to the analogous result for affine algebraic sets, but a little trickier due to the word homogeneous.

\begin{example*}
An example of a projective algebraic set is
$$ V' = \cbr{\sbr{w : x : y} \in \PP^2 \st wx - y^2 = 0}. $$
What is $ V = V' \cap \AA^2 $, using the embedding $ \AA^2 \to \PP^2 $ which we considered before? To find this, we just substitute $ w = 1 $ into the equation for $ V' $, so
$$ V = \cbr{\br{x, y} \in \AA^2 \st x - y^2 = 0}, $$
that is an affine parabola. The polynomial $ X - Y^2 $ is not homogeneous. Therefore consider instead the homogeneous polynomial $ WX - Y^2 $. When $ W = 1 $, this restricts to $ X - Y^2 $. That takes care of the points of $ V' $ where $ w \ne 0 $, since we can scale the homogeneous coordinates of such a point to get $ w = 1 $. But $ V' $ contains extra points where $ w = 0 $. We can also work out the intersection of $ V' $ with the $ \PP^1 $ at infinity. Substituting $ w = 0 $ into the equation $ wx - y^2 = 0 $ for $ V' $ gives also $ y = 0 $. There is only one point of $ \PP^2 $ with $ w = y = 0 $, the point $ \sbr{0 : 1 : 0} $, since any other value for $ x $ could be scaled to one. So we get
$$ V' = V \cup \cbr{\sbr{0 : 1 : 0}}. $$
Thus geometrically, $ V' $ consists of the parabola $ V $ together with a point at infinity in the direction $ \br{1, 0} $, that is along the $ x $-axis. Informally, the two arms of the parabola close up at infinity.
\end{example*}

We would like to reverse this process, and go from an affine algebraic set to a projective algebraic set.

\begin{example*}
Consider the affine hyperbola
$$ H = \cbr{\br{x, y} \in \AA^2 \st xy - 1 = 0}. $$
We need to turn the polynomial $ XY - 1 $ into a homogeneous polynomial, using a new variable $ W $ in $ k\sbr{W, X, Y} $, which restricts to $ XY - 1 $ when $ W = 1 $. To do this, note that the highest degree term in $ XY - 1 $ has degree two. We multiply each term by an appropriate power of $ W $ to get all terms of degree two, so we have to replace the constant one by $ W^2 $. Thus we get $ XY - W^2 = 0 $. Thus we consider
$$ H' = \cbr{\sbr{w : x : y} \in \PP^2 \st xy - w^2 = 0}. $$
Again, when $ w \ne 0 $, we can scale to get $ w = 1 $, so we can substitute that in and see that we just get back $ H' $. When $ w = 0 $, the equation becomes $ xy = 0 $, so we now get two points at infinity. Either $ x = 0 $, giving the point $ \sbr{0 : 0 : 1} \in \PP^2 $, or $ y = 0 $, giving the point $ \sbr{0 : 1 : 0} \in \PP^2 $. Thus
$$ H' = H \cup \cbr{\sbr{0 : 0 : 1}, \sbr{0 : 1 : 0}}. $$
Geometrically, $ H' $ consists of $ H $ together with points at infinity along the $ x $-axis and $ y $-axis. These axes are the asymptotes of $ H $.
\end{example*}

Compare the two above examples, where $ V' $ had equation $ wx - y^2 $, and $ H' $ had equation $ xy - w^2 $. These equations differ only by relabelling the coordinates. Thus $ V' $ and $ H' $ are isomorphic. We have not yet defined isomorphism of projective algebraic sets, but just relabelling the coordinates should certainly be an isomorphism. From the point of view of projective geometry, the only difference between the hyperbola and the parabola is that the parabola has one point at infinity while the hyperbola has two points at infinity. It turns out that $ V' $ and $ H' $ are also isomorphic to the projective line $ \PP^1 $. We will need to define isomorphism of projective algebraic sets before we can prove this.

\pagebreak

\subsubsection{Homogenisation}

The process we went through above to obtain $ V' $ from $ V $ and $ H' $ from $ H $ can be generalised.

\begin{definition*}
For any polynomial $ f \in k\sbr{X_1, \dots, X_n} $, we define the \textbf{homogenisation} of $ f $ to be the polynomial in $ \overline{f} \in k\sbr{X_0, \dots, X_n} $ obtained by the following procedure. Let $ d $ be the maximum degree of terms of $ f $. Then multiply each term of $ f $ by $ X_0^{d - e} $, where $ e $ is the degree of this term in $ f $.
\end{definition*}

\begin{example*}
If
$$ f\br{X_1, X_2, X_3} = X_1^3 + 4X_1X_2X_3 - X_1^2 - X_2^2 + 5X_3 + 8, $$
then the homogenisation is
$$ \overline{f}\br{X_0, X_1, X_2, X_3} = X_1^3 + 4X_1X_2X_3 - X_1^2X_0 - X_2^2X_0 + 5X_3X_0^2 + 8X_0^3. $$
\end{example*}

Let $ V \subseteq \AA^n $ be an affine algebraic set. Let $ W \subseteq \PP^n $ be the set defined by the homogenisations of all polynomials in $ \II\br{V} $. Then $ W $ is the smallest projective algebraic set containing $ V $. This is not entirely obvious, because we have defined it using infinitely many homogeneous polynomials. When we substitute $ x_0 = 1 $ into the polynomials defining $ W $, we just get back $ \II\br{V} $, so
$$ W \cap \cbr{\sbr{1 : x_1 : \dots : x_n}} = V. $$
This proves that every affine algebraic set $ V $ is of the form $ W \cap \AA^n $ for some projective algebraic set $ W $. We call $ W $ the \textbf{projective closure} of $ V $. When defining the projective closure, it is not enough to just take the homogenisations of some finite list of polynomials which define $ V $. You must take all of $ \II\br{V} $. The standard example of this below shows that if we just use homogenisations of a generating set, instead of all of $ \II\br{V} $, we still get a projective algebraic set $ V' $ such that $ V' \cap \AA^n = V $, but it might not be the smallest such set.

\begin{example*}
Here is a more complex example, the twisted cubic curve. Let
$$ C = \cbr{\br{t, t^2, t^3} \in \AA^3} = \VV\br{Y - X^2, Z - XY} \subseteq \AA^3. $$
Parametrically, we can write this as
$$ C = \cbr{\sbr{1 : t : t^3 : t^3} \in \PP^3}. $$
Homogenising the parametric description, we might expect the projective closure to be
$$ C' = \cbr{\sbr{s^3 : s^2t : st^2 : t^3} \in \PP^3} = C \cup \cbr{\sbr{0 : 0 : 0 : 1}}. $$
One can check that $ C' $ is a projective algebraic set. But if we homogenise the two defining polynomials $ Y - X^2 $ and $ Z - XY $, we get the projective algebraic set
$$ C'' = \cbr{\sbr{w : x : y : z} \in \PP^3 \st wy - x^2 = wz - xy = 0}. $$
It is still true that we can reverse this by just setting $ w = 1 $, so $ C'' \cap \AA^3 = C $. But what happens at infinity? Substituting in $ w = 0 $, one can check that
$$ C'' = C \cup \cbr{\sbr{0 : x : y : z} \in \PP^3 \st -x^2 = -xy = 0} = C \cup \cbr{\sbr{0 : 0 : y : z} \in \PP^3}. $$
Thus the intersection of $ C'' $ with the plane at infinity is a copy of $ \PP^1 $. Thus $ C'' \ne C' $. It contains an extra line at infinity. This is not what we should expect, if $ C'' $ were the projective closure of $ C $, since the dimension of the intersection with the plane at infinity should be smaller than the dimension of the initial affine algebraic set, speaking informally. If we homogenised all polynomials in $ \II\br{C} $ and not just the two generators, then you can calculate that the projective closure of $ C $ is in fact
$$ C' = \cbr{\sbr{w : x : y : z} \in \PP^3 \st wy - x^2 = wz - xy = xz - y^2 = 0} = C \cup \cbr{\sbr{0 : 0 : 0 : 1}}. $$
The three polynomials $ Y - X^2, Z - XY, XZ - Y^2 $ are a generating set for $ \II\br{C} $ and their homogenisations define $ C' $. The extra polynomial involves only $ x, y, z $ and is in the ideal generated by $ Y - X^2 $ and $ Z - XY $. I am not giving a procedure to find the projective closure of a given affine algebraic set. I just assert that this happens to work in this case. There is an algorithm but you would not want to have to use it by hand.
\end{example*}

\pagebreak

I did not actually prove that the projective closure $ \overline{V} $ of $ V \subseteq \AA^n $ is a projective algebraic set, because we constructed $ V $ as the zero set of infinitely many homogeneous polynomials, but said that a projective algebraic set must be defined using finitely many homogeneous polynomials. We can prove that these are equivalent using the Hilbert basis theorem, but it is a little more subtle than in the affine case.

\begin{definition*}
A \textbf{homogeneous ideal} in $ k\sbr{X_0, \dots, X_n} $ is an ideal which can be generated by homogeneous polynomials.
\end{definition*}

\begin{note*}
A homogeneous ideal does not contain only homogeneous polynomials. One can take a homogeneous polynomial $ f $ in the ideal and multiply it by $ X_0 + 1 $ to get a non-homogeneous ideal in $ I $.
\end{note*}

If $ f $ is any polynomial in $ k\sbr{X_0, \dots, X_n} $, we can write $ f $, uniquely, as
$$ f = \sum_{i = 0}^d f_i, $$
where $ f_i $ is homogeneous of degree $ i $. The $ f_i $ are called the \textbf{homogeneous components} of $ f $.

\begin{lemma}
\label{lem:homogeneousideal}
An ideal $ I \subseteq k\sbr{X_0, \dots, X_n} $ is a homogeneous ideal if and only if, for each $ f \in I $, every homogeneous component of $ f $ is in $ I $.
\end{lemma}

\begin{proof}
Just some algebraic manipulation.
\end{proof}

\begin{proposition}
\label{prop:homogeneousideal}
Let $ I \subseteq k\sbr{X_0, \dots, X_n} $ be a homogeneous ideal. Then there exists a finite set $ f_1, \dots, f_m $ of homogeneous polynomials which generate $ I $.
\end{proposition}

\begin{proof}
By the Hilbert basis theorem, there exists a finite set $ g_1, \dots, g_r $ of polynomials, not necessarily homogeneous, which generate $ I $. In total, the $ g_i $ have finitely many homogeneous components. By Lemma \ref{lem:homogeneousideal}, all homogeneous components are in $ I $. Clearly they generate $ I $.
\end{proof}

Thus any set of homogeneous polynomials, even an infinite set, defines a projective algebraic set. We can use Proposition \ref{prop:homogeneousideal} to prove that every projective algebraic set is a finite union of irreducible components, by the same proof as for affine algebraic sets.

\subsubsection{Zariski topology on projective space}

We can define the Zariski topology on $ \PP^n $ by saying that the closed subsets are the projective algebraic sets. Observe that $ \AA^n $ is embedded as a Zariski open subset in $ \PP^n $, because the complement $ \PP^n \setminus \AA^n $ is described by the homogeneous polynomial equation $ X_0 = 0 $. The existence of projective closures shows that the Zariski topology on $ \AA^n $ is the same as the subspace topology coming from the Zariski topology on $ \AA^n \subseteq \PP^n $. The terminology projective closure is justified by noting that the smallest projective algebraic set containing $ V \subseteq \AA^n $ which we just described is the same as the closure of $ V $ in the Zariski topology on $ \PP^n $.

\subsubsection{The projective Nullstellensatz}

\lecture{14}{Thursday}{13/02/20}

Which homogeneous ideals can occur as the ideal of functions vanishing on a projective algebraic set? Clearly they have to be radical ideals. Is there a projective version of the Nullstellensatz? Yes, but it turns out that there is an exceptional case to deal with. Consider the homogeneous ideal
$$ I_1 = \abr{X_0, \dots, X_n} \subseteq k\sbr{X_0, \dots, X_n}. $$
The only solution in $ k^{n + 1} $ to the equations $ x_0 = 0, \dots, x_n = 0 $ is $ \br{0, \dots, 0} $. But this is not the homogeneous coordinates of any point in $ \PP^n $. So the projective algebraic set defined by $ I_1 $ is the empty set. Thus the ideals $ I_1 $ and $ k\sbr{X_0, \dots, X_n} $ both define the empty set by $ I_1 $ is the empty set. Thus the ideals $ I_1 $ and $ k\sbr{X_0, \dots, X_n} $ both define the empty set in $ \PP^n $, even though they are both radical homogeneous ideals. So we have to modify the statement of the Nullstellensatz slightly from the affine case. Thus turns out to be the only special case.

\pagebreak

\begin{proposition}[Projective weak Nullstellensatz]
Let $ I \subseteq k\sbr{X_0, \dots, X_n} $ be a homogeneous ideal such that $ \rad I $ is not equal to either $ k\sbr{X_0, \dots, X_n} $ or $ I_1 = \abr{X_0, \dots, X_n} $. Then the projective algebraic set defined by $ I $ is non-empty.
\end{proposition}

\begin{proof}
Let $ V \subseteq \PP^n $ denote the projective algebraic set defined by $ I $. We can also consider the affine algebraic set $ \VV\br{I} \subseteq \AA^{n + 1} $ defined by $ I $, which we label $ C $. Since $ \rad I \ne k\sbr{X_0, \dots, X_n} $ and $ \rad I \ne I_1 $, the affine strong Nullstellensatz tells us that $ C $ is not equal to their associated affine algebraic sets, namely $ \emptyset $ or $ \cbr{\br{0, \dots, 0}} $. Therefore $ C $ contains some point $ \br{x_0, \dots, x_n} \in \AA^{n + 1} $ other than the origin. But then the point of $ \PP^n $ with homogeneous coordinates $ \sbr{x_0 : \dots : x_n} $ is in $ V $.
\end{proof}

We saw the projective weak Nullstellensatz, and we saw that the radical homogeneous ideal $ \abr{X_0, \dots, X_n} $ defines the empty projective algebraic set, the same as $ \abr{1} $. However, this turns out to be the only exception to the bijection between radical homogeneous ideals and projective algebraic sets.

\begin{theorem}
The map sending a homogeneous ideal to the corresponding projective algebraic set is a bijection between the sets
$$ \correspondence{\text{radical homogeneous ideals in} \ k\sbr{X_0, \dots, X_n} \\ \text{other than} \ \abr{X_0, \dots, X_n}}{\text{projective algebraic sets in} \ \PP^n}. $$
\end{theorem}

The set $ C $ which appears in the above proof is called the \textbf{affine cone} of $ V $. It is the union of the lines through the origin in $ \AA^{n + 1} $ which correspond to points of $ V \subseteq \PP^n $.

\begin{proof}
Apply the affine Nullstellensatz to the affine cones of projective algebraic sets in $ \AA^{n + 1} $ defined by the same ideal.
\end{proof}

\subsubsection{A remark on compactness}

Over the complex numbers, every projective algebraic set is compact in the analytic topology. This is because they are closed subsets of $ \PP_\CC^n $, which is compact. In the Zariski topology, the notion of compactness is not very interesting, since every algebraic set is compact in the Zariski topology, even affine algebraic sets. Affine algebraic sets definitely do not behave in ways matching our intuition about compactness, since this intuition and most of the usual theory of compact sets is only valid when the spaces are Hausdorff. There is a converse to this, which tells us that there is a very close relationship between analytic and algebraic geometry in $ \PP_\CC^n $.

\begin{theorem}[Chow's theorem]
\label{thm:chowtheorem}
Let $ V $ be an analytic subset of $ \PP_\CC^n $ which is closed in the analytic topology. Then $ V $ is a projective algebraic set.
\end{theorem}

I will not define analytic subsets here, but roughly it means a set defined by zeroes of holomorphic functions. Theorem \ref{thm:chowtheorem} is much harder to prove than to state, and requires too much complex analytic geometry beyond this course to prove here. One can prove analytically that every holomorphic function on a connected compact complex manifold is constant.

\begin{example*}
This holds on the Riemann sphere, which is equal to $ \PP_\CC^1 $.
\end{example*}

Polynomials are holomorphic, so every regular function on a connected projective algebraic set over $ \CC $ is constant. Once we define regular functions on projective algebraic sets, it will turn out that the same is true over any field.

\pagebreak

\subsection{Regular and rational maps}

In the affine case, we defined regular functions first and then used them to define regular maps. However, as remarked above the only regular functions on an irreducible projective algebraic set are constants so they are not useful for defining regular maps. Therefore we will jump directly to defining regular maps between projective algebraic sets.

\subsubsection{Regular maps between projective algebraic sets}

Let $ V \subseteq \PP^m $ and $ W \subseteq \PP^n $ be projective algebraic sets. We expect a regular map $ \phi : V \to W $ to be a function which can be expressed as polynomials in the homogeneous coordinates, so
$$ \phi\br{\sbr{x_0 : \dots : x_m}} = \sbr{f_0\br{x_0, \dots, x_m} : \dots : f_n\br{x_0, \dots, x_m}}. $$
Because we are working with homogeneous coordinates, in order for this to be a well-defined function, all the $ f_i $ must be homogeneous polynomials of the same degree. Then, if we re-scale the input coordinates $ \sbr{x_0 : \dots : x_m} $ by $ \lambda $, we get
\begin{align*}
\sbr{f_0\br{\lambda x_0, \dots, \lambda x_m} : \dots : f_n\br{\lambda x_0, \dots, \lambda x_m}}
& = \sbr{\lambda^df_0\br{x_0, \dots, x_m} : \dots : \lambda^df_n\br{x_0, \dots, x_m}} \\
& = \sbr{f_0\br{x_0, \dots, x_m} : \dots : f_n\br{x_0, \dots, x_m}}.
\end{align*}
Thus all the output coordinates are multiplied by the same value $ \lambda^d $, so they define the same point in $ \PP^n $. There is another condition which must be imposed to get a well-defined function $ V \to \PP^m $. We must never have
$$ f_0\br{x_0, \dots, x_m} = \dots = f_m\br{x_0, \dots, x_m} = 0, $$
because $ \sbr{0 : \dots : 0} $ is not the homogeneous coordinates of a point in $ \PP^n $. However it turns out that often, there is not a single sequence of polynomials which will define a regular map at every point of $ V $. Whatever polynomials we try, there might be some points where they all vanish. This is a very strong condition and there are too few lists of polynomials which satisfy it. However, we can get round it to some extent by imitating rational maps between affine algebraic sets, and allowing different sequences of polynomials to represent our regular map at different points of $ V $, so that, at each point, there is some list of polynomials which is always non-zero. It is the homogeneous nature of the coordinates that allows us to do this in such a way that the different sequences of polynomials represent the same regular map at places wherever they overlap. To help explain this, we consider an example.

\begin{example*}
Let $ V $ be the projective closure of the parabola, that is
$$ V = \cbr{\sbr{w : x : y} \in \PP^2 \st wy = x^2}. $$
Let
$$ V' = V \cap \cbr{\sbr{w : x : y} \st w \ne 0} = \cbr{\br{x, y} \in \AA^2 \st y = x^2}. $$
There is a regular map given by
$$ \function[\phi']{V'}{\AA^1}{\br{x, y}}{x}. $$
Does this extend to a regular map $ \phi : V \to \PP^1 $? We guess it should send the point at infinity $ \sbr{0 : 0 : 1} \in V $ to the point at infinity $ \sbr{0 : 1} \in \PP^1 $. To attempt to construct such a map, write $ \phi' $ in homogeneous coordinates using the embedding $ \AA^2 \hookrightarrow \PP^2 $, so
$$ \function[\phi']{V'}{\AA^1}{\sbr{1 : x : y}}{\sbr{1 : x}}. $$
Now we homogenise, that is multiply by powers of the extra coordinate $ w $ to make all the polynomials homogeneous of degree one, so
$$ \function[\phi]{V}{\PP^1}{\sbr{w : x : y}}{\sbr{w : x}}. $$

\pagebreak

This maps $ \sbr{0 : 0 : 1} $ to $ \sbr{0 : 0} $ which is not allowed. But we can fix this by expressing the same map differently. Using the homogeneous nature of the coordinates, and the equation $ x^2 = wy $ defining $ V $, we have
$$ \sbr{w : x} = \sbr{wx : x^2} = \sbr{wx : wy} = \sbr{x : y}, $$
whenever the values we multiplied or divided by, $ w $ and $ x $, are non-zero. The expression $ \sbr{x : y} $ is well-defined at $ \sbr{0 : 0 : 1} $, with value $ \sbr{0 : 1} $. On the other hand, $ \sbr{x : y} $ gives $ \sbr{0 : 0} $ at the point $ \sbr{1 : 0 : 0} \in V $, so we cannot use $ \sbr{x : y} $ alone to define a map $ V \to \PP^1 $. The two expressions together give a well-defined regular map
$$ \function[\phi]{V}{\PP^1}{\sbr{w : x : y}}{
\begin{cases}
\sbr{w : x} & w \ne 0 \\
\sbr{x : y} & y \ne 0
\end{cases}
}. $$
To check that this does indeed define a map $ V \to \PP^1 $, we have the check the following.
\begin{itemize}
\item We have defined the map at every point of $ \PP^1 $. This is true because every point of $ V $ must have to satisfy at least one of $ w \ne 0 $ or $ y \ne 0 $, since if $ w = y = 0 $, then the equation $ wy = x^2 $ implies that $ x = 0 $ but $ \sbr{0 : 0 : 0} $ is not a point of $ \PP^2 $. Thus at least one of these two expressions is defined everywhere on $ V $.
\item On the overlap between the two open sets, both expressions define the same map. This is true because, if $ w $ and $ y $ are both non-zero and $ \sbr{w : x : y} \in V $, then $ x $ is also non-zero. We can then see that $ \sbr{x : y} = \sbr{w : x} $.
\end{itemize}
In this example, there is no single sequence of homogeneous polynomials which defines $ \phi $ everywhere on $ \PP^1 $. Note that each of these expressions is well-defined on a Zariski open subset of $ V $, since they are made up of homogeneous polynomials of the same degree, and they never give a point with homogeneous coordinates $ \sbr{0 : 0} $ within the specified open sets. This is important because it is how we ensure that the value of $ \phi $ at each point is polynomially related to its value at nearby points. Open sets are the natural way to talk about nearby points in a topological space. This still applies in the Zariski topology, even though open sets are very big.
\end{example*}

\begin{note*}
Questions $ 5 $ and $ 6 $ on problem sheet $ 2 $ give examples of regular maps defined everywhere except at a single point of an affine algebraic set, where there is an obvious value the map should take at the missing point, but the map is not regular at that point because there is no way to extend it to that point using polynomials. This is why we are not allowed just to write down polynomials on arbitrary non-open subsets of $ V $ and claim they define a regular map.
\end{note*}

Therefore, a regular map is defined to be a map which can be represented by some homogeneous polynomials at every point of $ V $. It is not enough just to say that for each point $ x \in V $, there exist some polynomials which give the correct value at $ x $, because then we could get every set-theoretic map by choosing different polynomials at different points. To relate the values of the map at different points, we require that there is some list of polynomials which defines the map on an open neighbourhood of $ x $. The formal definition of a regular map between projective algebraic sets $ V \subseteq \PP^m $ and $ W \subseteq \PP^n $ is the following.

\begin{definition*}
A \textbf{regular map} $ \phi : V \to W $ is a function $ V \to W $ such that for every point $ x \in V $, there exist a Zariski open set $ U \subseteq V $ containing $ x $ and a sequence of polynomials $ f_0, \dots, f_n \in k\sbr{X_0, \dots, X_m} $ such that,
\begin{itemize}
\item $ f_0, \dots, f_n $ are homogeneous of the same degree,
\item for every $ y \in U $, $ f_0, \dots, f_n $ are not all zero at $ y $, and
\item for every $ y = \sbr{y_0 : \dots : y_m} \in U $, $ \phi\br{y} = \sbr{f_0\br{y_0, \dots, y_m} : \dots : f_n\br{y_0, \dots, y_m}} $.
\end{itemize}
\end{definition*}

In practice, every regular map can be written down by specifying lists of polynomials on just finitely many open sets, like $ \phi $. This follows ultimately from the Hilbert basis theorem. To check that a purported definition like $ \phi $ really does define a regular map $ V \to W $, you have to check

\pagebreak

\begin{itemize}
\item each set on which an expression is defined is Zariski open,
\item an expression never gives $ \sbr{0 : \dots : 0} $ on its associated set,
\item two expressions agree wherever they are both defined, and
\item the image of the map is contained in $ W $.
\end{itemize}

\begin{example*}
As another example, taking $ V $ and $ V' $ as in the previous example, let us try to extend the inverse of $ \phi $ from affine to projective algebraic sets. On affine algebraic sets, the inverse of $ \phi' $ is given by
$$ \function[\psi']{\AA^1}{V'}{t}{\br{t, t^2}}. $$
In projective coordinates, this is
$$ \function[\psi']{\AA^1}{V'}{\sbr{1 : t}}{\sbr{1 : t : t^2}}. $$
Homogenising, by inserting powers of $ s $ to make all the polynomials on right hand side degree two, we get
$$ \function[\psi]{\PP^1}{V}{\sbr{s : t}}{\sbr{s^2 : st : t^2}}. $$
Now recalling that $ s $ and $ t $ cannot both be zero at the same point, $ s^2, st, t^2 $ are never simultaneously zero for $ \sbr{s : t} \in \PP^1 $, so in this case the single expression $ \sbr{s^2 : st : t^2} $ is enough to define a regular map $ \psi : \PP^1 \to V $ everywhere on $ \PP^1 $. Note that the image of $ \phi $ is indeed contained in $ V $.
\end{example*}

\begin{note*}
This homogenisation procedure often allows us to extend a regular map between affine algebraic sets into a regular map between their projective closures, but it does not always work. Sometimes there are regular maps between affine algebraic sets which it is impossible to extend to regular maps between their projective closures, since there are points for which it is impossible to avoid sending them to $ \sbr{0 : \dots : 0} $, or we might find that the homogeneous polynomials
involved become simultaneously zero at some point at infinity.
\end{note*}

\lecture{15}{Friday}{14/02/20}

\begin{definition*}
A regular map $ \phi : V \to W $ between projective algebraic sets is an \textbf{isomorphism} if there exists a regular map $ \psi : W \to V $ such that $ \phi \circ \psi = \id_W $ and $ \psi \circ \phi = \id_V $.
\end{definition*}

Observe that the two maps $ \phi : V \to \PP^1 $ and $ \psi : \PP^1 \to V $ which we just defined are inverses, so we conclude that the projective parabola $ V $ is isomorphic to $ \PP^1 $. We already remarked that the projective parabola is isomorphic to the projective hyperbola
$$ H = \cbr{\sbr{w : x : y} \in \PP^2 \st xy = w^2}, $$
by relabelling coordinates, so we deduce that the projective hyperbola is also isomorphic to $ \PP^1 $. In fact, we can show that all irreducible \textbf{conics} in $ \PP^2 $, subsets of $ \PP^2 $ defined by a homogeneous polynomial of degree two, are isomorphic to $ \PP^1 $, by using a projection as in problem $ 5 $ on problem sheet $ 2 $, and checking that in the projective setting, in this case, the projection gives regular maps and not just rational ones.

\subsubsection{Regular maps equal on a dense subset}

We already proved and made use of the following lemma previously for regular maps between affine algebraic sets. It is even more useful for regular maps between projective algebraic sets as it tells us that we only need to test equality between regular maps on a dense subset, since we will need it in the definition of rational maps.

\begin{lemma}
\label{lem:projectivedense}
Let $ \phi, \psi : V \to W $ be regular maps. If there exists a Zariski dense subset $ A \subseteq V $ such that $ \eval{\phi}_A = \eval{\psi}_A $, then $ \phi = \psi $.
\end{lemma}

\begin{example*}
Lemma \ref{lem:projectivedense} is especially useful if $ V $ is irreducible, because then Zariski open subsets of $ V $ are dense. So Lemma \ref{lem:projectivedense} tells us that, given a list of polynomials on a Zariski open subset of $ V $, there is at most one regular map which is given by that list of polynomials on that set, then it is sufficient to look at the open set where a single expression for the regular map is defined.
\end{example*}

\pagebreak

We will use the following topological fact.

\begin{fact*}
Let $ S $ be any topological space, not necessarily Hausdorff. Let $ \cbr{U_\alpha} $ be a collection of open subsets of $ S $, whose union is all of $ S $. Let $ Z $ be any subset of $ S $ such that $ Z \cap U_\alpha $ is closed in the subspace topology on $ U_\alpha $ for every $ \alpha $. Then $ Z $ is closed as a subset of $ S $.
\end{fact*}

\begin{proof}
Let
$$ Z = \cbr{x \in V \st \phi\br{x} = \psi\br{x}}. $$
By hypothesis, $ Z $ contains a dense subset of $ V $. Hence in order to show that $ Z = V $, it suffices to show that $ Z $ is closed in $ V $. From the definition of regular maps, we know that we can cover $ V $ by Zariski open sets $ U_\alpha $ such that on each $ U_\alpha $, both $ \phi $ and $ \psi $ are defined by sequences of homogeneous polynomials, so
$$ \eval{\phi}_{U_\alpha} = \sbr{f_{\alpha, 0} : \dots : f_{\alpha, m}}, \qquad \eval{\psi}_{U_\alpha} = \sbr{g_{\alpha, 0} : \dots : g_{\alpha, m}}. $$
By the general topological fact, it suffices to show that $ Z \cap U_\alpha $ is relatively closed in the subspace topology on $ U_\alpha $ for every $ \alpha $. Now
$$ Z \cap U_\alpha = \cbr{x \in U_\alpha \st \sbr{f_{\alpha, 0}\br{x} : \dots : f_{\alpha, m}\br{x}} = \sbr{g_{\alpha, 0}\br{x} : \dots : g_{\alpha, m}\br{x}}}. $$
This is the same as the set of $ x \in U_\alpha $ where the vectors $ \br{f_{\alpha, 0}\br{x}, \dots, f_{\alpha, m}\br{x}} $ and $ \br{g_{\alpha, 0}\br{x}, \dots, g_{\alpha, m}\br{x}} $ are proportional, for any choice of homogeneous coordinates for $ x $, or in other words where the matrix
$$ \twobyone{f_{\alpha, 0}\br{x} \qquad \dots \qquad f_{\alpha, m}\br{x}}{g_{\alpha, 0}\br{x} \qquad \dots \qquad g_{\alpha, m}\br{x}} $$
has rank one. A little linear algebra shows that this condition is equivalent to all the $ 2 \times 2 $ minors of this matrix vanishing, that is
$$ f_{\alpha, i}\br{x}g_{\alpha, j}\br{x} - f_{\alpha, j}\br{x}g_{\alpha, i}\br{x} = 0, \qquad i, j \in \cbr{0, \dots, m}. $$
This last condition is given by homogeneous polynomials, and therefore defines a closed subset in the subspace topology on $ U_\alpha $.
\end{proof}

\subsubsection{Quasi-projective algebraic sets}

So far, we have defined affine algebraic sets and projective algebraic sets, as separate types of objects. It is very convenient to have a single notion that unifies both affine and projective algebraic sets, for example to save us from having to prove a lemma for affine algebraic sets, then the same lemma for projective algebraic sets.

\begin{definition*}
A \textbf{quasi-projective algebraic set} is the intersection between an open subset and a closed subset of $ \PP^n $, in the Zariski topology.
\end{definition*}

A projective algebraic set is quasi-projective, by just taking the open subset to be $ \PP^n $ itself. An affine algebraic set $ V $ is also quasi-projective, since it is the intersection between $ \AA^n $, which is open in $ \PP^n $, and the projective closure $ \overline{V} $. There are other quasi-projective algebraic sets, for example $ \AA^1 \setminus \cbr{0} $ which is an open subset of $ \PP^1 $. We define a regular map between quasi-projective algebraic sets by the same definition as a regular map between projective algebraic sets, so it is a map which has a well-defined expression by homogeneous polynomials on a neighbourhood of every point. If $ V $ and $ W $ are affine algebraic sets, we now have two ways to define regular maps $ V \to W $.
\begin{itemize}
\item The original definition of regular maps between affine algebraic sets.
\item View $ V $ and $ W $ as quasi-projective algebraic sets, and use the new definition of regular maps between quasi-projective algebraic sets.
\end{itemize}
Fortunately, these two definitions turn out to be equivalent. One has to do a bit of work to check this. The problem is that a regular map of affine algebraic sets must be defined by the same list of polynomials at every point, but a regular map of quasi-projective algebraic sets may be defined by different polynomials at every point. Proving that actually one list of polynomials is enough if the set happens to be affine is similar to the proof of Lemma \ref{lem:rationalregular}. This gives us for free a notion of regular maps from a projective algebraic set to an affine algebraic set or vice versa. Just view them both as quasi-projective algebraic sets.

\pagebreak

\begin{example*}
We can now define a regular function on a projective algebraic set $ V $ to be a regular map $ V \to \AA^1 $, thus it is a function from the algebraic set $ V $ taking values in the base field $ k $. As remarked last lecture, we will later prove that the only regular functions on a projective algebraic set are the constants.
\end{example*}

\begin{example*}
We can now make rigorous the claim that $ \AA^1 \setminus \cbr{0} $ looks the same as the affine hyperbola
$$ H = \cbr{\br{x, y} \in \AA^2 \st xy = 1}. $$
The set $ \AA^1 \setminus \cbr{0} = \PP^1 \setminus \cbr{\sbr{1 : 0}, \sbr{0 : 1}} $ is a Zariski open subset of $ \PP^1 $, because its complement is finite. Hence $ \AA^1 \setminus \cbr{0} $ is a quasi-projective algebraic set. The map
$$ \function[\phi]{\AA^1 \setminus \cbr{0}}{H}{t}{\dfrac{1}{t}} $$
can be written in homogeneous coordinates as
$$ \function[\phi]{\AA^1 \setminus \cbr{0}}{H}{\sbr{1 : t}}{\sbr{1 : t : \dfrac{1}{t}} = \sbr{t : t^2 : 1}}, $$
so homogenising, we get
$$ \function[\phi]{\AA^1 \setminus \cbr{0}}{H}{\sbr{s : t}}{\sbr{st : t^2 : s^2}}. $$
So long as $ \sbr{s : t} \in \AA^1 \setminus \cbr{0} $, this does give a point in
$$ H = \cbr{\sbr{w : x : y} \in \PP^2 \st xy = w^2} \cap \AA^2, $$
so $ \phi $ is a regular map $ \AA^1 \setminus \cbr{0} \to H $. The projection $ \br{x, y} \mapsto x $ is a regular inverse to $ \phi $. Hence $ \AA^1 \setminus \cbr{0} $ and $ H $ are isomorphic as quasi-projective algebraic sets.
\end{example*}

As mentioned previously, we use the word \textbf{variety} to mean an algebraic set considered up to isomorphism, not caring about how it is embedded into affine or projective space.

\begin{example*}
$ \AA^1 \setminus \cbr{0} $ is isomorphic, as a quasi-projective algebraic set, to the affine algebraic set $ H $, so we may say that $ \AA^1 \setminus \cbr{0} $ is an affine variety, even though $ \AA^1 \setminus \cbr{0} $ is definitely not an affine algebraic set.
\end{example*}

There exist quasi-projective algebraic sets which are not isomorphic to anything either projective or affine.

\begin{example*}
$ \AA^2 \setminus \cbr{\br{0, 0}} $. See problem sheet $ 3 $.
\end{example*}

\subsubsection{Rational maps between quasi-projective algebraic sets}

Let $ V \subseteq \PP^m $ and $ W \subseteq \PP^n $ be irreducible quasi-projective algebraic sets. The formal definition of a rational map $ V \dashrightarrow W $ looks quite complicated, but the underlying idea is the same as for regular maps. Just like for affine algebraic sets, a rational map is something which is almost a regular map, except that it is allowed to have some points where it is not defined. Rational maps of affine algebraic sets were non-regular at points where the denominator was zero. For quasi-projective algebraic sets, they are non-regular at points where the coordinates of the image become $ \sbr{0 : \dots : 0} $.

\begin{note*}
Unlike for affine sets, there is no need to use fractions of polynomials in the definition of rational maps between quasi-projective algebraic sets. Because our coordinates are homogeneous, we can always multiply up by a common denominator and get an expression involving only polynomials.
\end{note*}

Once again, somehow we have to make a definition which takes account of the fact that rational maps can be expressed in terms of different lists of polynomials at different points, and it might be necessary to use more than one expression to see the full domain of definition of the rational map. But unlike with regular maps of projective algebraic sets, we cannot tie the different expressions together into a single object by saying a rational map is a function $ V \to W $, because a rational map is not a function $ V \to W $. Instead we define rational maps as equivalence classes for a certain equivalence relation.

\pagebreak

\begin{note*}
Before defining rational maps as equivalence classes, let us ask, why is that a sensible thing to do? Thinking back to the definition of rational functions on an affine variety $ V $, this happens under the hood in defining rational functions on affine varieties too. They are defined as the elements of the field of fractions of $ k\sbr{V} $. The field of fractions of an integral domain $ R $ is defined as a set of equivalence classes, namely, you take the set $ \cbr{\br{a, b} \in R^2 \st b \ne 0} $, and the equivalence relation $ \br{a, b} \sim \br{c, d} $ if $ ad = bc $. The field of fractions of $ R $ is defined to be the set of equivalence classes for this relation. But normally we do not think of fractions as equivalence classes. We just write down one representative, with the special notation $ a / b $, and then manipulate it by the normal rules for manipulating fractions. In the ring $ R = \ZZ $, then often it may make sense to reduce fractions to lowest terms representatives, and if we impose the condition $ b > 0 $, then every fraction has a unique lowest terms representative. But if $ R $ is not a UFD, then we do not have special lowest terms representatives for fractions. This matches the fact that we might need different expressions to define a rational map at different points.
\end{note*}

So our definition begins by saying which sequences of polynomials determine rational maps, and then specifies when two sequences of polynomials determine the same rational map.

\begin{definition*}
A \textbf{rational map} $ \phi : V \dashrightarrow \PP^n $ is defined by a sequence of homogeneous polynomials $ f_0, \dots, f_n \in k\sbr{X_0, \dots, X_m} $ of the same degree such that $ f_0, \dots, f_n $ are not identically zero on $ V $. We write this as $ \phi = \sbr{f_0 : \dots : f_n} $. Two sequences of polynomials $ \sbr{f_0 : \dots : f_n} $ and $ \sbr{g_0 : \dots : g_n} $ represent the same rational map if the homogeneous coordinates $ \sbr{f_0\br{x} : \dots : f_n\br{x}} $ and $ \sbr{g_0\br{x} : \dots : g_n\br{x}} $ represent the same point in $ \PP^n $ wherever both expressions make sense. Using the fact that $ V $ is irreducible, we can check that this is an equivalence relation on sequences of homogeneous polynomials.
\end{definition*}

This is exactly the same as the definition of a regular map $ V \to \PP^n $, except that we are allowing there to be points where no expression for the map is defined. Now we define rational maps $ V \dashrightarrow W $, where $ W \subseteq \PP^n $ is any quasi-projective algebraic set. The definition is mostly what you would expect. A rational map is determined by a sequence of homogeneous polynomials $ \sbr{f_0 : \dots : f_n} $. There are points where these polynomials are allowed to be all zero, but they cannot be all zero everywhere on $ V $ so that the rational map is defined somewhere. When we say that the rational map goes into $ W $ instead of into $ \PP^n $, we require there to be a Zariski dense set $ A \subseteq V $ on which $ \sbr{f_0\br{x} : \dots : f_n\br{x}} $ lies in $ W $, but we do not require $ \sbr{f_0\br{x} : \dots : f_n\br{x}} \in W $ at every point of $ V $. This is the difference between regular and rational maps.

\begin{definition*}
Let $ V \subseteq \PP^m $ and $ W \subseteq \PP^n $ be irreducible quasi-projective algebraic sets. Let $ S $ denote the set of sequences $ \br{f_0, \dots, f_n} \in k\sbr{X_0, \dots, X_m}^{n + 1} $ such that,
\begin{itemize}
\item $ f_0, \dots, f_n $ are homogeneous of the same degree,
\item $ f_0, \dots, f_n $ are not all identically zero on $ V $, noting that this looks a little like the $ b \ne 0 $ condition in defining the field of fractions, and
\item there exists a non-empty Zariski dense open set $ A \subseteq V $ such that, for all $ x \in A $, the homogeneous coordinates $ \sbr{f_0\br{x} : \dots : f_n\br{x}} $ make sense and define a point in $ W $.
\end{itemize}
Define an equivalence relation $ \sim $ on $ S $ by,
$$ \br{f_0, \dots, f_n} \sim \br{g_0, \dots, g_n} \qquad \iff \qquad \sbr{f_0\br{x} : \dots : f_n\br{x}} = \sbr{g_0\br{x} : \dots : g_n\br{x}} \in \PP^n, $$
for all $ x \in V $ where both expressions make sense. We could write this more algebraically as,
$$ \br{f_0, \dots, f_n} \sim \br{g_0, \dots, g_n} \qquad \iff \qquad f_ig_j = f_jg_i, \qquad i, j \in \cbr{0, \dots, n}. $$
Having defined $ S $ and $ \sim $, we then define a \textbf{rational map} $ \phi : V \dashrightarrow W $ to be an equivalence class in $ S $ for $ \sim $.
\end{definition*}

These two definitions of $ S $ and $ \sim $ are more formal ways of writing the two parts of the definition of a rational map. Observe that this resembles the equivalence relation used in defining the field of fractions. One needs to check that $ \sim $ really is an equivalence relation. This is a detail which was hidden in my informal statement of the definition. This uses the fact that $ V $ is irreducible and Lemma \ref{lem:projectivedense} that if two polynomials are equal on a Zariski dense set, then they are equal everywhere. Just as with fractions, we usually just write down a single representative for a rational map. There is a special notation for representatives of rational maps in $ S $, namely $ \sbr{f_0 : \dots : f_n} $. We have seen examples on problem sheets of UFD-like situations where one can choose a lowest terms representative for the rational map, but this is not always possible.

\lecture{16}{Monday}{17/02/20}

Lecture 16 is a problems class.

\pagebreak

\subsubsection{Domain of definition of rational maps}

\lecture{17}{Thursday}{20/02/20}

\begin{definition*}
A rational map $ \phi : V \to W $ is \textbf{regular} at a point $ x \in V $ if there exists at least one list of polynomials $ \br{f_0, \dots, f_n} \in S $ representing $ \phi $ such that $ \sbr{f_0\br{x} : \dots : f_n\br{x}} \ne \sbr{0 : \dots : 0} $ and $ \sbr{f_0\br{x} : \dots : f_n\br{x}} \in W $. If $ \phi $ is regular at $ x \in V $, then the equivalence relation $ \sim $ ensures that the value $ \phi\br{x} \in W $ makes sense and is well-defined, with homogeneous coordinates given by $ \sbr{f_0\br{x} : \dots : f_n\br{x}} $. This point is independent of the choice of polynomials representing $ \phi $, as well as independent of the choice of homogeneous coordinates for $ x $. Just as for affine algebraic sets, we define the \textbf{domain of definition} of a rational map to be the set of points where it is regular, the union of the sets where each representative of the equivalence class makes sense as a map.
\end{definition*}

\begin{note*}
Just as in the affine case, when checking whether $ \phi $ is regular at a point $ x $, it is not enough to check whether the representation $ \sbr{f_0 : \dots : f_n} $ which we first used to define the map is regular at $ x $. We have to check whether there exists any representation $ \sbr{g_0 : \dots : g_n} $ for $ \phi $ which is defined at $ x $.
\end{note*}

\begin{note*}
Furthermore, the domain of definition of a rational map can change if we change the target set $ W $.
\end{note*}

\begin{example*}
Consider the map defined by
$$ \function{\PP^1}{\PP^2}{\sbr{s : t}}{\sbr{s^2 : st : t^2}}. $$
This is regular at every point. We could interpret the same formula as defining a rational map $ \PP^1 \dashrightarrow W $ where $ W \subseteq \PP^2 $ is the open set $ W = \cbr{\sbr{w : x : y} \st w \ne 0} $. As a rational map $ \PP^1 \dashrightarrow W $, this is not regular at the point $ \sbr{0 : 1} $ because this point maps to $ \sbr{0 : 0 : 1} \notin W $.
\end{example*}

\begin{lemma}
Let $ \phi : V \dashrightarrow W $ be a rational map. The domain of definition of $ \phi $ is a non-empty Zariski open subset of $ V $.
\end{lemma}

\begin{proof}
Similar to the affine case, in Lemma \ref{lem:domaindefinition}.
\end{proof}

It follows immediately from the definition of regular maps between quasi-projective algebraic sets that if a rational map is regular at every point, then it is a regular map. In the affine case, in Lemma \ref{lem:rationalregular}, we had to work to prove that if a rational map is regular at every point, then there is a single polynomial expression which defines the map everywhere. In the quasi-projective case, we do not need to do this because our definition of regular map allows different expressions at different points.

\begin{example*}
Let $ C $ denote the affine algebraic set
$$ C = \cbr{\br{x, y} \in \AA^2 \st y = x^3}. $$
This has projective closure
$$ \overline{C} = \cbr{\sbr{w : x : y} \in \PP^2 \st w^2y = x^3} = C \cup \cbr{\sbr{0 : 0 : 1}}. $$
Consider the regular map of affine algebraic sets given by
$$ \function[\phi]{C}{\AA^1}{\br{x, y}}{x}. $$
If we try to extend this to a map of projective algebraic sets $ \overline{\phi} : \overline{C} \to \PP^1 $, we would say that for points $ \sbr{1 : x : y} \in C \subseteq \overline{C} $,
$$ \function[\phi]{C}{\AA^1}{\br{\sbr{1 : x : y}}}{\sbr{1 : x}}, $$
and this homogenises to
$$ \rational[\overline{\phi}]{\overline{C}}{\PP^1}{\br{\sbr{w : x : y}}}{\sbr{w : x}}. $$
Thus $ \overline{\phi} $ is a rational map $ \overline{C} \dashrightarrow \PP^1 $. The above expression for $ \overline{\phi} $ is not defined at the point $ \sbr{0 : 0 : 1} \in \overline{C} $. We can prove that there is no other expression for $ \overline{\phi} $ which is defined at that point, and so $ \overline{\phi} $ is not regular at $ \sbr{0 : 0 : 1} $. See problem sheet $ 3 $, question $ 3 $.
\end{example*}

Thus a regular map of affine algebraic sets extends to a rational map between their projective closures, but the extended map is not necessarily regular at the points at infinity.

\pagebreak

\subsubsection{Birational maps}

Just as in the affine case, if we have irreducible quasi-projective sets $ V, W, T $ and rational maps $ \phi : V \dashrightarrow W $ and $ \psi : W \dashrightarrow T $, if the image of $ \phi $ is dense in $ W $, then the composite $ \psi \circ \phi $ is a rational map $ V \dashrightarrow T $. The following definitions are the same as the affine case.

\begin{definition*}
A rational map $ \phi : V \dashrightarrow W $ is \textbf{dominant} if its image is dense in $ W $. A rational map $ \phi : V \dashrightarrow W $ is a \textbf{birational equivalence} if it is dominant and there exists a dominant rational map $ \psi : W \dashrightarrow V $ such that $ \psi \circ \phi = \id_V $ and $ \phi \circ \psi = \id_W $, where these composite rational maps are defined. Irreducible algebraic sets $ V $ and $ W $ are \textbf{birational} if there exists a birational equivalence $ V \dashrightarrow W $.
\end{definition*}

\begin{note*}
$ \AA^n $ is birational to $ \PP^n $. Consider the regular map
$$ \function[\phi]{\AA^n}{\PP^n}{\br{x_1, \dots, x_n}}{\sbr{1 : x_1 : \dots : x_n}}, $$
and the rational map
$$ \rational[\psi]{\PP^n}{\AA^n}{\sbr{x_0 : \dots : x_n}}{\br{\dfrac{x_1}{x_0}, \dots, \dfrac{x_n}{x_0}}}. $$
Each of these is dominant and composing them in either direction gives the identity, so these are birational equivalences. Observe that $ \phi $ is an isomorphism from $ \AA^n $ to an open subset of $ \PP^n $.
\end{note*}

We can generalise this to show that if $ V $ is any irreducible quasi-projective variety and $ U $ is a Zariski open subset of $ V $, thus $ U $ is also an irreducible quasi-projective variety, then $ U $ is birational to $ V $. Indeed, this is a corollary of the following stronger result, which makes precise the intuition that varieties are birational if and only if they are the same almost everywhere.

\begin{note*}
We need the concept of quasi-projective varieties to state this lemma, even if $ V $ and $ W $ are both affine or both projective, because it is necessary to interpret the statement that $ A $ and $ B $ are isomorphic.
\end{note*}

\begin{lemma}
Irreducible quasi-projective varieties $ V $ and $ W $ are birational if and only if there exist non-empty Zariski open subsets $ A \subseteq V $ and $ B \subseteq W $ such that $ A $ is isomorphic to $ B $, as quasi-projective varieties.
\end{lemma}

\begin{proof}
Let $ \phi : V \dashrightarrow W $ and $ \psi : W \dashrightarrow V $ be an inverse pair of rational maps. Let $ A_1 = \dom \phi $ and $ B_1 = \dom \psi $. Then $ B_1 $ is a non-empty open subset of $ W $. Since $ \phi $ induces a continuous map $ A_1 \to W $, $ A = \eval{\phi}_{A_1}^{-1}\br{B_1} $ is an open subset of $ V $. Furthermore, since $ \phi $ is dominant, its image intersects the open set $ B_1 \subseteq W $. Therefore $ A $ is non-empty. Similarly $ B = \eval{\psi}_{B_1}^{-1}\br{A_1} $ is a non-empty open subset of $ W $. One can now check that $ \eval{\phi}_A $ and $ \eval{\psi}_B $ form an inverse pair of isomorphisms between $ A $ and $ B $.
\end{proof}

If $ V $ is a quasi-projective algebraic set, we define a \textbf{rational function} on $ V $ to be a rational map $ \phi : V \dashrightarrow \AA^1 $. By definition, this is the same as a rational map $ \phi' : V \dashrightarrow \PP^1 $ except that we declare $ \phi $ to be non-regular at points where $ \phi'\br{x} = \infty = \sbr{0 : 1} \in \PP^1 $. We can therefore say
$$ \phi\br{x} = \sbr{f\br{x} : g\br{x}} = \sbr{1 : \dfrac{g\br{x}}{f\br{x}}} = \dfrac{g\br{x}}{f\br{x}} \in \AA^1, $$
whenever $ f\br{x} \ne 0 $, for suitable polynomials $ f $ and $ g $. Of course, as always with rational maps, we might need to use different polynomials to evaluate it at different points. The rational functions on $ V $ form a field $ k\br{V} $. Just as in the affine case, $ V $ is birational to $ W $ if and only if $ k\br{V} $ is $ k $-isomorphic to $ k\br{W} $. This allows us to calculate
$$ k\br{\PP^n} = k\br{\AA^n} = k\br{X_1, \dots, X_n}. $$

\pagebreak

\subsection{Rigidity and images of maps}

\subsubsection{Linear spaces in projective space}

We want to define a fundamental example of a rational map, the projection from a point to a hyperplane. First, we need to make a few other definitions.

\begin{definition*}
A \textbf{hyperplane} in $ \PP^n $ is the projective algebraic set defined by a single homogeneous linear equation,
$$ H = \cbr{\sbr{x_0 : \dots : x_n} \in \PP^n \st h_0x_0 + \dots + h_nx_n = 0}, $$
for some $ h_0, \dots, h_n \in k $, not all zero. More generally, a \textbf{linear subspace} of $ \PP^n $ is a subset defined by any set of homogeneous linear equations.
\end{definition*}

\begin{example*}
Examples of linear subspaces are $ \PP^n $ itself with the empty set of equations, $ \emptyset $ with too many equations, and singletons. We cannot define the singleton $ \cbr{\sbr{p_0 : \dots : p_n}} $ by the equations $ x_0 = p_0, \dots, x_n = p_n $ because these are not homogeneous. Instead, we can write homogeneous equations asserting that the ratios between pairs of coordinates are correct, so
$$ \cbr{\sbr{p_0 : \dots : p_n}} = \cbr{\sbr{x_0 : \dots : x_n} \in \PP^n \st \forall i, j, \ p_ix_j = p_jx_i}. $$
\end{example*}

If $ \Lambda $ is a linear subspace of $ \PP^n $, then the affine cone $ \C\br{\Lambda} $, the set of points in $ \AA^{n + 1} $ satisfying the same equations as $ \Lambda $, is a vector subspace of $ k^{n + 1} $. As a vector space, we know what is meant by $ \dim \C\br{\Lambda} $. We define
$$ \dim \Lambda = \dim \C\br{\Lambda} - 1. $$
We have not yet defined the dimension of an arbitrary algebraic set. This definition is only for linear subspaces of projective space. The $ -1 $ is because $ \C\br{\Lambda} $ contains a line for each point in $ \Lambda $.

\begin{example*}
$ \PP^n $ has dimension $ n $, a hyperplane has dimension $ n - 1 $, and a point has dimension zero.
\end{example*}

If $ \Lambda $ is a linear subspace of $ \PP^n $ of dimension $ d $, then $ \C\br{\Lambda} \cong k^{d + 1} $, as a vector space, and $ \Lambda = \br{\C\br{\Lambda} \setminus \cbr{0}} $ modulo multiplying by scalars, so $ \Lambda \cong \PP^d $.

\begin{definition*}
A \textbf{line} in $ \PP^n $ is a linear subspace of dimension one.
\end{definition*}

\lecture{18}{Friday}{21/02/20}

\begin{lemma}
For any two distinct points $ p, q \in \PP^n $, there exists a unique line $ \L_{pq} $ through $ p $ and $ q $.
\end{lemma}

One could prove this by saying, $ \PP^n $ can be written as a union $ \AA^n \cup \PP^{n - 1} $, and going through the cases $ p, q \in \AA^n $, $ p, q \in \PP^{n - 1} $, and $ p \in \AA^n $ and $ q \in \PP^{n - 1} $. In order to make this into a full proof, we would need to check that a line in $ \PP^n $, intersected with $ \AA^n $, is the same as the ordinary definition of a line in $ \AA^n $, which is true. Instead we shall give a proof using linear algebra. A benefit of this proof is that it gives a description of the homogeneous coordinates of points in the line $ \L_{pq} $.

\begin{proof}
Let $ p = \sbr{p_0 : \dots : p_n} $ and $ q = \sbr{q_0 : \dots : q_n} $. The affine cones $ \C\br{p} $ and $ \C\br{q} $ are the one-dimensional vector spaces of generated by $ \br{p_0, \dots, p_n} $ and $ \br{q_0, \dots, q_n} $ respectively. Since $ p \ne q $, these vector spaces are linearly independent so there is a unique two-dimensional vector subspace $ W \subseteq k^{n + 1} $ which contains $ \C\br{p} $ and $ \C\br{q} $. The image of $ W \setminus \cbr{0} $ in $ \PP^n $ is the unique line through $ p $ and $ q $. Explicitly, $ W $ consists of all linear combinations of the vectors $ \br{p_0, \dots, p_n} $ and $ \br{q_0, \dots, q_n} $. It follows that
$$ \L_{pq} = \cbr{\sbr{p_0s + q_0t : \dots : p_ns + q_nt} \in \PP^n \st \sbr{s : t} \in \PP^1}. $$
\end{proof}

\subsubsection{Projections of projective algebraic sets}

A fundamental example of a rational map is the projection from a point to a hyperplane. Let $ p = \sbr{p_0 : \dots : p_n} \in \PP^n $ and let $ H \subseteq \PP^n $ be a hyperplane such that $ p \notin H $. To simplify the calculations, we shall assume that
$$ H = \cbr{\sbr{x_0 : \dots : x_n} \in \PP^n \st x_n = 0}. $$

\pagebreak

Any line in $ \PP^n $ which is not contained in $ H $ meets $ H $ in exactly one point. This is geometrically clear. One can prove it algebraically via linear algebra using the affine cones, or by the following calculation. Let $ x \in \PP^n \setminus \cbr{p} $. Then
$$ \L_{px} = \cbr{\sbr{p_0s + x_0t : \dots : p_ns + x_nt} \in \PP^n \st \sbr{s : t} \in \PP^1}. $$
Hence, to find $ \L_{px} \cap H $, we need to choose $ \sbr{s : t} $ such that $ p_ns + x_nt = 0 $. We can choose $ \sbr{s : t} = \sbr{x_n : -p_n} $, noting that $ p_n \ne 0 $ because $ p \notin H $, so we do not get $ \sbr{0 : 0} $. Substituting in to $ \L_{px} $, the unique point of $ \L_{px} \cap H $ is
$$ \sbr{p_0x_n - x_0p_n : \dots : p_{n - 1}x_n - x_{n - 1}p_n : 0}. $$
The final $ 0 = p_nx_n - x_np_n $ is what we expect for a point in $ H $.

\begin{note*}
If $ p \ne x $, then this is not $ \sbr{0 : \dots : 0} $ so it is well-defined.
\end{note*}

Thus, for $ x \in \PP^n \setminus \cbr{p} $, it makes sense to define $ \pi\br{x} $ to be the unique point of $ \L_{px} \cap H $. The above calculation shows that $ \pi $ is a rational map $ \PP^n \dashrightarrow H $, regular on $ \PP^n \setminus \cbr{p} $. We show below that $ \pi $ is not regular at $ p $. This rational map is called the \textbf{projection from $ p $ to $ H $}. One could replace this particular fixed $ H $ by any hyperplane not containing $ p $, and carry out the same recipe.

\begin{lemma}
Let $ n \ge 2 $. The projection of $ \PP^n $ from $ p $ to $ H $ is not regular at $ p $.
\end{lemma}

Intuitively, there are many lines passing through $ p $ and $ p $, so the projection would have to map $ p $ to everywhere at once. We can make this rigorous.

\begin{proof}
Pick a point $ s \in H $ and consider the line $ \L_{ps} $. For any $ x \in \L_{ps} \setminus \cbr{p} $, the geometric description of $ \pi $ shows that $ \pi\br{x} = s $. If we assume that $ \pi $ is regular at $ p $, then it restricts to a regular map $ \L_{ps} \to H $. We have just shown that this map is constant on $ \L_{ps} \setminus \cbr{p} $ and therefore it is constant on $ \L_{ps} $. Hence $ \pi\br{p} = s $. We could pick another point $ t \in H $ and repeat exactly the same argument using $ \L_{pt} $, so that $ \pi\br{p} = t $. This is a contradiction.
\end{proof}

The condition $ n \ge 2 $ is needed to ensure that $ H \cong \PP^{n - 1} $ has two distinct points $ s $ and $ t $. If $ n = 1 $, then $ H $ is just a point and $ \pi $ is a constant map, so it is regular everywhere.

\subsubsection{Products of projective algebraic sets}

Many sets that we want to work with, for example, the graph of a regular map $ V \to W $, are naturally defined as subsets of products $ V \times W $ of algebraic sets. Therefore we would like to be able to say that the product of algebraic sets are also algebraic sets. We saw that this is easy for affine algebraic sets, since $ V \times W $ is an affine algebraic subset of $ \AA^{m + n} $. The key point here is the isomorphism $ \AA^m \times \AA^n \cong \AA^{m + n} $. For projective algebraic sets, it is harder to define products because $ \PP^m \times \PP^n \not\cong \PP^{m + n} $.

\begin{example*}
To see informally why $ \PP^1 \times \PP^1 \not\cong \PP^2 $, recall that $ \PP^1 = \AA^1 \cup \cbr{\text{point}} $ so
$$ \PP^1 \times \PP^1 = \br{\AA^1 \times \AA^1} \cup \br{\AA^1 \times \cbr{\text{point}}} \cup \br{\cbr{\text{point}} \times \AA^1} \cup \br{\text{point} \times \cbr{\text{point}}} = \AA^2 \cup \AA^1 \cup \AA^1 \cup \cbr{\text{point}}. $$
Meanwhile $ \PP^2 = \AA^2 \cup \PP^1 = \AA^2 \cup \AA^1 \cup \cbr{\text{point}} $. Thus $ \PP^1 \times \PP^1 $ contains an extra copy of $ \AA^1 $ compared to $ \PP^2 $. This is only an informal argument. A rigorous proof will be on problem sheet $ 4 $.
\end{example*}

We could try giving an ad hoc definition for $ \PP^m \times \PP^n $ by hand. It is fairly clear what algebraic subsets of $ \PP^m \times \PP^n $, sets defined by polynomials in the two sets of homogeneous coordinates $ \sbr{x_0 : \dots : x_m} $ and $ \sbr{y_0 : \dots : y_n} $, should mean. In order for the zero set of such a polynomial to be well-defined, it must be \textbf{bihomogeneous}, that is homogeneous in the $ x $ variables and homogeneous in the $ y $ variables, but the $ x $ and $ y $ degrees can potentially be different. Similarly, we could give a definition of regular maps between subvarieties of $ \PP^m \times \PP^n $ involving bihomogeneous polynomials. But it would be annoying to have just defined quasi-projective varieties, unifying affine and projective varieties, and then immediately have to introduce ad hoc definitions for another different kind of variety. So we aim to construct the product in a way which makes it a quasi-projective set, and then we can just reuse the definitions from before. Furthermore, projective varieties have special properties of their own. In particular, we will prove that the image of a projective variety under a regular map is always closed. By showing that the product of projective varieties is itself a projective variety, we will be able to apply these properties to products too.

\pagebreak

\subsubsection{The Segre embedding}

To construct the product $ \PP^m \times \PP^n $ as a projective algebraic set, we will embed it inside some larger $ \PP^N $. The homogeneous coordinates of a point in $ \PP^m \times \PP^n $ will be given by an $ \br{m + 1} \times \br{n + 1} $ matrix, so we need
$$ N = \br{m + 1}\br{n + 1} - 1 = mn + m + n. $$
Thus the number of homogeneous coordinates needed to specify a point in $ \PP^N $ is $ \br{m + 1}\br{n + 1} $. We will arrange the homogeneous coordinates of points in $ \PP^N $ as if they were entries of a matrix. Thus we label them as
$$ \sbr{\br{z_{ij} \st 0 \le i \le m, \ 0 \le j \le n}}, $$
rather than the usual $ \sbr{z_0 : \dots : z_N} $. Define a map given by
$$ \function[\sigma_{m, n}]{\PP^m \times \PP^n}{\PP^N}{\br{\sbr{x_0 : \dots : x_m}, \sbr{y_0 : \dots : y_n}}}{\sbr{\br{z_{ij} = x_iy_j \st 0 \le i \le m, \ 0 \le j \le n}}}. $$
Another way to describe this is to say that the homogeneous coordinates of $ \sigma_{m, n}\br{\sbr{x_0 : \dots : x_m}, \sbr{y_0 : \dots : y_n}} $ are given by the product matrix
$$ \br{z_{ij}} = \threebyone{x_0}{\vdots}{x_m}\onebythree{y_0}{\dots}{y_n}. $$
Observe that this matrix has rank one. Let
$$ \Sigma_{m, n} = \cbr{\sbr{z_{00} : \dots : z_{mn}} \in \PP^N \st \rk \br{z_{ij}} = 1}. $$
Some linear algebra shows that we can describe $ \Sigma_{m, n} $ as the subset of $ \PP^N $ where all $ 2 \times 2 $ submatrices of the matrix $ \br{z_{ij}} $ have zero determinant. Thus $ \Sigma_{m, n} $ is a projective algebraic set, defined by the equations
$$ z_{ij}z_{kl} = z_{kj}z_{il}, \qquad 0 \le i, k \le m, \qquad 0 \le j, l \le n. $$

\begin{lemma}
$ \sigma_{m, n} $ is a bijection from $ \PP^m \times \PP^n $ to $ \Sigma_{m, n} $.
\end{lemma}

This proof is not part of the course.

\begin{proof}
We can define an inverse to $ \sigma_{m, n} $ as follows. Let $ a \in \Sigma_{m, n} $, and let $ A $ be a matrix giving homogeneous coordinates for $ a $. Then $ A $ is not the zero matrix, because it is a set of homogeneous coordinates, so we can pick $ j $ such that the $ j $-th column of $ A $ contains a non-zero entry. Define $ \pi_1\br{a} \in \PP^m $ to be the point with homogeneous coordinates given by the $ j $-th column of $ A $, that is $ \pi_1\br{a} = \sbr{A_{1j} : \dots : A_{mj}} $. This is independent of the choice of $ j $ because the matrix has rank one, since every non-zero column is a multiple of every other non-zero column. Similarly we can pick $ i $ such that the $ i $-th row of $ A $ contains a non-zero entry, and define $ \pi_2\br{a} \in \PP^n $ to be the point with homogeneous coordinates given by the $ i $-th row of $ A $. Again this is independent of the choice of $ i $. Now $ \br{\pi_1, \pi_2} : \Sigma_{m, n} \to \PP^m \times \PP^n $ is an inverse to $ \sigma_{m, n} $.
\end{proof}

This construction shows that the projections $ \pi_1 : \Sigma_{m, n} \to \PP^m $ and $ \pi_2 : \Sigma_{m, n} \to \PP^n $ are regular maps, since each column of the matrix is non-zero on a Zariski open subset of $ \Sigma_{m, n} $. The map $ \sigma_{m, n} : \PP^m \times \PP^n \to \PP^N $ is called the \textbf{Segre embedding} and its image $ \Sigma_{m, n} \subseteq \PP^N $ is called the \textbf{Segre variety}.

\lecture{19}{Monday}{24/02/20}

\begin{example*}
When $ m = n = 1 $, $ N = 3 $. The Segre variety $ \Sigma_{m, n} \subseteq \PP^3 $ is defined by the single equation
$$ \det \twobytwo{z_{00}}{z_{01}}{z_{10}}{z_{11}} = z_{00}z_{11} - z_{10}z_{01} = 0. $$
The Segre embedding is given by
$$ \sigma_{m, n}\br{\sbr{x_1 : x_2}, \sbr{y_1 : y_2}} = \sbr{x_1y_1 : x_1y_2 : x_2y_1 : x_2y_2}. $$
We see that $ \Sigma_{m, n} $ is an irreducible quadric hypersurface in $ \PP^3 $. Therefore by problem sheet $ 3 $, question $ 4 $, it is birational to $ \PP^2 $ and $ \AA^2 $. This is not surprising, because of course $ \PP^1 \times \PP^1 $ should have an open subset isomorphic to $ \AA^1 \times \AA^1 \cong \AA^2 $, which in turn is an open subset of $ \PP^2 $. We gave an informal argument earlier that $ \PP^1 \times \PP^1 $ should not be isomorphic to $ \PP^2 $. A rigorous proof of this will be on the next problem sheet.
\end{example*}

\pagebreak

Because $ \Sigma_{m, n} $ is a projective algebraic set, it has a subspace topology induced by the Zariski topology on $ \PP^N $ and so we get a Zariski topology on $ \PP^m \times \PP^n $. One can check that this topology is the same as what we expect, namely the following.

\begin{lemma}
Let $ V \subseteq \PP^m \times \PP^n $. Then $ \sigma_{m, n}\br{V} \subseteq \Sigma_{m, n} $ is closed if and only if
$$ V = \cbr{\br{\sbr{x_0 : \dots : x_m}, \sbr{y_0 : \dots : y_n}} \st \forall 1 \le i \le s, \ f_i\br{x_0, \dots, x_m, y_0, \dots, y_n} = 0}, $$
where $ f_1, \dots, f_s \in k\sbr{X_0, \dots, X_m, Y_0, \dots, Y_n} $ are bihomogeneous polynomials.
\end{lemma}

We say that a polynomial $ f \in k\sbr{X_0, \dots, X_m, Y_0, \dots, Y_n} $ is \textbf{bihomogeneous of degree $ \br{d, e} $} if every term of $ f $ has degree $ d $ with respect to the $ X $ variables and degree $ e $ with respect to the $ Y $ variables.

\begin{proof}
Suppose that $ \sigma_{m, n}\br{V} $ is Zariski closed in $ \PP^N $. Then it is defined by some homogeneous polynomials $ g_r\br{z_{00}, \dots, z_{mn}} $. Making the substitutions $ z_{ij} = x_iy_j $, as in the definition of $ \sigma_{m, n} $, we get a finite set of polynomials which define $ V $. If $ g_r $ is homogeneous in $ z_{ij} $ of degree $ d_r $, then $ g_r \circ \sigma_{m, n} $ is bihomogeneous of degree $ \br{d_r, d_r} $. It is easy to see that if $ V $ is defined by polynomials $ f_r $, where $ f_r $ is bihomogeneous of degree $ \br{d_r, d_r} $, then we can reverse this process to get homogeneous polynomials in $ z_{ij} $ which define $ \sigma_{m, n}\br{V} $. But what if the defining polynomials for $ V $ include some $ f $ which is bihomogeneous of degree $ \br{d, e} $, where $ d \ne e $? Without loss of generality, suppose that $ d > e $. Then $ f = 0 $ is equivalent to the system of equations
$$ x_0^{d - e}f = 0, \qquad \dots, \qquad x_m^{d - e}f = 0, $$
and these equations are bihomogeneous of degree $ \br{d, d} $.
\end{proof}

\subsubsection{Graphs of regular functions}

If $ V \subseteq \PP^m $ and $ W \subseteq \PP^n $ are projective algebraic sets, then their product $ V \times W \subseteq \PP^m \times \PP^n $ is a Zariski closed subset of $ \PP^m \times \PP^n $, since the homogeneous polynomials defining $ V $ become bihomogeneous polynomials of degree $ \br{d, 0} $ while those defining $ W $ become bihomogeneous polynomials of degree $ \br{0, e} $, and therefore $ V \times W $ is itself a projective variety. Similarly, if $ V \subseteq \PP^m $ and $ W \subseteq \PP^n $ are quasi-projective algebraic sets, then the product $ V \times W $ is also quasi-projective, since it is the intersection of an open subset and a closed subset in $ \PP^m \times \PP^n $, and therefore in $ \PP^N $ via the Segre embedding.

\begin{example*}
One useful example of a subvariety of a product is the graph of a regular function. Let $ V \subseteq \PP^n $ and $ W \subseteq \PP^m $ be quasi-projective algebraic sets, and let $ \phi : V \to W $ be a regular map. The \textbf{graph} of $ \phi $ is
$$ \Gamma = \cbr{\br{x, y} \in V \times W \st y = \phi\br{x}}. $$
To check that this is closed in $ V \times W $, observe that $ \Gamma $ is the preimage of the diagonal $ \Delta \subseteq \PP^m \times \PP^m $ under the regular map
$$ \br{\iota \circ \phi, \iota} : V \times W \to \PP^m \times \PP^m, $$
where $ \iota $ denotes the inclusion map $ W \to \PP^m $. Since $ \br{\iota \circ \phi, \iota} $ is a regular map, it is continuous. Therefore it suffices to check that the diagonal is a Zariski closed subset of $ \PP^m \times \PP^m $. This is true because we can describe the diagonal by bihomogeneous equations as
$$ \Delta = \cbr{\br{\sbr{x_0 : \dots : x_m}, \sbr{y_0 : \dots : y_m}} \st \forall i, j, \ x_iy_j = x_jy_i}. $$
\end{example*}

\subsubsection{Images of projective varieties}

The following is a key property of projective algebraic varieties, which is analogous to compactness for Hausdorff topological spaces.

\begin{theorem}
\label{thm:imageclosed}
Let $ V $ be a projective variety. Let $ \phi : V \to W $ be a regular map into any quasi-projective variety. Then the image of $ \phi $ is Zariski closed.
\end{theorem}

Clearly Theorem \ref{thm:imageclosed} is false if $ V $ is not projective.

\begin{example*}
Consider the projection of the hyperbola $ \cbr{\br{x, y} \st xy = 1} $ onto one of the axes.
\end{example*}

\pagebreak

Theorem \ref{thm:imageclosed} shows that projective varieties are similar to compact spaces in topology, since if $ S $ is a compact topological space and $ T $ is a Hausdorff topological space, then the image of any continuous map $ S \to T $ is closed. By applying Theorem \ref{thm:imageclosed} to $ \iota \circ \phi $, where $ \iota $ is an embedding $ W \to \PP^m $, we see that the image of a projective variety under a regular map is again a projective variety. Before proving Theorem \ref{thm:imageclosed}, we shall state some important corollaries.

\begin{corollary}
\label{cor:regularconstant}
Every regular function on an irreducible projective variety is constant.
\end{corollary}

\begin{proof}
Let $ V $ be an irreducible projective variety and $ \phi : V \to \AA^1 $ a regular function. Let $ \iota : \AA^1 \to \PP^1 $ be the natural inclusion. Then $ \iota \circ \phi : V \to \PP^1 $ is a regular map, so by Theorem \ref{thm:imageclosed}, its image is a closed subset of $ \PP^1 $. But the image of $ \iota \circ \phi $ is contained in $ \AA^1 $, so it cannot be all of $ \PP^1 $. Therefore the image of $ \phi $ is finite. Since $ V $ is irreducible, its image is also irreducible and therefore consists of a single point.
\end{proof}

Thus projective algebraic sets are essentially opposite to affine ones, since an affine algebraic set is determined by its ring of regular functions while a projective algebraic set has no regular functions except constants.

\begin{corollary}
\label{cor:regularpoint}
The image of a regular map from an irreducible projective variety to an affine variety is a point.
\end{corollary}

\begin{proof}
Suppose we have a regular map $ \phi : V \to W $, where $ V $ is projective and irreducible and $ W $ is affine. We can suppose that $ W \subseteq \AA^m $, and let $ X_1, \dots, X_m $ denote the coordinate functions on $ W $. Then $ X_1 \circ \phi, \dots, X_m \circ \phi $ are all constant by Corollary \ref{cor:regularconstant}, and so $ \phi $ is constant.
\end{proof}

\begin{lemma}
\label{lem:hypersurfaceintersection}
Let $ V \subseteq \PP^n $ be an infinite projective algebraic set and let $ H \subseteq \PP^n $ be a hyperplane. Then the intersection $ V \cap H $ is non-empty.
\end{lemma}

We use the following fact. This fact is proved for $ \PP^2 $ on problem sheet $ 3 $ using the Veronese embedding, and the proof generalises to arbitrary $ \PP^n $.

\begin{fact*}
If $ H \subseteq \PP^n $ is a hypersurface, then the complement $ \PP^n \setminus H $ is isomorphic to an affine algebraic set.
\end{fact*}

\begin{proof}
Suppose for contradiction that Lemma \ref{lem:hypersurfaceintersection} were false, then $ V \cap H = \emptyset $. Then $ V \subseteq \PP^n \setminus H $, which is isomorphic to an affine algebraic set $ \AA^n $ for some $ n $. Hence we get an injective regular map $ \iota : V \to \AA^n $. Pick an infinite irreducible component $ V_1 \subseteq V $. Then $ V_1 $ is a projective algebraic set so, by Corollary \ref{cor:regularpoint}, $ \iota $ is constant on $ V_1 $, and since $ \iota $ is injective, $ V_1 $ maps to a point. But $ V $ has only finitely many irreducible components, so this contradicts the hypothesis that $ V $ is infinite.
\end{proof}

\subsubsection{Completeness of varieties}

To prove Theorem \ref{thm:imageclosed}, we will use the graph $ \Gamma \subseteq V \times W $ of $ \phi $. The image of $ \phi $ is the same as the projection of $ \Gamma $ onto $ W $. Hence Theorem \ref{thm:imageclosed} can be deduced from the following theorem, which will be a more convenient statement to prove.

\begin{theorem}
\label{thm:projectionclosed}
Let $ V $ be a projective variety. For any quasi-projective variety $ W $, the second projection map $ \pi_2 : V \times W \to W $ maps closed sets to closed sets.
\end{theorem}

Again, we can see that Theorem \ref{thm:projectionclosed} does not apply when $ V $ is not projective by taking $ V = W = \AA^1 $ and taking the hyperbola as a closed subset of $ V \times W $. At first sight, Theorem \ref{thm:projectionclosed} looks stronger than Theorem \ref{thm:imageclosed} because it applies to all closed subsets of $ V \times W $, not just the graphs $ \Gamma $ of regular maps $ \phi : V \to W $, using that $ \Im \phi = \pi_2\br{\Gamma} $. In fact it is easy to deduce Theorem \ref{thm:projectionclosed} from Theorem \ref{thm:imageclosed}, by applying it to $ \pi_2 \circ \iota : Z \to W $ where $ \iota $ is the inclusion map $ Z \to V \times W $ for any closed subset $ Z \subseteq V \times W $.

\begin{definition*}
A variety $ V $ is \textbf{complete} if it satisfies the conclusion of Theorem \ref{thm:projectionclosed}. In other words, for every quasi-projective variety $ W $, the second projection $ \pi_2 : V \times W \to W $ maps closed sets to closed sets.
\end{definition*}

For quasi-projective varieties, complete is equivalent to projective, but if we go beyond the world of quasi-projective varieties, and we have not defined non-quasi-projective varieties at all in this course, then it is possible to find algebraic varieties which are complete but not projective. Completeness is the natural analogue in algebraic geometry for compactness in topology. This is justified by the following result from topology.

\begin{lemma}
\label{lem:projectionclosed}
Let $ S $ be a topological space. Then $ S $ is compact if and only if, for every topological space $ T $, the second projection map $ S \times T \to T $ maps closed sets to closed sets.
\end{lemma}

\pagebreak

\begin{note*}
In Lemma \ref{lem:projectionclosed}, we use closed sets for the product topology on $ S \times T $, while in Theorem \ref{thm:projectionclosed} we use closed sets for the Zariski topology on $ V \times W $, coming from the Segre embedding. These are not the same thing, since we have seen, in the case $ \AA^1 \times \AA^1 $, that the Zariski topology on a product has more closed sets than the product topology.
\end{note*}

We remark that, over the complex numbers, an algebraic variety is complete if and only if it is compact for the analytic topology. This is hard to prove.

\subsubsection{Images of quasi-projective varieties}

Completeness tells us that images of regular maps of projective algebraic sets are closed. We know that this is false for affine algebraic sets, by considering our favourite example of the hyperbola and its projection to $ \AA^1 $. So what can we say about the images of regular maps of affine, or more generally quasi-projective algebraic sets? We might speculate that they would always be quasi-projective, that is the intersection of an open and a closed set. But this is not true either. Consider the regular map given by
$$ \function[\phi]{\AA^2}{\AA^2}{\br{x, y}}{\br{x, xy}}. $$
The image of $ \phi $ is $ \cbr{\br{x, y} \st x \ne 0} \cup \cbr{\br{0, 0}} $. This is the union of an open set with a closed set, not their intersection. It turns out that this is more or less as bad as things can get.

\begin{definition*}
Let $ S $ be any topological space. A \textbf{locally closed} subset of $ S $ is the intersection between an open and a closed set. A \textbf{constructible} subset of $ S $ is a finite union of locally closed sets.
\end{definition*}

\begin{example*}
Quasi-projective algebraic sets are locally closed subsets of $ \PP^n $.
\end{example*}

Equivalently, a constructible set is any set which can be obtained by starting with a finite list of open and closed sets, and combining them in any way using unions and intersections. The image of the map $ \br{x, y} \mapsto \br{x, xy} $ considered above is the typical example to keep in mind for a constructible set which is not locally closed. Chevalley's theorem tells us that the image of a regular map between quasi-projective varieties is constructible. Indeed it tells us slightly more. The image of a constructible set is constructible.

\begin{theorem}[Chevalley's theorem]
Let $ \phi : V \to W $ be a regular map of quasi-projective algebraic sets. The image of any constructible set in $ V $ is a constructible set in $ W $.
\end{theorem}

We will prove completeness of projective varieties and Chevalley's theorem in the next lecture. Their proofs are linked but neither theorem is an easy consequence of the other.

\subsubsection{Chevalley's theorem and mathematical logic}

This is not a formal part of the course, so I will not define things carefully. For anyone with an interest in mathematical logic, we remark on a logical interpretation of Chevalley's theorem. In logic, we consider formulas made out of some algebraic operations. In the context of algebraic geometry, these will be polynomial equations over an algebraically closed field, and combine these using logical operations, $ \land, \lor, \lnot, \exists, \forall $.

\begin{example*}
A logical formula might look like $ \br{\lnot\br{xy = z}} \land \exists\br{u, v}\br{\br{x = u^2} \land \br{y = uv} \land \br{z = v^2}} $.
\end{example*}

If we allow just $ \land, \lor, \lnot $ then formulas like this define unions and intersections of Zariski open and closed sets in $ \AA^n $, that is constructible sets. If we also allow quantifiers, then we can also get images of regular maps.

\begin{example*}
The part of the formula above starting with $ \exists\br{u, v} $ defines the image of the regular map $ \br{u, v} \mapsto \br{u^2, uv, v^2} $.
\end{example*}

But Chevalley's theorem tells us that images of regular maps are actually also constructible sets, so we deduce the following.

\begin{fact*}
Every formula, made out of polynomials over an algebraically closed field, is equivalent to a formula without quantifiers.
\end{fact*}

This is called \textbf{elimination of quantifiers for algebraically closed fields}.

\pagebreak

\subsubsection{Affine open covers}

\lecture{20}{Thursday}{27/02/20}

By definition, every quasi-projective algebraic set is contained in a projective algebraic set. We can use this to reduce some proofs for quasi-projective algebraic sets to the projective case, proving from the outside in. On the other hand, it is often useful to know that we can find affine varieties as open sets inside each quasi-projective algebraic set. This can be used to reduce some proofs to the affine case, proving from the inside out.

\begin{lemma}
\label{lem:quasiprojectiveaffine}
Let $ V $ be a quasi-projective variety. For every point $ x \in V $, there exists an open set $ U \subseteq V $ which contains $ x $ and is isomorphic to an affine variety.
\end{lemma}

\begin{proof}
Write $ V = V_0 \cap U_0 $ where $ V_0 \subseteq \PP^n $ is closed and $ U_0 \subseteq \PP^n $ is open. Given a point $ x \in V $, we may assume that $ x $ is in $ \AA^n \subseteq \PP^n $, embedded by setting $ X_0 = 1 $. We can achieve this by changing the coordinate system if necessary. Since $ \PP^n \setminus U_0 $ is a projective algebraic set which does not contain $ x $, there is some homogeneous polynomial $ f $ which vanishes on $ \PP^n \setminus U_0 $ but not at $ x $. Then $ x $ is contained in the set $ U_0 = V_0 \cap D\br{f} = V \cap D\br{f} $, where
$$ D\br{f} = \cbr{\br{y_1, \dots, y_n} \in \AA^n \st f\br{1, y_1, \dots, y_n} \ne 0}. $$
We have $ V_0 \cap D\br{f} = V \cap D\br{f} $ because $ D\br{f} \subseteq U_0 $. Then $ U $ is an open subset of $ V $ because $ D\br{f} $ is an open subset of $ \PP^n $, and $ U $ is a closed subset of $ D\br{f} $, so in order to show that $ U $ is an affine variety, it suffices to show that $ D\br{f} $ is an affine variety. We can prove this using the hyperbola trick. Consider the set
$$ E\br{f} = \cbr{\br{y_1, \dots, y_n, z} \in \AA^{n + 1} \st zf\br{1, y_1, \dots, y_n} = 1}. $$
Then $ E\br{f} $ is an affine algebraic set in $ \AA^{n + 1} $, and projection onto the first $ n $ coordinates gives an isomorphism between $ E\br{f} $ and $ D\br{f} $.
\end{proof}

\subsubsection{Proof of completeness}

We will now prove the completeness of projective varieties, in the form of Theorem \ref{thm:projectionclosed}. Let $ Z $ be a closed subset of $ V \times W $. By Lemma \ref{lem:quasiprojectiveaffine}, we may cover $ W $ by open sets $ U_\alpha $ such that each $ U_\alpha $ is an affine variety. According to the topological fact from the proof of Lemma \ref{lem:projectivedense}, in order to show that $ \pi_2\br{Z} $ is closed in $ W $, it suffices to show that $ \pi_2\br{Z} \cap U_\alpha $ is closed in $ U_\alpha $ for every $ \alpha $. In other words, since $ \pi_2\br{Z} \cap U_\alpha = \pi_2\br{Z \cap \br{V \times U_\alpha}} $, replacing $ W $ by $ U_\alpha $, we conclude that it suffices to prove Theorem \ref{thm:projectionclosed} for the case where $ W $ is affine. Then we can replace $ V \subseteq \PP^m $ by $ \PP^m $ and $ W \subseteq \AA^n $ by $ \AA^n $, because $ V $ is closed in $ \PP^m $ and $ W $ is closed in $ \AA^n $, so $ Z \subseteq V \times W $ is closed in $ \PP^m \times \AA^n $. The benefit of doing this is that it simplifies the algebra when we change everything into coordinates. Thus it suffices to prove the following special case of Theorem \ref{thm:projectionclosed}.

\begin{theorem}
\label{thm:projectionclosed2}
The second projection map $ \pi_2 : \PP^m \times \AA^n \to \AA^n $ maps closed sets to closed sets.
\end{theorem}

\begin{proof}
We can concretely describe a Zariski closed subset $ Z \subseteq \PP^m \times \AA^n $ as the zero set of some polynomials $ f_0, \dots, f_r \in k\sbr{X_0, \dots, X_m, Y_1, \dots, Y_n} $ which are homogeneous with respect to $ X_0, \dots, X_m $. The coordinates $ Y_1, \dots, Y_n $ are affine coordinates, so there is no homogeneity condition with respect to them. For each point $ \underline{y} \in \AA^n $, we can substitute the values $ \underline{y} $ into these polynomials and get a projective algebraic set
$$ Z_{\underline{y}} = \cbr{\sbr{x_0 : \dots : x_m} \in \PP^m \st \forall i, \ f_i\br{x_0, \dots, x_m, \underline{y}} = 0}. $$
Observe that $ \underline{y} \in \pi_2\br{Z} $ if and only if $ Z_{\underline{y}} $ is non-empty. Let $ I_{\underline{y}} $ denote the ideal in $ k\sbr{X_0, \dots, X_m} $ generated by the polynomials
$$ f_0\br{X_0, \dots, X_m, \underline{y}}, \qquad \dots, \qquad f_r\br{X_0, \dots, X_m, \underline{y}}. $$
By the projective Nullstellensatz, $ Z_{\underline{y}} $ is non-empty if and only if $ \rad I_{\underline{y}} $ is not equal to either the full ring $ k\sbr{X_0, \dots, X_m} $ or to the ideal $ \abr{X_0, \dots, X_m} $. It is easy to see that this is equivalent to, $ I_{\underline{y}} $ does not contain $ S_d $ for any $ d \in \NN $, where $ S_d $ denotes the set of all homogeneous polynomials of degree $ d $ in $ k\sbr{X_0, \dots, X_m} $. For each $ d \in \NN $, write
$$ W_d = \cbr{\underline{y} \in \AA^n \st I_{\underline{y}} \not\supseteq S_d}. $$

\pagebreak

We have shown that $ \pi_2\br{Z} = \bigcap_{d \in \NN} W_d $. Let the polynomials $ f_0, \dots, f_r $ have degrees $ d_0, \dots, d_r $ with respect to the $ X $ variables. We shall show that $ W_d $ is closed for $ d \ge \max\br{d_0, \dots, d_r} $. Since the $ W_d $ are a descending chain of sets, this is sufficient to show that $ \pi_2\br{Z} $ is closed. Now we just need some linear algebra to finish the proof. If $ g \in S_d $, then $ g \in I_{\underline{y}} $ if and only if we can write
$$ g\br{X_0, \dots, X_m} = \sum_{i = 1}^r f_i\br{X_0, \dots, X_m, \underline{y}}h_i\br{X_0, \dots, X_m}, $$
for some homogeneous polynomials $ h_1, \dots, h_r $, where $ \deg h_i = d - d_i $. Hence $ S_d \cap I_{\underline{y}} $ is the image of the linear map given by
$$ \function[\alpha_{d, \underline{y}}]{\bigoplus_{i = 1}^r S_{d - d_i}}{S_d}{\br{h_1, \dots, h_r}}{\sum_{i = 1}^r f_i\br{X_0, \dots, X_m, \underline{y}}h_i\br{X_0, \dots, X_m}}. $$
Therefore
\begin{align*}
W_d
& = \cbr{\underline{y} \in \AA^n \st \alpha_{d, \underline{y}} \ \text{is not surjective}} \\
& = \cbr{\underline{y} \in \AA^n \st \rk \alpha_{d, \underline{y}} < \dim S_d} \\
& = \cbr{\underline{y} \in \AA^n \st \text{all} \ \br{\dim S_d \times \dim S_d} \ \text{submatrices of} \ \alpha_{d, \underline{y}} \ \text{have determinant zero}},
\end{align*}
where we fix bases for $ S_d $ and $ \bigoplus_i S_{d - d_i} $ and use these to write $ \alpha_{d, \underline{y}} $ as a matrix with respect to these bases. The determinants of these submatrices are polynomials in $ y_1, \dots, y_n $, proving that $ W_d $ is Zariski closed in $ \AA^n $.
\end{proof}

\subsubsection{The resultant}

Theorem \ref{thm:projectionclosed2} has the following application to roots of polynomials. We want to describe the set of pairs of polynomials $ f, g \in k\sbr{S, T} $, homogeneous of degrees $ d $ and $ e $ respectively, for which the set of common zeroes
$$ \cbr{\sbr{s : t} \in \PP^1 \st f\br{s, t} = 0, \ g\br{s, t} = 0} $$
is non-empty. We can identify the space of homogeneous polynomials of degree $ d $ in two variables with $ \AA^{d + 1} $, by associating $ \underline{a} = \br{a_0, \dots, a_d} \in \AA^{d + 1} $ with the polynomial
$$ f_{\underline{a}}\br{S, T} = \sum_{i = 0}^d a_iS^iT^{d - i}. $$
We can define a Zariski closed subset of $ \PP^1 \times \AA^{\br{d + 1} + \br{e + 1}} $ by
$$ Z_{d, e} = \cbr{\br{\sbr{s : t}, \underline{a}, \underline{b}} \in \PP^1 \times \AA^{\br{d + 1} + \br{e + 1}} \st \sum_{i = 0}^d a_is^it^{d - i} = 0, \ \sum_{i = 0}^e b_is^it^{e - i} = 0}. $$
For any point $ \br{\underline{a}, \underline{b}} \in \AA^{\br{d + 1} + \br{e + 1}} $ the fibre $ \pi_2^{-1}\br{\underline{a}, \underline{b}} \cap Z_{d, e} $ is simply the set of common zeroes of $ f_{\underline{a}} $ and $ f_{\underline{b}} $ in $ \PP^1 $. Hence
$$ \pi_2\br{Z_{d, e}} = \cbr{\br{\underline{a}, \underline{b}} \in \AA^{\br{d + 1} + \br{e + 1}} \st f_{\underline{a}} \ \text{and} \ f_{\underline{b}} \ \text{have a common zero in} \ \PP^1}. $$
By Theorem \ref{thm:projectionclosed2}, $ \pi_2\br{Z_{d, e}} $ is a Zariski closed subset of $ \AA^{\br{d + 1} + \br{e + 1}} $. In other words, there is some list of polynomials $ p_1, \dots, p_r $ such that the condition, homogeneous polynomials $ f $ and $ g $ in two variables of given degrees have a common zero in $ \PP^1 $, is equivalent to $ p_1, \dots, p_r $ all vanishing at the coefficients of $ f $ and $ g $. It turns out that this condition is equivalent not just to the vanishing of a list of polynomials in the coefficients, but to a single polynomial called the \textbf{resultant} $ \Res_{d, e} $.

\pagebreak

\begin{theorem}
\label{thm:fieldresultant}
Fix $ d, e \in \ZZ_{> 0} $. There exists a polynomial $ \Res_{d, e} \in k\sbr{A_0, \dots, A_d, B_0, \dots, B_e} $ such that the polynomials
$$ \sum_{i = 0}^d a_iS^iT^{d - i}, \qquad \sum_{i = 0}^e b_iS^iT^{e - i} $$
have a common root in $ \PP^1 $ if and only if
$$ \Res_{d, e}\br{a_0, \dots, a_d, b_0, \dots, b_e} = 0. $$
\end{theorem}

This can be proved by going through the linear algebra from the end of the proof of Theorem \ref{thm:projectionclosed2}. Indeed it is possible to work out the polynomial $ \Res_{d, e} $ explicitly in this way. We shall just quote this as a result of algebra. The algebra actually gives us something more. This works not just for polynomials over an algebraically closed field, but for polynomials over any integral domain, provided we replace have a common zero by have a common factor of positive degree.

\begin{theorem}
Fix $ d, e \in \ZZ_{> 0} $. There exists a universal polynomial $ \Res_{d, e} \in \ZZ\sbr{A_0, \dots, A_d, B_0, \dots, B_e} $ such that, for any integral domain $ R $ and any values $ a_0, \dots, a_d, b_0, \dots, b_e \in R $, the homogeneous polynomials
$$ f = \sum_{i = 0}^d a_iS^iT^{d - i} \in R\sbr{S, T}, \qquad g = \sum_{i = 0}^e b_iS^iT^{e - i} \in R\sbr{S, T} $$
have a common factor of positive degree in $ R\sbr{S, T} $ if and only if
$$ \Res_{d, e}\br{a_0, \dots, a_d, b_0, \dots, b_e} = 0. $$
\end{theorem}

From the perspective of elementary algebra, when stating Theorem \ref{thm:fieldresultant}, it is simpler to look at inhomogeneous polynomials in one variable and roots in $ \AA^1 $ instead of homogeneous polynomials in two variables and roots in $ \PP^1 $. Of course, we can convert back and forth by homogenising and dehomogenising the polynomials, replacing $ f\br{S, T} $ by $ f\br{1, T} $ and vice versa, but we have to be a little bit careful. We have to worry about the possibility that $ f\br{S, T} $ and $ g\br{S, T} $ might have a common root at $ \infty = \sbr{0 : 1} \in \PP^1 $ but not anywhere in $ \AA^1 = \PP^1 \setminus \cbr{\infty} $. It turns out that $ f\br{S, T} $ has a root at $ \infty $ if and only if the dehomogenised polynomial $ f\br{1, T} $ has degree strictly less than $ \deg f\br{S, T} $. Thus, Theorem \ref{thm:fieldresultant} implies that $ \Res_{d, e} $ vanishes on the coefficients of two single variable polynomials
$$ f\br{T} = \sum_{i = 0}^d a_iT^i, \qquad g\br{T} = \sum_{i = 0}^e b_iT^i $$
if and only if $ f $ and $ g $ have a common root in $ k $, as long as $ f $ and $ g $ have degrees exactly $ d $ and $ e $ respectively. If $ \deg f < d $, but we still write out $ f $ as in the above with $ a_d = 0 $, then looking at $ \Res_{d, e} $ might give the wrong answer for whether $ f $ and $ g $ have a common root, and similarly if $ \deg g < e $.

\end{document}